{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# This notebook is used for intial data exploration for the capstone project\n",
    "##########################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Before DropNA', 31057875)\n",
      "('After DropNA', 21967768)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "\n",
    "\n",
    "#data = pd.read_csv('data/transactions_200607.csv')  #import one file\n",
    "\n",
    "#import all csvs (courtesy of http://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe)\n",
    "\n",
    "path =r'data' # use your path\n",
    "allFiles = glob.glob(path + \"/tr*.csv\")\n",
    "\n",
    "#print allFiles\n",
    "data = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0)\n",
    "    list_.append(df)\n",
    "data = pd.concat(list_)\n",
    "\n",
    "#print(data.head(20))\n",
    "\n",
    "\n",
    "print('Before DropNA',len(data))\n",
    "data=data.dropna()\n",
    "print('After DropNA',len(data))\n",
    "\n",
    "#consider dropping these categories, but will try with them first.\n",
    "\n",
    "#data = data[data.CUST_PRICE_SENSITIVITY != 'XX']\n",
    "#data = data[data.CUST_LIFESTAGE != 'OT']\n",
    "#print('After Uninteresting categories',len(data))\n",
    "#list(data.columns.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Reformat the data into a wide dataset using Prod_code_20 as the lowest level of aggregation.  This is as recommended by Apeh et al. in Customer Profile Classification Using Transactional Data (https://core.ac.uk/download/pdf/4899037.pdf).  Then, to predict the basket, we just apply the value for the predicted customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                DEP00001  DEP00002  DEP00003  DEP00004  DEP00005  DEP00006  \\\n",
      "CUST_CODE                                                                    \n",
      "CUST0000000031     14.41     19.62      1.39     21.96     13.28       0.0   \n",
      "CUST0000000068    266.45     50.44     71.24      1.68      6.86       0.0   \n",
      "CUST0000000108      0.00      0.00      4.32      0.00      0.00       0.0   \n",
      "CUST0000000131      2.34     30.37      0.00      4.86      2.46       0.0   \n",
      "CUST0000000164      2.34      0.00      0.00      0.00      0.00       0.0   \n",
      "\n",
      "                DEP00007  DEP00008  DEP00009  DEP00010  \\\n",
      "CUST_CODE                                                \n",
      "CUST0000000031       0.0    111.16      3.21     34.87   \n",
      "CUST0000000068       0.0    153.07      2.56     11.08   \n",
      "CUST0000000108       0.0      1.76      0.00      2.98   \n",
      "CUST0000000131       0.0    130.05      2.78     30.59   \n",
      "CUST0000000164       0.0      2.77      0.00      1.29   \n",
      "\n",
      "                         ...               L    M   S  Full Shop  Small Shop  \\\n",
      "CUST_CODE                ...                                                   \n",
      "CUST0000000031           ...             301  294  62         44         268   \n",
      "CUST0000000068           ...            1028  285  71        333         334   \n",
      "CUST0000000108           ...               0   12   0          0           0   \n",
      "CUST0000000131           ...             255   92  17        179          75   \n",
      "CUST0000000164           ...               0   61  44          0          94   \n",
      "\n",
      "                Top Up  XX    SPEND  CUST_LIFESTAGE  CUST_PRICE_SENSITIVITY  \n",
      "CUST_CODE                                                                    \n",
      "CUST0000000031     345   0  1210.04              OT                      UM  \n",
      "CUST0000000068     711   6  2034.81              OT                      LA  \n",
      "CUST0000000108      12   0    17.86              OT                      XX  \n",
      "CUST0000000131     110   0   933.54              OA                      UM  \n",
      "CUST0000000164       8   3   134.55              OT                      MM  \n",
      "\n",
      "[5 rows x 107 columns]\n"
     ]
    }
   ],
   "source": [
    "#create customerprofiles.  Simplest version will be to sum spend in each category in PROD_CODE_20, keeping the target variable as well\n",
    "#pivot code from http://stackoverflow.com/questions/41046766/using-and-graphing-the-results-of-a-crosstab-dataframe-in-python\n",
    "\n",
    "data_cross=data.pivot_table(index='CUST_CODE', columns='PROD_CODE_20', values='SPEND', aggfunc=np.sum, fill_value=0)\n",
    "data_cross.reset_index(level=['CUST_CODE'], inplace=True)\n",
    "\n",
    "#group the variables that are unique to each basket\n",
    "byCustomer=data.groupby(['CUST_CODE'])\n",
    "targetsByCustomer=pd.DataFrame(byCustomer['CUST_LIFESTAGE', 'CUST_PRICE_SENSITIVITY'].first())\n",
    "targetsByCustomer.reset_index(level=['CUST_CODE'], inplace=True)\n",
    "\n",
    "sumsByCustomer=pd.DataFrame(byCustomer['SPEND'].sum())\n",
    "sumsByCustomer.reset_index(level=['CUST_CODE'], inplace=True)\n",
    "\n",
    "data_cross_day=data.pivot_table(index='CUST_CODE', columns='SHOP_WEEKDAY', values='SPEND', aggfunc=np.sum, fill_value=0)\n",
    "data_cross_day.reset_index(level=['CUST_CODE'], inplace=True)\n",
    "data_cross_basketsize = data.pivot_table(index='CUST_CODE', columns='BASKET_SIZE', values='SPEND', aggfunc=len, fill_value=0)\n",
    "data_cross_basketsize.reset_index(level=['CUST_CODE'], inplace=True)\n",
    "data_cross_baskettype = data.pivot_table(index='CUST_CODE', columns='BASKET_TYPE', values='SPEND', aggfunc=len, fill_value=0)\n",
    "data_cross_baskettype.reset_index(level=['CUST_CODE'], inplace=True)\n",
    "\n",
    "\n",
    "data_cross = pd.merge(data_cross, data_cross_day, how='inner', on = 'CUST_CODE')\n",
    "data_cross = pd.merge(data_cross, data_cross_basketsize, how='inner', on = 'CUST_CODE')\n",
    "data_cross = pd.merge(data_cross, data_cross_baskettype, how='inner', on = 'CUST_CODE')\n",
    "\n",
    "data_cross = pd.merge(data_cross, sumsByCustomer, how='inner', on = 'CUST_CODE')\n",
    "data_cross = pd.merge(data_cross, targetsByCustomer, how='inner', on = 'CUST_CODE')\n",
    "\n",
    "#reset the index to what it should be for the rest of the analysis\n",
    "data_cross.set_index(['CUST_CODE'], inplace=True)\n",
    "\n",
    "print(data_cross.head(5))\n",
    "#list(data_cross.columns.values)\n",
    "#print(data_cross.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHOP_WEEKDAY       CUST_CODE       1       2       3       4       5       6  \\\n",
      "0             CUST0000000031  208.17  183.57  162.41  136.72  260.78  159.22   \n",
      "1             CUST0000000068  356.85  303.24  250.42  341.69  231.09  298.53   \n",
      "2             CUST0000000108    8.93    0.00    0.00    0.00    0.00    0.00   \n",
      "3             CUST0000000131  176.47  251.85  117.20  162.75  151.36   34.75   \n",
      "4             CUST0000000164   22.89   20.13   22.95   20.60   17.28   11.25   \n",
      "\n",
      "SHOP_WEEKDAY       7  \n",
      "0              99.17  \n",
      "1             252.99  \n",
      "2               8.93  \n",
      "3              39.16  \n",
      "4              19.45  \n",
      "BASKET_SIZE       CUST_CODE     L    M   S\n",
      "0            CUST0000000031   301  294  62\n",
      "1            CUST0000000068  1028  285  71\n",
      "2            CUST0000000108     0   12   0\n",
      "3            CUST0000000131   255   92  17\n",
      "4            CUST0000000164     0   61  44\n",
      "BASKET_TYPE       CUST_CODE  Full Shop  Small Shop  Top Up  XX\n",
      "0            CUST0000000031         44         268     345   0\n",
      "1            CUST0000000068        333         334     711   6\n",
      "2            CUST0000000108          0           0      12   0\n",
      "3            CUST0000000131        179          75     110   0\n",
      "4            CUST0000000164          0          94       8   3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(data_cross_day.head())\n",
    "print(data_cross_basketsize.head())\n",
    "print(data_cross_baskettype.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGDCAYAAAB3BFm+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFXfuJRsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120a3f710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  #http://pandas.pydata.org/pandas-docs/stable/visualization.html\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "#http://pbpython.com/simple-graphing-pandas.html\n",
    "    \n",
    "plt.subplot(211)  \n",
    "lsPlot = data_cross.groupby(['CUST_LIFESTAGE'])['SPEND'].count().plot(kind='bar')\n",
    "plt.subplot(212)  \n",
    "psPlot = data_cross.groupby(['CUST_PRICE_SENSITIVITY'])['SPEND'].count().plot(kind='bar')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data #should probably consider stratified sampling here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create the training, testing split.  can't use sklearn.cross_validation.train_test_split since I have two targets\n",
    "\n",
    "#create a copy:\n",
    "data_cross_for_balanced_PS = data_cross\n",
    "data_cross_for_balanced_LS = data_cross\n",
    "\n",
    "#first do a 70-30 split.  \n",
    "train_X=data_cross.sample(frac=0.7,random_state=42)\n",
    "test_X=data_cross.drop(train_X.index)\n",
    "\n",
    "#pop off the classifiers\n",
    "train_y = train_X[[\"CUST_LIFESTAGE\",\"CUST_PRICE_SENSITIVITY\"]] #potentially for use in multi-output decision trees\n",
    "train_y_LS = train_X.pop(\"CUST_LIFESTAGE\")\n",
    "train_y_PS = train_X.pop(\"CUST_PRICE_SENSITIVITY\")\n",
    "\n",
    "test_y = test_X[[\"CUST_LIFESTAGE\",\"CUST_PRICE_SENSITIVITY\"]] #potentially for use in multi-output decision trees\n",
    "test_y_LS = test_X.pop(\"CUST_LIFESTAGE\")\n",
    "test_y_PS = test_X.pop(\"CUST_PRICE_SENSITIVITY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Downsample the training so all strata are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUST_PRICE_SENSITIVITY\n",
      "LA    10689\n",
      "MM    16603\n",
      "UM    11290\n",
      "XX     6067\n",
      "Name: SPEND, dtype: int64\n",
      "CUST_PRICE_SENSITIVITY\n",
      "LA    6067\n",
      "MM    6067\n",
      "UM    6067\n",
      "XX    6067\n",
      "Name: SPEND, dtype: int64\n",
      "CUST_LIFESTAGE\n",
      "OA     5359\n",
      "OF     1756\n",
      "OT    22126\n",
      "PE     3600\n",
      "YA     6375\n",
      "YF     5433\n",
      "Name: SPEND, dtype: int64\n",
      "CUST_LIFESTAGE\n",
      "OA    1756\n",
      "OF    1756\n",
      "OT    1756\n",
      "PE    1756\n",
      "YA    1756\n",
      "YF    1756\n",
      "Name: SPEND, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#based on  https://www.datarobot.com/blog/classification-with-scikit-learn/\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "print(data_cross_for_balanced_PS.groupby(['CUST_PRICE_SENSITIVITY'])['SPEND'].count())\n",
    "min_count_PS = min(data_cross_for_balanced_PS.groupby(['CUST_PRICE_SENSITIVITY'])['SPEND'].count())\n",
    "\n",
    "indices_LA = np.where(data_cross_for_balanced_PS.CUST_PRICE_SENSITIVITY == 'LA')[0]\n",
    "rng.shuffle(indices_LA)\n",
    "data_cross_for_balanced_PS = data_cross_for_balanced_PS.drop(data_cross_for_balanced_PS.index[indices_LA[min_count_PS:]])\n",
    "\n",
    "indices_MM = np.where(data_cross_for_balanced_PS.CUST_PRICE_SENSITIVITY == 'MM')[0]\n",
    "rng.shuffle(indices_MM)\n",
    "data_cross_for_balanced_PS = data_cross_for_balanced_PS.drop(data_cross_for_balanced_PS.index[indices_MM[min_count_PS:]])\n",
    "\n",
    "indices_UM = np.where(data_cross_for_balanced_PS.CUST_PRICE_SENSITIVITY == 'UM')[0]\n",
    "rng.shuffle(indices_UM)\n",
    "data_cross_for_balanced_PS = data_cross_for_balanced_PS.drop(data_cross_for_balanced_PS.index[indices_UM[min_count_PS:]])\n",
    "\n",
    "indices_XX = np.where(data_cross_for_balanced_PS.CUST_PRICE_SENSITIVITY == 'XX')[0]\n",
    "rng.shuffle(indices_XX)\n",
    "data_cross_for_balanced_PS = data_cross_for_balanced_PS.drop(data_cross_for_balanced_PS.index[indices_XX[min_count_PS:]])\n",
    "\n",
    "print(data_cross_for_balanced_PS.groupby(['CUST_PRICE_SENSITIVITY'])['SPEND'].count())\n",
    "\n",
    "print(data_cross_for_balanced_LS.groupby(['CUST_LIFESTAGE'])['SPEND'].count())\n",
    "min_count_LS = min(data_cross_for_balanced_LS.groupby(['CUST_LIFESTAGE'])['SPEND'].count())\n",
    "\n",
    "indices_OA = np.where(data_cross_for_balanced_LS.CUST_LIFESTAGE == 'OA')[0]\n",
    "rng.shuffle(indices_OA)\n",
    "data_cross_for_balanced_LS = data_cross_for_balanced_LS.drop(data_cross_for_balanced_LS.index[indices_OA[min_count_LS:]])\n",
    "\n",
    "indices_OF = np.where(data_cross_for_balanced_LS.CUST_LIFESTAGE == 'OF')[0]\n",
    "rng.shuffle(indices_OF)\n",
    "data_cross_for_balanced_LS = data_cross_for_balanced_LS.drop(data_cross_for_balanced_LS.index[indices_OF[min_count_LS:]])\n",
    "\n",
    "indices_OT = np.where(data_cross_for_balanced_LS.CUST_LIFESTAGE == 'OT')[0]\n",
    "rng.shuffle(indices_OT)\n",
    "data_cross_for_balanced_LS = data_cross_for_balanced_LS.drop(data_cross_for_balanced_LS.index[indices_OT[min_count_LS:]])\n",
    "\n",
    "indices_PE = np.where(data_cross_for_balanced_LS.CUST_LIFESTAGE == 'PE')[0]\n",
    "rng.shuffle(indices_PE)\n",
    "data_cross_for_balanced_LS = data_cross_for_balanced_LS.drop(data_cross_for_balanced_LS.index[indices_PE[min_count_LS:]])\n",
    "\n",
    "indices_YA = np.where(data_cross_for_balanced_LS.CUST_LIFESTAGE == 'YA')[0]\n",
    "rng.shuffle(indices_YA)\n",
    "data_cross_for_balanced_LS = data_cross_for_balanced_LS.drop(data_cross_for_balanced_LS.index[indices_YA[min_count_LS:]])\n",
    "\n",
    "indices_YF = np.where(data_cross_for_balanced_LS.CUST_LIFESTAGE == 'YF')[0]\n",
    "rng.shuffle(indices_YF)\n",
    "data_cross_for_balanced_LS = data_cross_for_balanced_LS.drop(data_cross_for_balanced_LS.index[indices_YF[min_count_LS:]])\n",
    "\n",
    "\n",
    "print(data_cross_for_balanced_LS.groupby(['CUST_LIFESTAGE'])['SPEND'].count())\n",
    "\n",
    "\n",
    "\n",
    "#first do a 70-30 split.  \n",
    "balanced_PS_train_X=data_cross_for_balanced_PS.sample(frac=0.7,random_state=42)\n",
    "balanced_PS_test_X=data_cross_for_balanced_PS.drop(balanced_PS_train_X.index)\n",
    "\n",
    "#pop off the classifiers\n",
    "balanced_PS_train_y_LS = balanced_PS_train_X.pop(\"CUST_LIFESTAGE\") #don't need this\n",
    "balanced_PS_train_y_PS = balanced_PS_train_X.pop(\"CUST_PRICE_SENSITIVITY\")\n",
    "\n",
    "balanced_PS_test_y_LS = balanced_PS_test_X.pop(\"CUST_LIFESTAGE\") #don't need this\n",
    "balanced_PS_test_y_PS = balanced_PS_test_X.pop(\"CUST_PRICE_SENSITIVITY\")\n",
    "\n",
    "#first do a 70-30 split.  \n",
    "balanced_LS_train_X=data_cross_for_balanced_LS.sample(frac=0.7,random_state=42)\n",
    "balanced_LS_test_X=data_cross_for_balanced_LS.drop(balanced_LS_train_X.index)\n",
    "\n",
    "#pop off the classifiers\n",
    "balanced_LS_train_y_LS = balanced_LS_train_X.pop(\"CUST_LIFESTAGE\")\n",
    "balanced_LS_train_y_PS = balanced_LS_train_X.pop(\"CUST_PRICE_SENSITIVITY\") #don't need this\n",
    "\n",
    "balanced_LS_test_y_LS = balanced_LS_test_X.pop(\"CUST_LIFESTAGE\")\n",
    "balanced_LS_test_y_PS = balanced_LS_test_X.pop(\"CUST_PRICE_SENSITIVITY\") #don't need this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUST_LIFESTAGE\n",
      "OA     5359\n",
      "OF     1756\n",
      "OT    22126\n",
      "PE     3600\n",
      "YA     6375\n",
      "YF     5433\n",
      "Name: SPEND, dtype: int64\n",
      "CUST_LIFESTAGE\n",
      "OA    22126\n",
      "OF    22126\n",
      "OT    22126\n",
      "PE    22126\n",
      "YA    22126\n",
      "YF    22126\n",
      "Name: SPEND, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#upsampling for LS, per http://www.site.uottawa.ca/~nat/Courses/csi5388/Class-Imbalances.ppt\n",
    "from sklearn.utils import resample\n",
    "data_cross_upsampled_LS = data_cross\n",
    "\n",
    "print(data_cross_upsampled_LS.groupby(['CUST_LIFESTAGE'])['SPEND'].count())\n",
    "max_count_LS = max(data_cross_upsampled_LS.groupby(['CUST_LIFESTAGE'])['SPEND'].count())\n",
    "\n",
    "subset_OA = data_cross_upsampled_LS[data_cross_upsampled_LS.CUST_LIFESTAGE == 'OA']\n",
    "up_subset_OA = resample(subset_OA, n_samples=max_count_LS)\n",
    "subset_OT = data_cross_upsampled_LS[data_cross_upsampled_LS.CUST_LIFESTAGE == 'OT']\n",
    "up_subset_OT = resample(subset_OT, n_samples=max_count_LS)\n",
    "subset_PE = data_cross_upsampled_LS[data_cross_upsampled_LS.CUST_LIFESTAGE == 'PE']\n",
    "up_subset_PE = resample(subset_PE, n_samples=max_count_LS)\n",
    "subset_YA = data_cross_upsampled_LS[data_cross_upsampled_LS.CUST_LIFESTAGE == 'YA']\n",
    "up_subset_YA = resample(subset_YA, n_samples=max_count_LS)\n",
    "subset_OF = data_cross_upsampled_LS[data_cross_upsampled_LS.CUST_LIFESTAGE == 'OF']\n",
    "up_subset_OF = resample(subset_OF, n_samples=max_count_LS)\n",
    "subset_YF = data_cross_upsampled_LS[data_cross_upsampled_LS.CUST_LIFESTAGE == 'YF']\n",
    "up_subset_YF = resample(subset_YF, n_samples=max_count_LS)\n",
    "\n",
    "data_cross_upsampled_LS = pd.concat([up_subset_OA, subset_OT,up_subset_OF, up_subset_YA, up_subset_YF, up_subset_PE ])\n",
    "\n",
    "print(data_cross_upsampled_LS.groupby(['CUST_LIFESTAGE'])['SPEND'].count())\n",
    "\n",
    "#first do a 70-30 split.  \n",
    "upsampled_LS_train_X=data_cross_upsampled_LS.sample(frac=0.7,random_state=42)\n",
    "upsampled_LS_test_X=data_cross_upsampled_LS.drop(upsampled_LS_train_X.index)\n",
    "\n",
    "#pop off the classifiers\n",
    "upsampled_LS_train_y_LS = upsampled_LS_train_X.pop(\"CUST_LIFESTAGE\")\n",
    "upsampled_LS_train_y_PS = upsampled_LS_train_X.pop(\"CUST_PRICE_SENSITIVITY\") #don't need this\n",
    "\n",
    "upsampled_LS_test_y_LS = upsampled_LS_test_X.pop(\"CUST_LIFESTAGE\")\n",
    "upsampled_LS_test_y_PS = upsampled_LS_test_X.pop(\"CUST_PRICE_SENSITIVITY\") #don't need this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Create a function to test classifiers and create simple output\n",
    "def tryClassifier_PS (title,psClassifier, train_X, test_X, train_y_PS, test_y_PS):\n",
    "    ps_pred_train = psClassifier.predict(train_X)\n",
    "    ps_pred_test = psClassifier.predict(test_X)\n",
    "    \n",
    "    print(title)\n",
    "    print('Price Sensitivity Training: ', psClassifier.score(train_X, train_y_PS))\n",
    "    print(confusion_matrix(train_y_PS, ps_pred_train, labels=[\"LA\", \"MM\", \"UM\",\"XX\"]))\n",
    "    print('Price Sensitivity Testing: ', psClassifier.score(test_X, test_y_PS))\n",
    "    print(confusion_matrix(test_y_PS, ps_pred_test, labels=[\"LA\", \"MM\", \"UM\",\"XX\"]))\n",
    "\n",
    "\n",
    "def tryClassifier_LS (title, lsClassifier, train_X, test_X, train_y_LS, test_y_LS):\n",
    "\n",
    "    ls_pred_train = lsClassifier.predict(train_X)\n",
    "    ls_pred_test = lsClassifier.predict(test_X)\n",
    "    \n",
    "    print('LifeStage Training: ', lsClassifier.score(train_X, train_y_LS))\n",
    "    print(confusion_matrix(train_y_LS, ls_pred_train, labels=[\"OA\", \"OF\", \"OT\",\"PE\",\"YA\",\"YF\"]))\n",
    "    print('LifeStage Testing: ', lsClassifier.score(test_X, test_y_LS))\n",
    "    print(confusion_matrix(test_y_LS, ls_pred_test, labels=[\"OA\", \"OF\", \"OT\",\"PE\",\"YA\",\"YF\"]))\n",
    " \n",
    "    \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#create an accuracy metric\n",
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true and predicted values based on the metric chosen. \"\"\"\n",
    "    \n",
    "    # TODO: Calculate the performance score between 'y_true' and 'y_predict'\n",
    "    score = accuracy_score(y_true, y_predict)\n",
    "    \n",
    "    # Return the score\n",
    "    return score\n",
    "from sklearn.metrics import make_scorer\n",
    "scoring_fnc = make_scorer(performance_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbalanced:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier #using scikitlearn 0.17.1\n",
    "\n",
    "print('Unbalanced:')\n",
    "\n",
    "rfc_ps = RandomForestClassifier(n_estimators = 10000,random_state=42, criterion=\"entropy\"\n",
    "                                , max_features = 10\n",
    "                                #, max_leaf_nodes=1000\n",
    "                                #, min_samples_leaf=20\n",
    "                                , oob_score=True\n",
    "                               )\n",
    "rfc_ls = RandomForestClassifier(n_estimators = 10000,random_state=42, criterion=\"entropy\"\n",
    "                                , max_features = 10\n",
    "                                #, max_leaf_nodes=1000\n",
    "                                #, min_samples_leaf=20\n",
    "                                , oob_score=True\n",
    "                               )\n",
    "#need to handle categorical variables either through pandas.getDummies or http://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder\n",
    "#train_X_num\n",
    "\n",
    "#print(train_X_dummied.head(10))\n",
    "#print(list(train_X_dummied.columns.values))\n",
    "\n",
    "rfc_ps = rfc_ps.fit(train_X, train_y_PS)\n",
    "rfc_ls = rfc_ls.fit(train_X, train_y_LS)\n",
    "\n",
    "print ('Recall that running training data back through the random forest is not as good an indicator of performance as the OOB score')\n",
    "\n",
    "print('Price Sensitivity OOB: ', rfc_ps.oob_score_)\n",
    "tryClassifier_PS (\"Random Forest\",rfc_ps, train_X, test_X, train_y_PS, test_y_PS)\n",
    "\n",
    "print('Life Stage OOB: ', rfc_ls.oob_score_)\n",
    "tryClassifier_LS (\"Random Forest\", rfc_ls, train_X, test_X, train_y_LS, test_y_LS)\n",
    "\n",
    "print('Balanced:')\n",
    "\n",
    "rfc_balanced_ps = RandomForestClassifier(n_estimators = 10000,random_state=42, criterion=\"entropy\"\n",
    "                                , max_features = 10\n",
    "                                #, max_leaf_nodes=1000\n",
    "                                #, min_samples_leaf=20\n",
    "                                , oob_score=True\n",
    "                               )\n",
    "rfc_balanced_ls = RandomForestClassifier(n_estimators = 10000,random_state=42, criterion=\"entropy\"\n",
    "                                , max_features = 10\n",
    "                                #, max_leaf_nodes=1000\n",
    "                                #, min_samples_leaf=20\n",
    "                                , oob_score=True\n",
    "                               )\n",
    "#need to handle categorical variables either through pandas.getDummies or http://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder\n",
    "#train_X_num\n",
    "\n",
    "#print(train_X_dummied.head(10))\n",
    "#print(list(train_X_dummied.columns.values))\n",
    "\n",
    "rfc_balanced_ps = rfc_balanced_ps.fit(balanced_PS_train_X, balanced_PS_train_y_PS)\n",
    "rfc_balanced_ls = rfc_balanced_ls.fit(balanced_LS_train_X, balanced_LS_train_y_LS)\n",
    "\n",
    "print('Price Sensitivity OOB: ', rfc_ps.oob_score_)\n",
    "tryClassifier_PS (\"Random Forest\",rfc_balanced_ps, balanced_PS_train_X, test_X, balanced_PS_train_y_PS, test_y_PS)\n",
    "\n",
    "print('Life Stage OOB: ', rfc_ls.oob_score_)\n",
    "tryClassifier_LS (\"Random Forest\", rfc_balanced_ls, balanced_LS_train_X, test_X, balanced_LS_train_y_LS, test_y_LS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Sample output\n",
    "\n",
    "Unbalanced:\n",
    "Recall that running training data back through the random forest is not as good an indicator of performance as the OOB score\n",
    "('Price Sensitivity OOB: ', 0.61323350611121774)\n",
    "Random Forest\n",
    "('Price Sensitivity Training: ', 1.0)\n",
    "[[ 7467     0     0     0]\n",
    " [    0 11628     0     0]\n",
    " [    0     0  7936     0]\n",
    " [    0     0     0  4223]]\n",
    "('Price Sensitivity Testing: ', 0.61612541993281078)\n",
    "[[1150 1783  133  156]\n",
    " [ 457 3696  666  156]\n",
    " [  42 1551 1670   91]\n",
    " [  15   70   22 1737]]\n",
    "('Life Stage OOB: ', 0.51938951814167789)\n",
    "('LifeStage Training: ', 0.99910411467332183)\n",
    "[[ 3717     0     6     0     0     0]\n",
    " [    0  1253     2     0     0     0]\n",
    " [    0     0 15496     0     0     0]\n",
    " [    0     0     3  2500     0     0]\n",
    " [    0     0    12     0  4457     0]\n",
    " [    0     0     5     0     0  3803]]\n",
    "('LifeStage Testing: ', 0.51213139231056359)\n",
    "[[  56    0 1481   36    2   61]\n",
    " [   0    0  369    2    0  130]\n",
    " [  50    1 6219   54    3  303]\n",
    " [  54    0  921  114    0    8]\n",
    " [  25    0 1723    7    6  145]\n",
    " [   7    0 1146    7    0  465]]\n",
    "Balanced:\n",
    "('Price Sensitivity OOB: ', 0.61323350611121774)\n",
    "Random Forest\n",
    "('Price Sensitivity Training: ', 1.0)\n",
    "[[4236    0    0    0]\n",
    " [   0 4228    0    0]\n",
    " [   0    0 4288    0]\n",
    " [   0    0    0 4236]]\n",
    "('Price Sensitivity Testing: ', 0.71392310563643147)\n",
    "[[2485  359  228  150]\n",
    " [1155 2532 1087  201]\n",
    " [ 206  322 2722  104]\n",
    " [  11    1    8 1824]]\n",
    "('Life Stage OOB: ', 0.51938951814167789)\n",
    "('LifeStage Training: ', 0.99959322033898301)\n",
    "[[1223    0    0    0    0    1]\n",
    " [   0 1209    0    0    0    0]\n",
    " [   0    0 1250    0    0    0]\n",
    " [   0    0    1 1242    0    0]\n",
    " [   0    0    1    0 1236    0]\n",
    " [   0    0    0    0    0 1212]]\n",
    "('LifeStage Testing: ', 0.51847704367301228)\n",
    "[[ 617  117  191  431  188   92]\n",
    " [  12  376   24    9   35   45]\n",
    " [ 419  476 3364  903 1032  436]\n",
    " [  98   19  116  815   34   15]\n",
    " [ 171  173  235  197  953  177]\n",
    " [ 103  250  150   81  221  820]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 0.18.1.\n",
      "All code tested on 0.18.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "print('All code tested on 0.18.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier\n",
      "('Price Sensitivity Training: ', 1.0)\n",
      "[[ 7467     0     0     0]\n",
      " [    0 11628     0     0]\n",
      " [    0     0  7936     0]\n",
      " [    0     0     0  4223]]\n",
      "('Price Sensitivity Testing: ', 0.6206047032474804)\n",
      "[[1476 1512  154   80]\n",
      " [ 721 3342  822   90]\n",
      " [ 104 1374 1833   43]\n",
      " [  43   96   43 1662]]\n",
      "Gradient Boosting Classifier\n",
      "('Price Sensitivity Training: ', 1.0)\n",
      "[[4236    0    0    0]\n",
      " [   0 4228    0    0]\n",
      " [   0    0 4288    0]\n",
      " [   0    0    0 4236]]\n",
      "('Price Sensitivity Testing: ', 0.72340425531914898)\n",
      "[[2476  471  171  104]\n",
      " [1073 2723 1039  140]\n",
      " [ 185  419 2678   72]\n",
      " [  14    6   11 1813]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc_ps = GradientBoostingClassifier(learning_rate=0.05, n_estimators=1000, max_depth=10)\n",
    "balanced_gbc_ps = GradientBoostingClassifier(learning_rate=0.05, n_estimators=1000, max_depth=10)\n",
    "\n",
    "#gbc_ls = GradientBoostingClassifier(learning_rate=0.05, n_estimators=1000, max_depth=10)\n",
    "\n",
    "gbc_ps = gbc_ps.fit(train_X, train_y_PS)\n",
    "balanced_gbc_ps = balanced_gbc_ps.fit(balanced_PS_train_X, balanced_PS_train_y_PS)\n",
    "#gbc_ls = rfc_ls.fit(train_X, train_y_LS)\n",
    "\n",
    "tryClassifier_PS (\"Gradient Boosting Classifier\",gbc_ps, train_X, test_X, train_y_PS, test_y_PS)\n",
    "tryClassifier_PS (\"Gradient Boosting Classifier\",balanced_gbc_ps, balanced_PS_train_X, test_X, balanced_PS_train_y_PS, test_y_PS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample output\n",
    "Gradient Boosting Classifier\n",
    "('Price Sensitivity Training: ', 1.0)\n",
    "[[ 7467     0     0     0]\n",
    " [    0 11628     0     0]\n",
    " [    0     0  7936     0]\n",
    " [    0     0     0  4223]]\n",
    "('Price Sensitivity Testing: ', 0.61814109742441214)\n",
    "[[1466 1520  158   78]\n",
    " [ 740 3321  822   92]\n",
    " [ 102 1378 1833   41]\n",
    " [  47   91   46 1660]]\n",
    "Gradient Boosting Classifier\n",
    "('Price Sensitivity Training: ', 1.0)\n",
    "[[4236    0    0    0]\n",
    " [   0 4228    0    0]\n",
    " [   0    0 4288    0]\n",
    " [   0    0    0 4236]]\n",
    "('Price Sensitivity Testing: ', 0.72474804031354978)\n",
    "[[2466  470  184  102]\n",
    " [1061 2759 1011  144]\n",
    " [ 185  435 2668   66]\n",
    " [  16    4    9 1815]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LifeStage Training: ', 0.99910411467332183)\n",
      "[[ 3717     0     6     0     0     0]\n",
      " [    0  1253     2     0     0     0]\n",
      " [    0     0 15496     0     0     0]\n",
      " [    0     0     3  2500     0     0]\n",
      " [    0     0    12     0  4457     0]\n",
      " [    0     0     5     0     0  3803]]\n",
      "('LifeStage Testing: ', 0.50727883538633822)\n",
      "[[ 138    0 1305   87   61   45]\n",
      " [   9    2  370    4   18   98]\n",
      " [ 131    7 5936  130  190  236]\n",
      " [  98    0  783  197   10    9]\n",
      " [  58    0 1568   20  142  118]\n",
      " [  32    5 1144   10   54  380]]\n",
      "('LifeStage Training: ', 0.99959322033898301)\n",
      "[[1224    0    0    0    0    0]\n",
      " [   0 1209    0    0    0    0]\n",
      " [   0    0 1250    0    0    0]\n",
      " [   0    0    1 1242    0    0]\n",
      " [   0    0    1    0 1236    0]\n",
      " [   1    0    0    0    0 1211]]\n",
      "('LifeStage Testing: ', 0.49092945128779397)\n",
      "[[ 696  119  191  344  172  114]\n",
      " [  18  379   20    7   30   47]\n",
      " [ 666  581 3047  811  904  621]\n",
      " [ 153   17   96  771   32   28]\n",
      " [ 220  209  228  149  867  233]\n",
      " [ 115  283  148   62  201  816]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc_LS = GradientBoostingClassifier(learning_rate=0.05, n_estimators=1000, max_depth=10)\n",
    "balanced_gbc_LS = GradientBoostingClassifier(learning_rate=0.05, n_estimators=1000, max_depth=10)\n",
    "\n",
    "#gbc_ls = GradientBoostingClassifier(learning_rate=0.05, n_estimators=1000, max_depth=10)\n",
    "\n",
    "gbc_LS = gbc_LS.fit(train_X, train_y_LS)\n",
    "balanced_gbc_LS = balanced_gbc_LS.fit(balanced_LS_train_X, balanced_LS_train_y_LS)\n",
    "#gbc_ls = rfc_ls.fit(train_X, train_y_LS)\n",
    "\n",
    "tryClassifier_LS (\"Gradient Boosting Classifier\",gbc_LS, train_X, test_X, train_y_LS, test_y_LS)\n",
    "tryClassifier_LS (\"Gradient Boosting Classifier\",balanced_gbc_LS, balanced_LS_train_X, test_X, balanced_LS_train_y_LS, test_y_LS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier\n",
      "('Price Sensitivity Training: ', 0.6076342228194791)\n",
      "[[4091 2711  496  169]\n",
      " [2321 7977 1192  138]\n",
      " [1108 3497 3239   92]\n",
      " [ 259  197   83 3684]]\n",
      "('Price Sensitivity Testing: ', 0.50272489734975734)\n",
      "[[1319 1542  277   84]\n",
      " [1413 2768  724   70]\n",
      " [ 557 1685 1079   33]\n",
      " [ 113  114   49 1568]]\n",
      "KNN Classifier\n",
      "('Price Sensitivity Training: ', 0.65104779844596183)\n",
      "[[2838  814  427  157]\n",
      " [1345 2025  744  114]\n",
      " [ 881 1033 2266  108]\n",
      " [ 162   74   69 3931]]\n",
      "('Price Sensitivity Testing: ', 0.53049645390070921)\n",
      "[[1968  764  358  132]\n",
      " [1904 1908 1027  136]\n",
      " [ 794  924 1548   88]\n",
      " [  89   33   40 1682]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_ps = KNeighborsClassifier(n_neighbors=10)\n",
    "balanced_knn_ps = KNeighborsClassifier(n_neighbors=10)\n",
    "#knn_ls = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "knn_ps = knn_ps.fit(train_X,train_y_PS)\n",
    "balanced_knn_ps = balanced_knn_ps.fit(balanced_PS_train_X,balanced_PS_train_y_PS)\n",
    "#knn_ls = knn_ls.fit(train_X,train_y_LS)\n",
    "\n",
    "tryClassifier_PS (\"KNN Classifier\",knn_ps, train_X, test_X, train_y_PS, test_y_PS)\n",
    "tryClassifier_PS (\"KNN Classifier\",balanced_knn_ps, balanced_PS_train_X, test_X, balanced_PS_train_y_PS, test_y_PS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## sample output\n",
    "KNN Classifier\n",
    "('Price Sensitivity Training: ', 0.6076342228194791)\n",
    "[[4091 2711  496  169]\n",
    " [2321 7977 1192  138]\n",
    " [1108 3497 3239   92]\n",
    " [ 259  197   83 3684]]\n",
    "('Price Sensitivity Testing: ', 0.50272489734975734)\n",
    "[[1319 1542  277   84]\n",
    " [1413 2768  724   70]\n",
    " [ 557 1685 1079   33]\n",
    " [ 113  114   49 1568]]\n",
    "KNN Classifier\n",
    "('Price Sensitivity Training: ', 0.65104779844596183)\n",
    "[[2838  814  427  157]\n",
    " [1345 2025  744  114]\n",
    " [ 881 1033 2266  108]\n",
    " [ 162   74   69 3931]]\n",
    "('Price Sensitivity Testing: ', 0.53049645390070921)\n",
    "[[1968  764  358  132]\n",
    " [1904 1908 1027  136]\n",
    " [ 794  924 1548   88]\n",
    " [  89   33   40 1682]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LifeStage Training: ', 0.55589684520381388)\n",
      "[[  929    47  2051    79   272   345]\n",
      " [   76   135   637    13   106   288]\n",
      " [  480   105 13670    84   463   694]\n",
      " [  303    25  1614   274   145   142]\n",
      " [  276    57  2708    35   904   489]\n",
      " [  158    71  1788    40   289  1462]]\n",
      "('LifeStage Testing: ', 0.46285927584919745)\n",
      "[[ 184   31 1051   41  140  189]\n",
      " [  25   13  297    5   30  131]\n",
      " [ 316   83 5294   71  374  492]\n",
      " [ 161   10  748   43   67   68]\n",
      " [ 137   31 1235   21  216  266]\n",
      " [  86   42  909   12  126  450]]\n",
      "('LifeStage Training: ', 0.41477966101694913)\n",
      "[[475 190 133 126 138 162]\n",
      " [101 556 132  52 119 249]\n",
      " [127 151 644  73 134 121]\n",
      " [218 160 202 432 122 109]\n",
      " [123 250 174  84 435 171]\n",
      " [108 278 116  64 129 517]]\n",
      "('LifeStage Testing: ', 0.33766330720418064)\n",
      "[[ 395  341  218  211  221  250]\n",
      " [  47  206   61   25   54  108]\n",
      " [ 758 1001 2666  619  848  738]\n",
      " [ 220  187  201  274   99  116]\n",
      " [ 262  433  264  149  461  337]\n",
      " [ 184  454  164   86  216  521]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_LS = KNeighborsClassifier(n_neighbors=10)\n",
    "balanced_knn_LS = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "\n",
    "knn_LS = knn_LS.fit(train_X,train_y_LS)\n",
    "balanced_knn_LS = balanced_knn_LS.fit(balanced_LS_train_X,balanced_LS_train_y_LS)\n",
    "\n",
    "\n",
    "tryClassifier_LS (\"KNN Classifier\",knn_LS, train_X, test_X, train_y_LS, test_y_LS)\n",
    "tryClassifier_LS (\"KNN Classifier\",balanced_knn_LS, balanced_LS_train_X, test_X, balanced_LS_train_y_LS, test_y_LS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier\n",
      "('Price Sensitivity Training: ', 0.5092788123120241)\n",
      "[[2191 5050  208   18]\n",
      " [1589 8793 1231   15]\n",
      " [ 272 5024 2627   13]\n",
      " [  59 1850    8 2306]]\n",
      "('Price Sensitivity Testing: ', 0.51325121313923106)\n",
      "[[ 947 2172   93   10]\n",
      " [ 670 3762  538    5]\n",
      " [ 121 2064 1167    2]\n",
      " [  25  814    6  999]]\n",
      "MLP Classifier Balanced\n",
      "('Price Sensitivity Training: ', 0.60448551919001647)\n",
      "[[2786  695  308  447]\n",
      " [1862 1186  859  321]\n",
      " [ 908  858 2220  302]\n",
      " [ 115   12   32 4077]]\n",
      "('Price Sensitivity Testing: ', 0.52541993281075028)\n",
      "[[2134  485  254  349]\n",
      " [2181 1390 1021  383]\n",
      " [ 709  679 1742  224]\n",
      " [  49    6   17 1772]]\n",
      "MLP Classifier Scaled\n",
      "('Price Sensitivity Training: ', 0.59982722211556916)\n",
      "[[3023 3711  295  438]\n",
      " [1649 7746 1804  429]\n",
      " [ 232 3375 4048  281]\n",
      " [  52  203   38 3930]]\n",
      "('Price Sensitivity Testing: ', 0.59977603583426653)\n",
      "[[1294 1596  138  194]\n",
      " [ 684 3335  763  193]\n",
      " [  91 1435 1718  110]\n",
      " [  29  106   22 1687]]\n",
      "MLP Classifier Balanced Scaled\n",
      "('Price Sensitivity Training: ', 0.66947256887214501)\n",
      "[[2612  912  408  304]\n",
      " [1186 1749 1085  208]\n",
      " [ 377  762 2964  185]\n",
      " [  95   21   72 4048]]\n",
      "('Price Sensitivity Testing: ', 0.58768197088465846)\n",
      "[[1951  718  313  240]\n",
      " [1429 1933 1358  255]\n",
      " [ 323  648 2239  144]\n",
      " [  42   12   41 1749]]\n",
      "MLP Classifier Scaled, tuned\n",
      "('Price Sensitivity Training: ', 0.58453317975299157)\n",
      "[[2734 3741  219  773]\n",
      " [1442 7841 1518  827]\n",
      " [ 191 3553 3613  579]\n",
      " [  17  106   19 4081]]\n",
      "('Price Sensitivity Testing: ', 0.587010078387458)\n",
      "[[1170 1612  100  340]\n",
      " [ 576 3386  630  383]\n",
      " [  72 1511 1542  229]\n",
      " [   9   61    9 1765]]\n"
     ]
    }
   ],
   "source": [
    "#requires sklearn 0.18\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler #from http://www.kdnuggets.com/2016/10/beginners-guide-neural-networks-python-scikit-learn.html/2\n",
    "\n",
    "scaler=StandardScaler()\n",
    "balanced_scaler=StandardScaler()\n",
    "\n",
    "scaler.fit(train_X)\n",
    "balanced_scaler.fit(balanced_PS_train_X)\n",
    "\n",
    "scaled_X_train=scaler.transform(train_X)\n",
    "scaled_X_test=scaler.transform(test_X)\n",
    "scaled_balanced_PS_X_train=balanced_scaler.transform(balanced_PS_train_X)\n",
    "scaled_balanced_PS_X_test=balanced_scaler.transform(test_X)\n",
    "\n",
    "ann_PS = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 100,100), random_state=42)\n",
    "balanced_ann_PS = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 100,100), random_state=42)\n",
    "scaled_ann_PS = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 100,100), random_state=42)\n",
    "scaled_balanced_ann_PS = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 100,100), random_state=42)\n",
    "#ann_LS = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "ann_PS = ann_PS.fit(train_X, train_y_PS)\n",
    "balanced_ann_PS = balanced_ann_PS.fit(balanced_PS_train_X, balanced_PS_train_y_PS)\n",
    "scaled_ann_PS = scaled_ann_PS.fit(scaled_X_train, train_y_PS)\n",
    "scaled_balanced_ann_PS = scaled_balanced_ann_PS.fit(scaled_balanced_PS_X_train, balanced_PS_train_y_PS)\n",
    "\n",
    "\n",
    "scaled_ann_PS_2 = MLPClassifier(solver='sgd', alpha=0.0001, learning_rate_init=0.001, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(200,200), random_state=42, activation='logistic', max_iter=500) \n",
    "scaled_ann_PS_2 = scaled_ann_PS_2.fit(scaled_X_train, train_y_PS)\n",
    "\n",
    "#ann_LS = ann_LS.fit(train_X, train_y_LS)\n",
    "\n",
    "tryClassifier_PS (\"MLP Classifier\",ann_PS, train_X, test_X, train_y_PS, test_y_PS)\n",
    "tryClassifier_PS (\"MLP Classifier Balanced\",balanced_ann_PS, balanced_PS_train_X, test_X, balanced_PS_train_y_PS, test_y_PS)\n",
    "tryClassifier_PS (\"MLP Classifier Scaled\",scaled_ann_PS, scaled_X_train, scaled_X_test, train_y_PS, test_y_PS)\n",
    "tryClassifier_PS (\"MLP Classifier Balanced Scaled\",scaled_balanced_ann_PS, scaled_balanced_PS_X_train, scaled_balanced_PS_X_test, balanced_PS_train_y_PS, test_y_PS)\n",
    "tryClassifier_PS (\"MLP Classifier Scaled, tuned\",scaled_ann_PS_2, scaled_X_train, scaled_X_test, train_y_PS, test_y_PS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier Scaled, tuned\n",
      "('Price Sensitivity Training: ', 0.60651436616113141)\n",
      "[[3134 3556  359  418]\n",
      " [1676 7661 1881  410]\n",
      " [ 266 3179 4231  260]\n",
      " [  69  180   44 3930]]\n",
      "('Price Sensitivity Testing: ', 0.603732736095558)\n",
      "[[1352 1525  163  182]\n",
      " [ 726 3269  796  184]\n",
      " [ 105 1374 1776   99]\n",
      " [  33  101   20 1690]]\n"
     ]
    }
   ],
   "source": [
    "scaled_ann_PS_2 = MLPClassifier(solver='sgd', alpha=0.0001, learning_rate_init=0.001, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(100,100,100), random_state=42, activation='logistic', max_iter=500) \n",
    "scaled_ann_PS_2 = MLPClassifier(solver='lbfgs', alpha=0.0001, hidden_layer_sizes=(100, 100), random_state=42, \n",
    "                                activation='logistic')\n",
    "scaled_ann_PS_2 = scaled_ann_PS_2.fit(scaled_X_train, train_y_PS)\n",
    "#record is .0606\n",
    "tryClassifier_PS (\"MLP Classifier Scaled, tuned\",scaled_ann_PS_2, scaled_X_train, scaled_X_test, train_y_PS, test_y_PS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample output:\n",
    "    MLP Classifier\n",
    "('Price Sensitivity Training: ', 0.5092788123120241)\n",
    "[[2191 5050  208   18]\n",
    " [1589 8793 1231   15]\n",
    " [ 272 5024 2627   13]\n",
    " [  59 1850    8 2306]]\n",
    "('Price Sensitivity Testing: ', 0.51325121313923106)\n",
    "[[ 947 2172   93   10]\n",
    " [ 670 3762  538    5]\n",
    " [ 121 2064 1167    2]\n",
    " [  25  814    6  999]]\n",
    "MLP Classifier Balanced\n",
    "('Price Sensitivity Training: ', 0.60448551919001647)\n",
    "[[2786  695  308  447]\n",
    " [1862 1186  859  321]\n",
    " [ 908  858 2220  302]\n",
    " [ 115   12   32 4077]]\n",
    "('Price Sensitivity Testing: ', 0.52541993281075028)\n",
    "[[2134  485  254  349]\n",
    " [2181 1390 1021  383]\n",
    " [ 709  679 1742  224]\n",
    " [  49    6   17 1772]]\n",
    "MLP Classifier Scaled\n",
    "('Price Sensitivity Training: ', 0.59982722211556916)\n",
    "[[3023 3711  295  438]\n",
    " [1649 7746 1804  429]\n",
    " [ 232 3375 4048  281]\n",
    " [  52  203   38 3930]]\n",
    "('Price Sensitivity Testing: ', 0.59977603583426653)\n",
    "[[1294 1596  138  194]\n",
    " [ 684 3335  763  193]\n",
    " [  91 1435 1718  110]\n",
    " [  29  106   22 1687]]\n",
    "MLP Classifier Balanced Scaled\n",
    "('Price Sensitivity Training: ', 0.66947256887214501)\n",
    "[[2612  912  408  304]\n",
    " [1186 1749 1085  208]\n",
    " [ 377  762 2964  185]\n",
    " [  95   21   72 4048]]\n",
    "('Price Sensitivity Testing: ', 0.58768197088465846)\n",
    "[[1951  718  313  240]\n",
    " [1429 1933 1358  255]\n",
    " [ 323  648 2239  144]\n",
    " [  42   12   41 1749]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LifeStage Training: ', 0.48803353170794139)\n",
      "[[  443     8  2599   224   183   266]\n",
      " [   48     3   867    21    68   248]\n",
      " [  551    12 13448   287   378   820]\n",
      " [  279     1  1805   242    58   118]\n",
      " [  244     9  3418    98   223   477]\n",
      " [  125    10  2539    80   160   894]]\n",
      "('LifeStage Testing: ', 0.48682344158268009)\n",
      "[[ 190    2 1134   93   87  130]\n",
      " [  13    0  362    7   34   85]\n",
      " [ 219    7 5734  138  158  374]\n",
      " [ 129    2  775  118   16   57]\n",
      " [ 102    4 1435   49  106  210]\n",
      " [  66    4 1078   31   73  373]]\n",
      "('LifeStage Training: ', 0.30006779661016947)\n",
      "[[217 174 280 199 146 208]\n",
      " [ 87 353 191  70 133 375]\n",
      " [101 127 657  79 108 178]\n",
      " [201 106 374 320  97 145]\n",
      " [114 219 329  85 196 294]\n",
      " [ 82 243 217  67 133 470]]\n",
      "('LifeStage Testing: ', 0.36677864874953342)\n",
      "[[ 277  225  391  284  184  275]\n",
      " [  37  138   95   26   45  160]\n",
      " [ 514  712 3379  432  526 1067]\n",
      " [ 167  122  337  256   89  126]\n",
      " [ 208  337  491  149  269  452]\n",
      " [ 103  321  317  105  185  594]]\n",
      "('LifeStage Training: ', 0.65879567415370832)\n",
      "[[ 1549    23  1604   264   181   102]\n",
      " [   67   277   556    10    77   268]\n",
      " [  360    39 13814   339   567   377]\n",
      " [  221     3  1015  1222    28    14]\n",
      " [  222    23  2312    45  1625   242]\n",
      " [  108    65  1285    31   216  2103]]\n",
      "('LifeStage Testing: ', 0.4870474057484136)\n",
      "[[ 282   23  896  195  125  115]\n",
      " [  33   19  273   10   56  110]\n",
      " [ 335   54 5167  221  448  405]\n",
      " [ 168    4  592  279   34   20]\n",
      " [ 174   26 1148   55  330  173]\n",
      " [ 105   54  799   30  190  447]]\n",
      "('LifeStage Training: ', 0.78481355932203389)\n",
      "[[ 940   34  109   74   50   17]\n",
      " [  40  975  107   13   36   38]\n",
      " [  42   27  972   67   98   44]\n",
      " [  46   18  144 1003   26    6]\n",
      " [  38   29  159   27  946   38]\n",
      " [  32   42  102   19   65  952]]\n",
      "('LifeStage Testing: ', 0.44471817842478539)\n",
      "[[ 593  185  213  288  219  138]\n",
      " [  19  308   62   17   48   47]\n",
      " [ 645  644 3126  666  946  603]\n",
      " [ 193   50  177  583   64   30]\n",
      " [ 236  236  352  139  706  237]\n",
      " [ 151  314  230   87  202  641]]\n"
     ]
    }
   ],
   "source": [
    "#requires sklearn 0.18\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler #from http://www.kdnuggets.com/2016/10/beginners-guide-neural-networks-python-scikit-learn.html/2\n",
    "\n",
    "scaler=StandardScaler()\n",
    "balanced_scaler=StandardScaler()\n",
    "\n",
    "scaler.fit(train_X)\n",
    "balanced_scaler.fit(balanced_LS_train_X)\n",
    "\n",
    "scaled_X_train=scaler.transform(train_X)\n",
    "scaled_X_test=scaler.transform(test_X)\n",
    "scaled_balanced_LS_X_train=balanced_scaler.transform(balanced_LS_train_X)\n",
    "scaled_balanced_LS_X_test=balanced_scaler.transform(test_X)\n",
    "\n",
    "ann_LS = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 100,100), random_state=42)\n",
    "balanced_ann_LS = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 100,100), random_state=42)\n",
    "scaled_ann_LS = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 100,100), random_state=42)\n",
    "scaled_balanced_ann_LS = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 100,100), random_state=42)\n",
    "#ann_LS = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "ann_LS = ann_LS.fit(train_X, train_y_LS)\n",
    "balanced_ann_LS = balanced_ann_LS.fit(balanced_LS_train_X, balanced_LS_train_y_LS)\n",
    "scaled_ann_LS = scaled_ann_LS.fit(scaled_X_train, train_y_LS)\n",
    "scaled_balanced_ann_LS = scaled_balanced_ann_LS.fit(scaled_balanced_LS_X_train, balanced_LS_train_y_LS)\n",
    "\n",
    "\n",
    "#ann_LS = ann_LS.fit(train_X, train_y_LS)\n",
    "\n",
    "tryClassifier_LS (\"MLP Classifier\",ann_LS, train_X, test_X, train_y_LS, test_y_LS)\n",
    "tryClassifier_LS (\"MLP Classifier Balanced\",balanced_ann_LS, balanced_LS_train_X, test_X, balanced_LS_train_y_LS, test_y_LS)\n",
    "tryClassifier_LS (\"MLP Classifier Scaled\",scaled_ann_LS, scaled_X_train, scaled_X_test, train_y_LS, test_y_LS)\n",
    "tryClassifier_LS (\"MLP Classifier Balanced Scaled\",scaled_balanced_ann_LS, scaled_balanced_LS_X_train, scaled_balanced_LS_X_test, balanced_LS_train_y_LS, test_y_LS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample output\n",
    "('LifeStage Training: ', 0.48803353170794139)\n",
    "[[  443     8  2599   224   183   266]\n",
    " [   48     3   867    21    68   248]\n",
    " [  551    12 13448   287   378   820]\n",
    " [  279     1  1805   242    58   118]\n",
    " [  244     9  3418    98   223   477]\n",
    " [  125    10  2539    80   160   894]]\n",
    "('LifeStage Testing: ', 0.48682344158268009)\n",
    "[[ 190    2 1134   93   87  130]\n",
    " [  13    0  362    7   34   85]\n",
    " [ 219    7 5734  138  158  374]\n",
    " [ 129    2  775  118   16   57]\n",
    " [ 102    4 1435   49  106  210]\n",
    " [  66    4 1078   31   73  373]]\n",
    "('LifeStage Training: ', 0.30006779661016947)\n",
    "[[217 174 280 199 146 208]\n",
    " [ 87 353 191  70 133 375]\n",
    " [101 127 657  79 108 178]\n",
    " [201 106 374 320  97 145]\n",
    " [114 219 329  85 196 294]\n",
    " [ 82 243 217  67 133 470]]\n",
    "('LifeStage Testing: ', 0.36677864874953342)\n",
    "[[ 277  225  391  284  184  275]\n",
    " [  37  138   95   26   45  160]\n",
    " [ 514  712 3379  432  526 1067]\n",
    " [ 167  122  337  256   89  126]\n",
    " [ 208  337  491  149  269  452]\n",
    " [ 103  321  317  105  185  594]]\n",
    "('LifeStage Training: ', 0.65879567415370832)\n",
    "[[ 1549    23  1604   264   181   102]\n",
    " [   67   277   556    10    77   268]\n",
    " [  360    39 13814   339   567   377]\n",
    " [  221     3  1015  1222    28    14]\n",
    " [  222    23  2312    45  1625   242]\n",
    " [  108    65  1285    31   216  2103]]\n",
    "('LifeStage Testing: ', 0.4870474057484136)\n",
    "[[ 282   23  896  195  125  115]\n",
    " [  33   19  273   10   56  110]\n",
    " [ 335   54 5167  221  448  405]\n",
    " [ 168    4  592  279   34   20]\n",
    " [ 174   26 1148   55  330  173]\n",
    " [ 105   54  799   30  190  447]]\n",
    "('LifeStage Training: ', 0.78481355932203389)\n",
    "[[ 940   34  109   74   50   17]\n",
    " [  40  975  107   13   36   38]\n",
    " [  42   27  972   67   98   44]\n",
    " [  46   18  144 1003   26    6]\n",
    " [  38   29  159   27  946   38]\n",
    " [  32   42  102   19   65  952]]\n",
    "('LifeStage Testing: ', 0.44471817842478539)\n",
    "[[ 593  185  213  288  219  138]\n",
    " [  19  308   62   17   48   47]\n",
    " [ 645  644 3126  666  946  603]\n",
    " [ 193   50  177  583   64   30]\n",
    " [ 236  236  352  139  706  237]\n",
    " [ 151  314  230   87  202  641]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier - PS Balanced\n",
      "('Price Sensitivity Training: ', 0.59177066164351311)\n",
      "[[1736 1230 1186   84]\n",
      " [ 946 1327 1883   72]\n",
      " [ 478  769 2982   59]\n",
      " [  83   60   85 4008]]\n",
      "('Price Sensitivity Testing: ', 0.49779768570362076)\n",
      "[[1255  977  904   86]\n",
      " [1139 1473 2244  119]\n",
      " [ 396  664 2233   61]\n",
      " [  53   32   52 1707]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#ada_PS = AdaBoostClassifier(n_estimators=1000)\n",
    "balanced_ada_PS = AdaBoostClassifier(n_estimators=10000)\n",
    "#ada_LS = AdaBoostClassifier(n_estimators=1000)\n",
    "\n",
    "#ada_PS = ada_PS.fit(train_X, train_y_PS)\n",
    "balanced_ada_PS = balanced_ada_PS.fit(balanced_PS_train_X, balanced_PS_train_y_PS)\n",
    "#ada_LS = ada_LS.fit(train_X, train_y_LS)\n",
    "\n",
    "\n",
    "#tryClassifier_PS (\"AdaBoost Classifier - PS Unbalanced\",ada_PS, train_X, test_X, train_y_PS, test_y_PS)\n",
    "tryClassifier_PS (\"AdaBoost Classifier - PS Balanced\",balanced_ada_PS, balanced_PS_train_X, test_X, balanced_PS_train_y_PS, test_y_PS)\n",
    "#tryClassifier_LS (\"AdaBoost Classifier - LS Unbalanced\",ada_LS, train_X, test_X, train_y_LS, test_y_LS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Sample Output:\n",
    "    AdaBoost Classifier - PS Balanced\n",
    "('Price Sensitivity Training: ', 0.59177066164351311)\n",
    "[[1736 1230 1186   84]\n",
    " [ 946 1327 1883   72]\n",
    " [ 478  769 2982   59]\n",
    " [  83   60   85 4008]]\n",
    "('Price Sensitivity Testing: ', 0.49779768570362076)\n",
    "[[1255  977  904   86]\n",
    " [1139 1473 2244  119]\n",
    " [ 396  664 2233   61]\n",
    " [  53   32   52 1707]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LifeStage Training: ', 0.40461016949152545)\n",
      "[[380 162 109 308 118 147]\n",
      " [ 89 518  90  46 151 315]\n",
      " [117 200 470 182 134 147]\n",
      " [185  44  82 806  67  59]\n",
      " [164 285 125  91 320 252]\n",
      " [ 84 390  82  50 116 490]]\n",
      "('LifeStage Testing: ', 0.31295259425158639)\n",
      "[[ 421  229  155  421  198  212]\n",
      " [  39  201   48   27   59  127]\n",
      " [ 649 1169 1938 1034  845  995]\n",
      " [ 187   44  104  638   68   56]\n",
      " [ 254  458  207  169  413  405]\n",
      " [ 144  500  140   77  183  581]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#ada_LS = AdaBoostClassifier(n_estimators=1000)\n",
    "balanced_ada_LS = AdaBoostClassifier(n_estimators=10000)\n",
    "#ada_LS = AdaBoostClassifier(n_estimators=1000)\n",
    "\n",
    "#ada_LS = ada_LS.fit(train_X, train_y_LS)\n",
    "balanced_ada_LS = balanced_ada_LS.fit(balanced_LS_train_X, balanced_LS_train_y_LS)\n",
    "#ada_LS = ada_LS.fit(train_X, train_y_LS)\n",
    "\n",
    "\n",
    "#tryClassifier_LS (\"AdaBoost Classifier - LS Unbalanced\",ada_LS, train_X, test_X, train_y_LS, test_y_LS)\n",
    "tryClassifier_LS (\"AdaBoost Classifier - LS Balanced\",balanced_ada_LS, balanced_LS_train_X, test_X, balanced_LS_train_y_LS, test_y_LS)\n",
    "#tryClassifier_LS (\"AdaBoost Classifier - LS Unbalanced\",ada_LS, train_X, test_X, train_y_LS, test_y_LS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# initial result summary\n",
    "For PS, it seems that random forest has the highest accuracy, so we can do a grid-search around it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "('Price Sensitivity Training: ', 1.0)\n",
      "[[4236    0    0    0]\n",
      " [   0 4228    0    0]\n",
      " [   0    0 4288    0]\n",
      " [   0    0    0 4236]]\n",
      "('Price Sensitivity Testing: ', 0.71556550951847708)\n",
      "[[2486  362  222  152]\n",
      " [1134 2533 1090  218]\n",
      " [ 197  308 2739  110]\n",
      " [   9    1    7 1827]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'grid_rfc_ps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-fd6d1aa0e408>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mgrid_balanced_rfc_ps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mtryClassifier_PS\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Random Forest\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_balanced_rfc_ps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbalanced_PS_train_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbalanced_PS_train_y_PS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y_PS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_rfc_ps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[1;31m#grid_rfc_ls.best_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_rfc_ps' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "params = {'n_estimators': [1000,3000,5000], 'max_features': [5,10,15]} #, 'random_state':42, 'criterion':\"entropy\"\n",
    "\n",
    "#rfc_ps=RandomForestClassifier()\n",
    "rfc_balanced_ps=RandomForestClassifier()\n",
    "\n",
    "#rfc_ls=RandomForestClassifier()\n",
    "\n",
    "#grid_rfc_ps = GridSearchCV(estimator=rfc_ps, param_grid=params)\n",
    "grid_balanced_rfc_ps = GridSearchCV(estimator=rfc_balanced_ps, param_grid=params)\n",
    "#grid_rfc_ls = GridSearchCV(estimator=rfc_ls, param_grid=params)\n",
    "\n",
    "# Fit the grid search object to the data to compute the optimal model\n",
    "#grid_rfc_ps = grid_rfc_ps.fit(train_X, train_y_PS)\n",
    "grid_balanced_rfc_ps = grid_balanced_rfc_ps.fit(balanced_PS_train_X, balanced_PS_train_y_PS)\n",
    "#grid_rfc_ls = grid_rfc_ls.fit(train_X, train_y_LS)\n",
    "\n",
    "# Return the optimal model after fitting the data\n",
    "#grid_rfc_ps.best_estimator_\n",
    "#tryClassifier_PS (\"Random Forest\", grid_rfc_ps, train_X, test_X, train_y_PS, test_y_PS)\n",
    "\n",
    "\n",
    "tryClassifier_PS (\"Random Forest\", grid_balanced_rfc_ps, balanced_PS_train_X, test_X, balanced_PS_train_y_PS, test_y_PS)\n",
    "#print(grid_rfc_ps.best_params_)\n",
    "\n",
    "#grid_rfc_ls.best_estimator_\n",
    "\n",
    "#tryClassifier_LS (\"Random Forest\", rfc_balanced_ls, balanced_LS_train_X, balanced_LS_test_X, balanced_LS_train_y_LS, balanced_LS_test_y_LS)\n",
    "print(grid_balanced_rfc_ps.best_estimator_)\n",
    "print(grid_balanced_rfc_ps.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##sample output\n",
    "Random Forest\n",
    "('Price Sensitivity Training: ', 1.0)\n",
    "[[4236    0    0    0]\n",
    " [   0 4228    0    0]\n",
    " [   0    0 4288    0]\n",
    " [   0    0    0 4236]]\n",
    "('Price Sensitivity Testing: ', 0.71601343784994398)\n",
    "[[2492  358  224  148]\n",
    " [1115 2566 1075  219]\n",
    " [ 193  350 2705  106]\n",
    " [   7    2    7 1828]]\n",
    "{'max_features': 5, 'n_estimators': 500}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier, GridSearch\n",
      "('Price Sensitivity Training: ', 0.838650812338121)\n",
      "[[3551  343  231  111]\n",
      " [ 601 2971  540  116]\n",
      " [ 240  391 3550  107]\n",
      " [  31   10   20 4175]]\n",
      "('Price Sensitivity Testing: ', 0.66629339305711088)\n",
      "[[2278  557  245  142]\n",
      " [1244 2399 1151  181]\n",
      " [ 282  529 2450   93]\n",
      " [  21    8   17 1798]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'grid_balanced_rfc_ps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-dd70c09db2d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mgrid_balanced_gbc_ps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_balanced_gbc_ps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbalanced_PS_train_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbalanced_PS_train_y_PS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtryClassifier_PS\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Gradient Boosting Classifier, GridSearch\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_balanced_gbc_ps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbalanced_PS_train_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbalanced_PS_train_y_PS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y_PS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_balanced_rfc_ps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_balanced_rfc_ps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_balanced_rfc_ps' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "params = {'learning_rate': [0.01,0.05,0.1], 'n_estimators': [500,1000,3000], 'max_depth':[5,10,15]} \n",
    "balanced_gbc_ps=GradientBoostingClassifier()\n",
    "grid_balanced_gbc_ps = GridSearchCV(estimator=balanced_gbc_ps, param_grid=params)\n",
    "grid_balanced_gbc_ps = grid_balanced_gbc_ps.fit(balanced_PS_train_X, balanced_PS_train_y_PS)\n",
    "tryClassifier_PS (\"Gradient Boosting Classifier, GridSearch\", grid_balanced_gbc_ps, balanced_PS_train_X, test_X, balanced_PS_train_y_PS, test_y_PS)\n",
    "\n",
    "print(grid_balanced_gbc_ps.best_estimator_)\n",
    "print(grid_balanced_gbc_ps.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample output:\n",
    "Gradient Boosting Classifier, GridSearch\n",
    "('Price Sensitivity Training: ', 0.838650812338121)\n",
    "[[3551  343  231  111]\n",
    " [ 601 2971  540  116]\n",
    " [ 240  391 3550  107]\n",
    " [  31   10   20 4175]]\n",
    "('Price Sensitivity Testing: ', 0.66629339305711088)\n",
    "[[2278  557  245  142]\n",
    " [1244 2399 1151  181]\n",
    " [ 282  529 2450   93]\n",
    " [  21    8   17 1798]]\n",
    "\n",
    "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
    "              learning_rate=0.01, loss='deviance', max_depth=5,\n",
    "              max_features=None, max_leaf_nodes=None,\n",
    "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "              n_estimators=1000, presort='auto', random_state=None,\n",
    "              subsample=1.0, verbose=0, warm_start=False)\n",
    "{'n_estimators': 1000, 'learning_rate': 0.01, 'max_depth': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LifeStage Training: ', 0.53561144173545783)\n",
      "[[  628     0  2332   469   129   165]\n",
      " [   53     0   789     7    30   376]\n",
      " [  475     0 13352   435   310   924]\n",
      " [  272     0  1335   860    21    15]\n",
      " [  202     0  3349    99   393   426]\n",
      " [  116     0  2058    45    82  1507]]\n",
      "('LifeStage Testing: ', 0.3384098544232923)\n",
      "[[ 128    0 1162  268    4   74]\n",
      " [  89    0  338   12    2   60]\n",
      " [1024    0 3926  514   36 1130]\n",
      " [  65    0  743  253    1   35]\n",
      " [ 251    0 1272  131    9  243]\n",
      " [ 248    0 1094   61    5  217]]\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(10, 10), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "{'alpha': 1e-05, 'solver': 'lbfgs', 'random_state': 42, 'hidden_layer_sizes': (10, 10)}\n",
      "{'rank_test_score': array([6, 3, 1, 5, 2, 4]), 'split6_test_score': array([ 0.49231754,  0.52400768,  0.51920615,  0.48783611,  0.52496799,\n",
      "        0.51696543]), 'split7_train_score': array([ 0.68602915,  0.53430501,  0.53348738,  0.6883754 ,  0.53274085,\n",
      "        0.53380732]), 'split0_train_score': array([ 0.69263315,  0.5364787 ,  0.53263884,  0.68424234,  0.53558985,\n",
      "        0.53246107]), 'split2_test_score': array([ 0.4766624 ,  0.50639386,  0.50543478,  0.48369565,  0.50767263,\n",
      "        0.50575448]), 'param_solver': masked_array(data = ['lbfgs' 'lbfgs' 'lbfgs' 'lbfgs' 'lbfgs' 'lbfgs'],\n",
      "             mask = [False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'mean_fit_time': array([ 56.84059997,   5.7680001 ,   6.55530005,  54.18259995,\n",
      "         5.15699999,   6.37349999]), 'split3_train_score': array([ 0.67694113,  0.53580063,  0.53494738,  0.6804252 ,  0.5353029 ,\n",
      "        0.53647611]), 'split6_train_score': array([ 0.6792748 ,  0.5394952 ,  0.53540704,  0.69225027,  0.53906861,\n",
      "        0.53679346]), 'split9_test_score': array([ 0.48142217,  0.50928892,  0.51121076,  0.48750801,  0.5128123 ,\n",
      "        0.50992953]), 'std_test_score': array([ 0.00604433,  0.00622338,  0.00645756,  0.00520804,  0.00583122,\n",
      "        0.00653962]), 'param_hidden_layer_sizes': masked_array(data = [(100, 100, 100) 10 (10, 10) (100, 100, 100) 10 (10, 10)],\n",
      "             mask = [False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'params': ({'alpha': 1e-05, 'solver': 'lbfgs', 'random_state': 42, 'hidden_layer_sizes': (100, 100, 100)}, {'alpha': 1e-05, 'solver': 'lbfgs', 'random_state': 42, 'hidden_layer_sizes': 10}, {'alpha': 1e-05, 'solver': 'lbfgs', 'random_state': 42, 'hidden_layer_sizes': (10, 10)}, {'alpha': 0.0005, 'solver': 'lbfgs', 'random_state': 42, 'hidden_layer_sizes': (100, 100, 100)}, {'alpha': 0.0005, 'solver': 'lbfgs', 'random_state': 42, 'hidden_layer_sizes': 10}, {'alpha': 0.0005, 'solver': 'lbfgs', 'random_state': 42, 'hidden_layer_sizes': (10, 10)}), 'split8_test_score': array([ 0.48735191,  0.51552994,  0.51585014,  0.4870317 ,  0.51488953,\n",
      "        0.51424912]), 'std_score_time': array([ 0.04450662,  0.00241657,  0.00048987,  0.01181909,  0.00080001,\n",
      "        0.00030003]), 'std_fit_time': array([ 3.50003391,  1.27689371,  0.50582743,  3.03409747,  0.41147194,\n",
      "        0.64527611]), 'std_train_score': array([ 0.00639295,  0.0014219 ,  0.00176295,  0.0068687 ,  0.00180359,\n",
      "        0.00159592]), 'split4_test_score': array([ 0.47728727,  0.51695457,  0.52207294,  0.47216891,  0.51631478,\n",
      "        0.52111324]), 'split1_train_score': array([ 0.67741591,  0.53608761,  0.53711868,  0.67510489,  0.53359881,\n",
      "        0.53594539]), 'split2_train_score': array([ 0.68075802,  0.53448766,  0.53800754,  0.67809145,  0.53388324,\n",
      "        0.5364787 ]), 'split4_train_score': array([ 0.68159841,  0.53686718,  0.53519625,  0.68316268,  0.53512514,\n",
      "        0.53526735]), 'mean_score_time': array([ 0.03060005,  0.00559998,  0.00439997,  0.01910005,  0.00459998,\n",
      "        0.00410001]), 'split9_train_score': array([ 0.68889521,  0.53590218,  0.53462249,  0.67233044,  0.53767951,\n",
      "        0.53579554]), 'split5_test_score': array([ 0.49216,  0.52384,  0.5216 ,  0.48384,  0.5216 ,  0.52576]), 'param_random_state': masked_array(data = [42 42 42 42 42 42],\n",
      "             mask = [False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'mean_train_score': array([ 0.68426078,  0.53595628,  0.53566123,  0.68373813,  0.53522032,\n",
      "        0.53574294]), 'split8_train_score': array([ 0.68198784,  0.53528136,  0.5372365 ,  0.69048381,  0.53492588,\n",
      "        0.53865842]), 'split7_test_score': array([ 0.47919334,  0.51984635,  0.51760563,  0.49231754,  0.52304738,\n",
      "        0.51600512]), 'split0_test_score': array([ 0.49360614,  0.52141944,  0.53005115,  0.49040921,  0.52078005,\n",
      "        0.5230179 ]), 'mean_test_score': array([ 0.48492993,  0.51577398,  0.51702182,  0.48560184,  0.51631791,\n",
      "        0.51507007]), 'split3_test_score': array([ 0.48304543,  0.50767754,  0.51247601,  0.48400512,  0.50767754,\n",
      "        0.50575816]), 'split5_train_score': array([ 0.69707419,  0.53485726,  0.53795016,  0.69291479,  0.53428846,\n",
      "        0.53574603]), 'param_alpha': masked_array(data = [1e-05 1e-05 1e-05 0.0005 0.0005 0.0005],\n",
      "             mask = [False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'split1_test_score': array([ 0.4862532 ,  0.51278772,  0.51470588,  0.48721228,  0.51342711,\n",
      "        0.51214834])}\n"
     ]
    }
   ],
   "source": [
    "#requires sklearn 0.18\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler #from http://www.kdnuggets.com/2016/10/beginners-guide-neural-networks-python-scikit-learn.html/2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(train_X)\n",
    "\n",
    "scaled_X_train=scaler.transform(train_X)\n",
    "scaled_X_test=scaler.transform(test_X)\n",
    "\n",
    "#params = {'learning_rate': [0.01,0.05,0.1], 'n_estimators': [500,1000,3000], 'max_depth':[5,10,15]} \n",
    "\n",
    "params = {'solver':[\"lbfgs\"], 'alpha':[0.00001, 0.0005], 'hidden_layer_sizes':[(100, 100,100),(10), (10,10)], 'random_state':[42]}\n",
    "scaled_ann_LS=MLPClassifier()\n",
    "\n",
    "grid_scaled_ann_LS = GridSearchCV(estimator=scaled_ann_LS, param_grid=params, n_jobs=2,cv=10)\n",
    "grid_scaled_ann_LS = grid_scaled_ann_LS.fit(scaled_X_train, train_y_LS)\n",
    "\n",
    "#scaled_ann_LS = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 100,100), random_state=42)\n",
    "\n",
    "\n",
    "tryClassifier_LS (\"MLP Classifier Scaled, GridSearch\", grid_scaled_ann_LS, scaled_X_train, test_X, train_y_LS, test_y_LS)\n",
    "\n",
    "print(grid_scaled_ann_LS.best_estimator_)\n",
    "print(grid_scaled_ann_LS.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LifeStage Training: ', 0.52201318231266403)\n",
      "[[  470     0  2667   357    58   171]\n",
      " [   39     0   848     5    23   340]\n",
      " [  388     0 13693   358   171   886]\n",
      " [  287     0  1612   579     4    21]\n",
      " [  175     0  3616    65   202   411]\n",
      " [   69     0  2286    30    52  1371]]\n",
      "('LifeStage Testing: ', 0.51086226203807394)\n",
      "[[ 190    0 1191  150   29   76]\n",
      " [  15    0  335    5    6  140]\n",
      " [ 186    0 5815  145   89  395]\n",
      " [ 149    0  708  227    5    8]\n",
      " [  78    0 1493   56   97  182]\n",
      " [  37    0 1039   15   20  514]]\n"
     ]
    }
   ],
   "source": [
    "#requires sklearn 0.18\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler #from http://www.kdnuggets.com/2016/10/beginners-guide-neural-networks-python-scikit-learn.html/2\n",
    "\n",
    "scaler=StandardScaler()\n",
    "\n",
    "scaler.fit(train_X)\n",
    "\n",
    "scaled_X_train=scaler.transform(train_X)\n",
    "scaled_X_test=scaler.transform(test_X)\n",
    "\n",
    "scaled_ann_LS = MLPClassifier(solver='sgd', alpha=0.0001, learning_rate_init=0.001, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(100,10), random_state=43, activation='logistic', max_iter=5000,\n",
    "                             )\n",
    "scaled_ann_LS = scaled_ann_LS.fit(scaled_X_train, train_y_LS)\n",
    "\n",
    "\n",
    "tryClassifier_LS (\"MLP Classifier Scaled\",scaled_ann_LS, scaled_X_train, scaled_X_test, train_y_LS, test_y_LS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaled_ann_LS = MLPClassifier(solver='lbfgs', alpha=0.0001, learning_rate_init=0.001, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(200,200), random_state=42) = .469\n",
    "scaled_ann_LS = MLPClassifier(solver='lbfgs', alpha=0.0001, learning_rate_init=0.01, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(200,200), random_state=42) = .469\n",
    "scaled_ann_LS = MLPClassifier(solver='sgd', alpha=0.0001, learning_rate_init=0.001, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(200,200), random_state=42) = .497, needs more iterations\n",
    "scaled_ann_LS = MLPClassifier(solver='sgd', alpha=0.0001, learning_rate_init=0.01, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(200,200), random_state=42) = 0.447\n",
    "scaled_ann_LS = MLPClassifier(solver='sgd', alpha=0.0001, learning_rate_init=0.001, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(200,200), random_state=42, activation='logistic') = 0.508\n",
    "scaled_ann_LS = MLPClassifier(solver='sgd', alpha=0.0001, learning_rate_init=0.001, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(200,200), random_state=42, activation='logistic', max_iter=500) = 0.511\n",
    "scaled_ann_LS = MLPClassifier(solver='sgd', alpha=0.0001, learning_rate_init=0.001, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(200,200), random_state=42, activation='logistic', max_iter=1000) = 0.511\n",
    "scaled_ann_LS = MLPClassifier(solver='sgd', alpha=0.0001, learning_rate_init=0.001, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(20,20), random_state=42, activation='logistic', max_iter=500) = 0.508\n",
    "scaled_ann_LS = scaled_ann_LS.fit(scaled_X_train, balanced_LS_train_y_LS) = 0.471\n",
    "scaled_ann_LS = MLPClassifier(solver='adam', alpha=0.0001, learning_rate_init=0.001, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(200,200), random_state=42, activation='logistic', max_iter=500)=0.480\n",
    "scaled_ann_LS = MLPClassifier(solver='adam', alpha=0.0001, learning_rate_init=0.001, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(200,200), random_state=42, activation='tanh', max_iter=500)=0.485\n",
    "scaled_ann_LS = scaled_ann_LS.fit(scaled_X_train, upsampled_LS_train_y_LS) = 0.473\n",
    "scaled_ann_LS = MLPClassifier(solver='sgd', alpha=0.0001, learning_rate_init=0.001, learning_rate='adaptive',\n",
    "                              hidden_layer_sizes=(200,200), random_state=42, activation='logistic', max_iter=500) = 0.510\n",
    "scaled_ann_LS = MLPClassifier(solver='sgd', alpha=0.0001, learning_rate_init=0.0001, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(200,200), random_state=42, activation='logistic', max_iter=1000) = 0.498\n",
    "scaled_ann_LS = MLPClassifier(solver='sgd', alpha=0.0001, learning_rate_init=0.001, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(100,10), random_state=42, activation='logistic', max_iter=5000) = 0.512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LifeStage Training: ', 0.99910411467332183)\n",
      "[[ 3717     0     6     0     0     0]\n",
      " [    0  1253     2     0     0     0]\n",
      " [    0     0 15496     0     0     0]\n",
      " [    0     0     3  2500     0     0]\n",
      " [    0     0    12     0  4457     0]\n",
      " [    0     0     5     0     0  3803]]\n",
      "('LifeStage Testing: ', 0.51131019036954084)\n",
      "[[  60    0 1455   53    3   65]\n",
      " [   1    0  366    2    0  132]\n",
      " [  58    1 6182   67    9  313]\n",
      " [  71    0  887  130    0    9]\n",
      " [  28    0 1709   10    7  152]\n",
      " [   8    0 1136    9    2  470]]\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features=15, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=5000, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "{'max_features': 15, 'n_estimators': 5000, 'random_state': 42, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "params = {'n_estimators': [1000,3000,5000], 'max_features': [5,10,15], 'random_state':[42], 'criterion':[\"entropy\"]}\n",
    "\n",
    "rfc_LS=RandomForestClassifier()\n",
    "\n",
    "grid_rfc_LS = GridSearchCV(estimator=rfc_LS, param_grid=params, n_jobs=2,cv=10)\n",
    "\n",
    "# Fit the grid search object to the data to compute the optimal model\n",
    "grid_rfc_LS = grid_rfc_LS.fit(train_X, train_y_LS)\n",
    "\n",
    "tryClassifier_LS (\"Random Forest, Grid\", grid_rfc_LS, train_X, test_X, train_y_LS, test_y_LS)\n",
    "\n",
    "print(grid_rfc_LS.best_estimator_)\n",
    "print(grid_rfc_LS.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample output:\n",
    "    ('LifeStage Training: ', 0.99910411467332183)\n",
    "[[ 3717     0     6     0     0     0]\n",
    " [    0  1253     2     0     0     0]\n",
    " [    0     0 15496     0     0     0]\n",
    " [    0     0     3  2500     0     0]\n",
    " [    0     0    12     0  4457     0]\n",
    " [    0     0     5     0     0  3803]]\n",
    "('LifeStage Testing: ', 0.51131019036954084)\n",
    "[[  60    0 1455   53    3   65]\n",
    " [   1    0  366    2    0  132]\n",
    " [  58    1 6182   67    9  313]\n",
    " [  71    0  887  130    0    9]\n",
    " [  28    0 1709   10    7  152]\n",
    " [   8    0 1136    9    2  470]]\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "            max_depth=None, max_features=15, max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=5000, n_jobs=1, oob_score=False, random_state=42,\n",
    "            verbose=0, warm_start=False)\n",
    "{'max_features': 15, 'n_estimators': 5000, 'random_state': 42, 'criterion': 'entropy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#random useful code snippets\n",
    "list(data.columns.values)\n",
    "data['SPEND'].dtype\n",
    "data_cross.head(10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
