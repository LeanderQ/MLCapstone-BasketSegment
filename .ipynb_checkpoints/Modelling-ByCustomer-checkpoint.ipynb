{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# This notebook is used for intial data exploration for the capstone project\n",
    "##########################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 0.18.1.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "# All code tested on 0.18.1, which is needed for sklearn.neural_network/MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "\n",
    "\n",
    "#data = pd.read_csv('data/transactions_200607.csv')  #import one file\n",
    "\n",
    "#import all csvs (courtesy of http://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe)\n",
    "\n",
    "path =r'data' # use your path\n",
    "allFiles = glob.glob(path + \"/tr*.csv\")\n",
    "\n",
    "#print allFiles\n",
    "data = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0)\n",
    "    list_.append(df)\n",
    "data = pd.concat(list_)\n",
    "\n",
    "#print(data.head(20))\n",
    "\n",
    "\n",
    "print('Before DropNA',len(data))\n",
    "data=data.dropna()\n",
    "print('After DropNA',len(data))\n",
    "\n",
    "#consider dropping these categories, but will try with them first.\n",
    "\n",
    "#data = data[data.CUST_PRICE_SENSITIVITY != 'XX']\n",
    "#data = data[data.CUST_LIFESTAGE != 'OT']\n",
    "#print('After Uninteresting categories',len(data))\n",
    "#list(data.columns.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Reformat the data into a wide dataset using Prod_code_20 as the lowest level of aggregation.  This is as recommended by Apeh et al. in Customer Profile Classification Using Transactional Data (https://core.ac.uk/download/pdf/4899037.pdf).  Then, to predict the basket, we just apply the value for the predicted customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create customerprofiles.  Simplest version will be to sum spend in each category in PROD_CODE_20, keeping the target variable as well\n",
    "#pivot code from http://stackoverflow.com/questions/41046766/using-and-graphing-the-results-of-a-crosstab-dataframe-in-python\n",
    "\n",
    "data_cross=data.pivot_table(index='CUST_CODE', columns='PROD_CODE_20', values='SPEND', aggfunc=np.sum, fill_value=0)\n",
    "data_cross.reset_index(level=['CUST_CODE'], inplace=True)\n",
    "\n",
    "#group the variables that are unique to each basket\n",
    "byCustomer=data.groupby(['CUST_CODE'])\n",
    "targetsByCustomer=pd.DataFrame(byCustomer['CUST_LIFESTAGE', 'CUST_PRICE_SENSITIVITY'].first())\n",
    "targetsByCustomer.reset_index(level=['CUST_CODE'], inplace=True)\n",
    "\n",
    "sumsByCustomer=pd.DataFrame(byCustomer['SPEND'].sum())\n",
    "sumsByCustomer.reset_index(level=['CUST_CODE'], inplace=True)\n",
    "\n",
    "data_cross_day=data.pivot_table(index='CUST_CODE', columns='SHOP_WEEKDAY', values='SPEND', aggfunc=np.sum, fill_value=0)\n",
    "data_cross_day.reset_index(level=['CUST_CODE'], inplace=True)\n",
    "data_cross_hour=data.pivot_table(index='CUST_CODE', columns='SHOP_HOUR', values='SPEND', aggfunc=np.sum, fill_value=0)\n",
    "data_cross_hour.reset_index(level=['CUST_CODE'], inplace=True)\n",
    "data_cross_basketsize = data.pivot_table(index='CUST_CODE', columns='BASKET_SIZE', values='SPEND', aggfunc=len, fill_value=0)\n",
    "data_cross_basketsize.reset_index(level=['CUST_CODE'], inplace=True)\n",
    "data_cross_baskettype = data.pivot_table(index='CUST_CODE', columns='BASKET_TYPE', values='SPEND', aggfunc=len, fill_value=0)\n",
    "data_cross_baskettype.reset_index(level=['CUST_CODE'], inplace=True)\n",
    "\n",
    "\n",
    "data_cross = pd.merge(data_cross, data_cross_day, how='inner', on = 'CUST_CODE')\n",
    "data_cross = pd.merge(data_cross, data_cross_hour, how='inner', on = 'CUST_CODE')\n",
    "data_cross = pd.merge(data_cross, data_cross_basketsize, how='inner', on = 'CUST_CODE')\n",
    "data_cross = pd.merge(data_cross, data_cross_baskettype, how='inner', on = 'CUST_CODE')\n",
    "\n",
    "data_cross = pd.merge(data_cross, sumsByCustomer, how='inner', on = 'CUST_CODE')\n",
    "data_cross = pd.merge(data_cross, targetsByCustomer, how='inner', on = 'CUST_CODE')\n",
    "\n",
    "#reset the index to what it should be for the rest of the analysis\n",
    "data_cross.set_index(['CUST_CODE'], inplace=True)\n",
    "\n",
    "print(data_cross.head(5))\n",
    "#list(data_cross.columns.values)\n",
    "#print(data_cross.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data_cross_day.head())\n",
    "print(data_cross_basketsize.head())\n",
    "print(data_cross_baskettype.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  #http://pandas.pydata.org/pandas-docs/stable/visualization.html\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel('# Customers')\n",
    "#http://pbpython.com/simple-graphing-pandas.html\n",
    "    \n",
    "#plt.subplot(211)  \n",
    "plt.suptitle('Life Stage Class Distribution')\n",
    "lsPlot = data_cross.groupby(['CUST_LIFESTAGE'])['SPEND'].count().plot(kind='bar')\n",
    "#plt.subplot(212)  \n",
    "\n",
    "#plt.suptitle('Price Sensitivity Class Distribution')\n",
    "#psPlot = data_cross.groupby(['CUST_PRICE_SENSITIVITY'])['SPEND'].count().plot(kind='bar')\n",
    "\n",
    "plt.xlabel('Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create the training, testing split.  can't use sklearn.cross_validation.train_test_split since I have two targets\n",
    "# could probably consider stratified sampling here\n",
    "\n",
    "#first do a 70-30 split.  \n",
    "train_X=data_cross.sample(frac=0.7,random_state=42)\n",
    "test_X=data_cross.drop(train_X.index)\n",
    "\n",
    "#pop off the classifiers\n",
    "train_y = train_X[[\"CUST_LIFESTAGE\",\"CUST_PRICE_SENSITIVITY\"]] #potentially for use in multi-output decision trees\n",
    "train_y_LS = train_X.pop(\"CUST_LIFESTAGE\")\n",
    "train_y_PS = train_X.pop(\"CUST_PRICE_SENSITIVITY\")\n",
    "\n",
    "test_y = test_X[[\"CUST_LIFESTAGE\",\"CUST_PRICE_SENSITIVITY\"]] #potentially for use in multi-output decision trees\n",
    "test_y_LS = test_X.pop(\"CUST_LIFESTAGE\")\n",
    "test_y_PS = test_X.pop(\"CUST_PRICE_SENSITIVITY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Downsample the training so all strata are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#based on  https://www.datarobot.com/blog/classification-with-scikit-learn/\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "#create a copy:\n",
    "data_cross_for_balanced_PS = data_cross\n",
    "data_cross_for_balanced_LS = data_cross\n",
    "\n",
    "#first do a 70-30 split.  \n",
    "balanced_PS_train_X=data_cross_for_balanced_PS.sample(frac=0.7,random_state=42)\n",
    "balanced_PS_test_X=data_cross_for_balanced_PS.drop(balanced_PS_train_X.index)\n",
    "\n",
    "#downsample the training data\n",
    "print(balanced_PS_train_X.groupby(['CUST_PRICE_SENSITIVITY'])['SPEND'].count())\n",
    "min_count_PS = min(balanced_PS_train_X.groupby(['CUST_PRICE_SENSITIVITY'])['SPEND'].count())\n",
    "print (min_count_PS)\n",
    "indices_LA = np.where(balanced_PS_train_X.CUST_PRICE_SENSITIVITY == 'LA')[0]\n",
    "rng.shuffle(indices_LA)\n",
    "balanced_PS_train_X = balanced_PS_train_X.drop(balanced_PS_train_X.index[indices_LA[min_count_PS:]])\n",
    "\n",
    "indices_MM = np.where(balanced_PS_train_X.CUST_PRICE_SENSITIVITY == 'MM')[0]\n",
    "rng.shuffle(indices_MM)\n",
    "balanced_PS_train_X = balanced_PS_train_X.drop(balanced_PS_train_X.index[indices_MM[min_count_PS:]])\n",
    "\n",
    "indices_UM = np.where(balanced_PS_train_X.CUST_PRICE_SENSITIVITY == 'UM')[0]\n",
    "rng.shuffle(indices_UM)\n",
    "balanced_PS_train_X = balanced_PS_train_X.drop(balanced_PS_train_X.index[indices_UM[min_count_PS:]])\n",
    "\n",
    "indices_XX = np.where(balanced_PS_train_X.CUST_PRICE_SENSITIVITY == 'XX')[0]\n",
    "rng.shuffle(indices_XX)\n",
    "balanced_PS_train_X = balanced_PS_train_X.drop(balanced_PS_train_X.index[indices_XX[min_count_PS:]])\n",
    "\n",
    "print('After downsampling', balanced_PS_train_X.groupby(['CUST_PRICE_SENSITIVITY'])['SPEND'].count())\n",
    "\n",
    "#pop off the classifiers\n",
    "balanced_PS_train_y_LS = balanced_PS_train_X.pop(\"CUST_LIFESTAGE\") #don't need this\n",
    "balanced_PS_train_y_PS = balanced_PS_train_X.pop(\"CUST_PRICE_SENSITIVITY\")\n",
    "\n",
    "balanced_PS_test_y_LS = balanced_PS_test_X.pop(\"CUST_LIFESTAGE\") #don't need this\n",
    "balanced_PS_test_y_PS = balanced_PS_test_X.pop(\"CUST_PRICE_SENSITIVITY\")\n",
    "\n",
    "\n",
    "\n",
    "#first do a 70-30 split.  \n",
    "balanced_LS_train_X=data_cross_for_balanced_LS.sample(frac=0.7,random_state=42)\n",
    "balanced_LS_test_X=data_cross_for_balanced_LS.drop(balanced_LS_train_X.index)\n",
    "\n",
    "#downsample the training data\n",
    "print(balanced_LS_train_X.groupby(['CUST_LIFESTAGE'])['SPEND'].count())\n",
    "min_count_LS = min(balanced_LS_train_X.groupby(['CUST_LIFESTAGE'])['SPEND'].count())\n",
    "\n",
    "indices_OA = np.where(balanced_LS_train_X.CUST_LIFESTAGE == 'OA')[0]\n",
    "rng.shuffle(indices_OA)\n",
    "balanced_LS_train_X = balanced_LS_train_X.drop(balanced_LS_train_X.index[indices_OA[min_count_LS:]])\n",
    "\n",
    "indices_OF = np.where(balanced_LS_train_X.CUST_LIFESTAGE == 'OF')[0]\n",
    "rng.shuffle(indices_OF)\n",
    "balanced_LS_train_X = balanced_LS_train_X.drop(balanced_LS_train_X.index[indices_OF[min_count_LS:]])\n",
    "\n",
    "indices_OT = np.where(balanced_LS_train_X.CUST_LIFESTAGE == 'OT')[0]\n",
    "rng.shuffle(indices_OT)\n",
    "balanced_LS_train_X = balanced_LS_train_X.drop(balanced_LS_train_X.index[indices_OT[min_count_LS:]])\n",
    "\n",
    "indices_PE = np.where(balanced_LS_train_X.CUST_LIFESTAGE == 'PE')[0]\n",
    "rng.shuffle(indices_PE)\n",
    "balanced_LS_train_X = balanced_LS_train_X.drop(balanced_LS_train_X.index[indices_PE[min_count_LS:]])\n",
    "\n",
    "indices_YA = np.where(balanced_LS_train_X.CUST_LIFESTAGE == 'YA')[0]\n",
    "rng.shuffle(indices_YA)\n",
    "balanced_LS_train_X = balanced_LS_train_X.drop(balanced_LS_train_X.index[indices_YA[min_count_LS:]])\n",
    "\n",
    "indices_YF = np.where(balanced_LS_train_X.CUST_LIFESTAGE == 'YF')[0]\n",
    "rng.shuffle(indices_YF)\n",
    "balanced_LS_train_X = balanced_LS_train_X.drop(balanced_LS_train_X.index[indices_YF[min_count_LS:]])\n",
    "\n",
    "print('After downsampling',balanced_LS_train_X.groupby(['CUST_LIFESTAGE'])['SPEND'].count())\n",
    "\n",
    "#pop off the classifiers\n",
    "balanced_LS_train_y_LS = balanced_LS_train_X.pop(\"CUST_LIFESTAGE\")\n",
    "balanced_LS_train_y_PS = balanced_LS_train_X.pop(\"CUST_PRICE_SENSITIVITY\") #don't need this\n",
    "\n",
    "balanced_LS_test_y_LS = balanced_LS_test_X.pop(\"CUST_LIFESTAGE\")\n",
    "balanced_LS_test_y_PS = balanced_LS_test_X.pop(\"CUST_PRICE_SENSITIVITY\") #don't need this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsample the training so all strata are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#upsampling for PS, per http://www.site.uottawa.ca/~nat/Courses/csi5388/Class-Imbalances.ppt\n",
    "from sklearn.utils import resample\n",
    "data_cross_upsampled_PS = data_cross\n",
    "\n",
    "#first do a 70-30 split.  \n",
    "upsampled_PS_train_X=data_cross_upsampled_PS.sample(frac=0.7,random_state=42)\n",
    "upsampled_PS_test_X=data_cross_upsampled_PS.drop(upsampled_PS_train_X.index)\n",
    "\n",
    "print(upsampled_PS_train_X.groupby(['CUST_PRICE_SENSITIVITY'])['SPEND'].count())\n",
    "max_count_PS = max(upsampled_PS_train_X.groupby(['CUST_PRICE_SENSITIVITY'])['SPEND'].count())\n",
    "\n",
    "subset_LA = upsampled_PS_train_X[upsampled_PS_train_X.CUST_PRICE_SENSITIVITY == 'LA']\n",
    "up_subset_LA = resample(subset_LA, n_samples=max_count_PS-len(subset_LA))\n",
    "subset_MM = upsampled_PS_train_X[upsampled_PS_train_X.CUST_PRICE_SENSITIVITY == 'MM']\n",
    "up_subset_MM = resample(subset_MM, n_samples=max_count_PS-len(subset_MM))\n",
    "subset_UM = upsampled_PS_train_X[upsampled_PS_train_X.CUST_PRICE_SENSITIVITY == 'UM']\n",
    "up_subset_UM = resample(subset_UM, n_samples=max_count_PS-len(subset_UM))\n",
    "subset_XX = upsampled_PS_train_X[upsampled_PS_train_X.CUST_PRICE_SENSITIVITY == 'XX']\n",
    "up_subset_XX = resample(subset_XX, n_samples=max_count_PS-len(subset_XX))\n",
    "\n",
    "upsampled_PS_train_X = pd.concat([subset_LA,up_subset_LA, subset_UM, up_subset_UM, \n",
    "                                     subset_MM, up_subset_MM, subset_XX, up_subset_XX])\n",
    "\n",
    "print(upsampled_PS_train_X.groupby(['CUST_PRICE_SENSITIVITY'])['SPEND'].count())\n",
    "\n",
    "\n",
    "#pop off the classifiers\n",
    "upsampled_PS_train_y_LS = upsampled_PS_train_X.pop(\"CUST_LIFESTAGE\") #don't need this\n",
    "upsampled_PS_train_y_PS = upsampled_PS_train_X.pop(\"CUST_PRICE_SENSITIVITY\") \n",
    "upsampled_PS_test_y_LS = upsampled_PS_test_X.pop(\"CUST_LIFESTAGE\") #don't need this\n",
    "upsampled_PS_test_y_PS = upsampled_PS_test_X.pop(\"CUST_PRICE_SENSITIVITY\") \n",
    "\n",
    "#upsampling for LS\n",
    "data_cross_upsampled_LS = data_cross\n",
    "\n",
    "#first do a 70-30 split.  \n",
    "upsampled_LS_train_X=data_cross_upsampled_LS.sample(frac=0.7,random_state=42)\n",
    "upsampled_LS_test_X=data_cross_upsampled_LS.drop(upsampled_LS_train_X.index)\n",
    "\n",
    "#upsample the training data\n",
    "\n",
    "print(upsampled_LS_train_X.groupby(['CUST_LIFESTAGE'])['SPEND'].count())\n",
    "max_count_LS = max(upsampled_LS_train_X.groupby(['CUST_LIFESTAGE'])['SPEND'].count())\n",
    "\n",
    "subset_OA = upsampled_LS_train_X[upsampled_LS_train_X.CUST_LIFESTAGE == 'OA']\n",
    "up_subset_OA = resample(subset_OA, n_samples=max_count_LS-len(subset_OA))\n",
    "subset_OT = upsampled_LS_train_X[upsampled_LS_train_X.CUST_LIFESTAGE == 'OT']\n",
    "up_subset_OT = resample(subset_OT, n_samples=max_count_LS-len(subset_OT))\n",
    "subset_PE = upsampled_LS_train_X[upsampled_LS_train_X.CUST_LIFESTAGE == 'PE']\n",
    "up_subset_PE = resample(subset_PE, n_samples=max_count_LS-len(subset_PE))\n",
    "subset_YA = upsampled_LS_train_X[upsampled_LS_train_X.CUST_LIFESTAGE == 'YA']\n",
    "up_subset_YA = resample(subset_YA, n_samples=max_count_LS-len(subset_YA))\n",
    "subset_OF = upsampled_LS_train_X[upsampled_LS_train_X.CUST_LIFESTAGE == 'OF']\n",
    "up_subset_OF = resample(subset_OF, n_samples=max_count_LS-len(subset_OF))\n",
    "subset_YF = upsampled_LS_train_X[upsampled_LS_train_X.CUST_LIFESTAGE == 'YF']\n",
    "up_subset_YF = resample(subset_YF, n_samples=max_count_LS-len(subset_YF))\n",
    "\n",
    "upsampled_LS_train_X = pd.concat([up_subset_OA,up_subset_OF, up_subset_YA, up_subset_YF, up_subset_PE, up_subset_OT,\n",
    "                                     subset_OA, subset_OF, subset_YA, subset_YF, subset_PE, subset_OT ])\n",
    "\n",
    "print(upsampled_LS_train_X.groupby(['CUST_LIFESTAGE'])['SPEND'].count())\n",
    "\n",
    "#pop off the classifiers\n",
    "upsampled_LS_train_y_LS = upsampled_LS_train_X.pop(\"CUST_LIFESTAGE\")\n",
    "upsampled_LS_train_y_PS = upsampled_LS_train_X.pop(\"CUST_PRICE_SENSITIVITY\") #don't need this\n",
    "\n",
    "upsampled_LS_test_y_LS = upsampled_LS_test_X.pop(\"CUST_LIFESTAGE\")\n",
    "upsampled_LS_test_y_PS = upsampled_LS_test_X.pop(\"CUST_PRICE_SENSITIVITY\") #don't need this\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "#Create a function to test classifiers and create simple output\n",
    "def tryClassifier_PS (title,psClassifier, train_X, test_X, train_y_PS, test_y_PS):\n",
    "    ps_pred_train = psClassifier.predict(train_X)\n",
    "    ps_pred_test = psClassifier.predict(test_X)\n",
    "    \n",
    "    print(title)\n",
    "    #print('Price Sensitivity Training Accuracy: ', psClassifier.score(train_X, train_y_PS))\n",
    "    print('Price Sensitivity Training Accuracy: ', accuracy_score(train_y_PS, ps_pred_train))\n",
    "    print('Price Sensitivity Training Precision: ', precision_score(train_y_PS, ps_pred_train, average='weighted'))\n",
    "    print('Price Sensitivity Training Recall: ', recall_score(train_y_PS, ps_pred_train, average='weighted'))\n",
    "    print('Price Sensitivity Training Confusion Matrix:')\n",
    "    print(confusion_matrix(train_y_PS, ps_pred_train, labels=[\"LA\", \"MM\", \"UM\",\"XX\"]))\n",
    "    #print('Price Sensitivity Testing Accuracy: ', psClassifier.score(test_X, test_y_PS))\n",
    "    print('Price Sensitivity Testing Accuracy: ', accuracy_score(test_y_PS, ps_pred_test))\n",
    "    print('Price Sensitivity Testing Precision: ', precision_score(test_y_PS, ps_pred_test, average='weighted'))\n",
    "    print('Price Sensitivity Testing Recall: ', recall_score(test_y_PS, ps_pred_test, average='weighted'))\n",
    "    print('Price Sensitivity Testing Confusion Matrix:')\n",
    "    print(confusion_matrix(test_y_PS, ps_pred_test, labels=[\"LA\", \"MM\", \"UM\",\"XX\"]))\n",
    "\n",
    "\n",
    "def tryClassifier_LS (title, lsClassifier, train_X, test_X, train_y_LS, test_y_LS):\n",
    "\n",
    "    ls_pred_train = lsClassifier.predict(train_X)\n",
    "    ls_pred_test = lsClassifier.predict(test_X)\n",
    "    \n",
    "    print(title)\n",
    "    \n",
    "    #print('Life Stage Training Accuracy: ', lsClassifier.score(train_X, train_y_LS))\n",
    "    print('Life Stage Training Accuracy: ', accuracy_score(train_y_LS, ls_pred_train))\n",
    "    print('Life Stage Training Precision: ', precision_score(train_y_LS, ls_pred_train, average='weighted'))\n",
    "    print('Life Stage Training Recall: ', recall_score(train_y_LS, ls_pred_train, average='weighted'))\n",
    "    print('Life Stage Training Confusion Matrix:')\n",
    "    print(confusion_matrix(train_y_LS, ls_pred_train, labels=[\"OA\", \"OF\", \"OT\",\"PE\",\"YA\",\"YF\"]))\n",
    "    #print('Life Stage Testing Accuracy: ', lsClassifier.score(test_X, test_y_LS))\n",
    "    print('Life Stage Testing Accuracy: ', accuracy_score(test_y_LS, ls_pred_test))\n",
    "    print('Life Stage Testing Precision: ', precision_score(test_y_LS, ls_pred_test, average='weighted'))\n",
    "    print('Life Stage Testing Recall: ', recall_score(test_y_LS, ls_pred_test, average='weighted'))\n",
    "    print('Life Stage Testing Confusion Matrix:')\n",
    "    print(confusion_matrix(test_y_LS, ls_pred_test, labels=[\"OA\", \"OF\", \"OT\",\"PE\",\"YA\",\"YF\"]))\n",
    "\n",
    "def tryClassifier_LS_OT (title, lsClassifier, train_X, test_X, train_y_LS, test_y_LS):\n",
    "    ls_pred_train = lsClassifier.predict(train_X)\n",
    "    ls_pred_test = lsClassifier.predict(test_X)\n",
    "    \n",
    "    print(title)\n",
    "    #print('LifeStage Training Accuracy: ', lsClassifier.score(train_X, train_y_LS))\n",
    "    print('Life Stage Training Accuracy: ', accuracy_score(train_y_LS, ls_pred_train))\n",
    "    print('Life Stage Training Precision: ', precision_score(train_y_LS, ls_pred_train, average='weighted'))\n",
    "    print('Life Stage Training Recall: ', recall_score(train_y_LS, ls_pred_train, average='weighted'))\n",
    "    print('Life Stage Training Confusion Matrix:')\n",
    "    print(confusion_matrix(train_y_LS, ls_pred_train, labels=[\"LS\", \"OT\"]))\n",
    "    \n",
    "    #print('LifeStage Testing Accuracy: ', lsClassifier.score(test_X, test_y_LS))\n",
    "    print('Life Stage Testing Accuracy: ', accuracy_score(test_y_LS, ls_pred_test))\n",
    "    print('Life Stage Testing Precision: ', precision_score(test_y_LS, ls_pred_test, average='weighted'))\n",
    "    print('Life Stage Testing Recall: ', recall_score(test_y_LS, ls_pred_test, average='weighted'))\n",
    "    print('Life Stage Testing Confusion Matrix:')\n",
    "    print(confusion_matrix(test_y_LS, ls_pred_test, labels=[\"LS\", \"OT\"]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#create an accuracy metric\n",
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true and predicted values based on the metric chosen. \"\"\"\n",
    "    \n",
    "    # TODO: Calculate the performance score between 'y_true' and 'y_predict'\n",
    "    score = accuracy_score(y_true, y_predict)\n",
    "    \n",
    "    # Return the score\n",
    "    return score\n",
    "from sklearn.metrics import make_scorer\n",
    "scoring_fnc = make_scorer(performance_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Logic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 286 2746  190    0]\n",
      " [ 346 4158  471    0]\n",
      " [ 134 2830  390    0]\n",
      " [  10 1834    0    0]]\n",
      "('Business Logic PS Testing Accuracy:', 0.36088092571855168)\n",
      "('Business Logic PS Testing Precision: ', 0.31506449969866618)\n",
      "('Business Logic PS Testing Recall: ', 0.36088092571855168)\n",
      "[[   0  491  831   34   39  241]\n",
      " [   0  155  272   13    4   57]\n",
      " [   6 1654 3328  507  238  897]\n",
      " [   1  288  538   35   33  202]\n",
      " [   0  551  959   50   37  309]\n",
      " [   1  646  793   37   15  133]]\n",
      "('Business Logic LS Testing Accuracy:', 0.27532661440836131)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('Business Logic LS Testing Precision: ', 0.27401717499124545)\n",
      "('Business Logic LS Testing Recall: ', 0.27532661440836131)\n"
     ]
    }
   ],
   "source": [
    "#print(test_X.head(10))\n",
    "\n",
    "#Full Shop  Small Shop  Top Up  XX \n",
    "\n",
    "avgCustTrainSpend=train_X['SPEND'].mean()\n",
    "stDevCustTrainSpend=train_X['SPEND'].std()\n",
    "\n",
    "testBaskets=test_X[['Full Shop','Small Shop', 'Top Up', 'XX']]\n",
    "mostFrequentBasketType=pd.DataFrame(testBaskets.idxmax(axis=1))\n",
    "mostFrequentBasketType.columns = ['MostFrequentBasketType']\n",
    "mostFrequentBasketType.reset_index(level=['CUST_CODE'], inplace=True)\n",
    "\n",
    "testBasketSize=test_X[['S','M', 'L']]\n",
    "mostFrequentBasketSize=pd.DataFrame(testBasketSize.idxmax(axis=1))\n",
    "mostFrequentBasketSize.columns = ['MostFrequentBasketSize']\n",
    "mostFrequentBasketSize.reset_index(level=['CUST_CODE'], inplace=True)\n",
    "\n",
    "\n",
    "testWeekBaskets = test_X[1L]+test_X[7L]\n",
    "testWeekendBaskets = test_X[2L]+test_X[3L]+test_X[4L]+test_X[5L]+test_X[6L]\n",
    "weekendShopper = pd.DataFrame(testWeekBaskets<testWeekendBaskets)\n",
    "weekendShopper.columns = ['weekendShopper']\n",
    "weekendShopper.reset_index(level=['CUST_CODE'], inplace=True)\n",
    "\n",
    "#print(weekendShopper)\n",
    "\n",
    "test_X_Naive=test_X.copy()\n",
    "test_X_Naive.reset_index(level=['CUST_CODE'], inplace=True)\n",
    "\n",
    "test_X_Naive = pd.merge(test_X_Naive, mostFrequentBasketType, how='inner', on = 'CUST_CODE')\n",
    "test_X_Naive = pd.merge(test_X_Naive, mostFrequentBasketSize, how='inner', on = 'CUST_CODE')\n",
    "test_X_Naive = pd.merge(test_X_Naive, weekendShopper, how='inner', on = 'CUST_CODE')\n",
    "\n",
    "#print(test_X_Naive.head(10))\n",
    "\n",
    "#Below based on http://stackoverflow.com/questions/21733893/pandas-dataframe-add-a-field-based-on-multiple-if-statements\n",
    "\n",
    "test_X_Naive['PS_Pred'] = 'MM'  #default value\n",
    "test_X_Naive.loc[(test_X_Naive['SPEND']<avgCustTrainSpend-0.5*stDevCustTrainSpend) & (test_X_Naive['MostFrequentBasketType']=='Full Shop'), 'PS_Pred'] = 'LA'\n",
    "test_X_Naive.loc[(test_X_Naive['SPEND']>avgCustTrainSpend+0.75*stDevCustTrainSpend) & (test_X_Naive['MostFrequentBasketType']<>'Full Shop'), 'PS_Pred'] = 'UM'\n",
    "\n",
    "#randomly set 13.6% of the values to 'XX, based on http://stackoverflow.com/questions/31389481/numpy-replace-random-elements-in-an-array\n",
    "#test_X_Naive.loc[np.random.random_sample((len(test_X)))<=0.136, 'PS_Pred'] = 'XX'\n",
    "\n",
    "\n",
    "test_X_Naive['LS_Pred'] = 'PE'  #default value\n",
    "test_X_Naive.loc[(test_X_Naive['weekendShopper']==True) & (test_X_Naive['MostFrequentBasketSize']=='L'), 'LS_Pred'] = 'OF'\n",
    "test_X_Naive.loc[(test_X_Naive['weekendShopper']==True) & (test_X_Naive['MostFrequentBasketSize']=='M'), 'LS_Pred'] = 'YF'\n",
    "test_X_Naive.loc[(test_X_Naive['weekendShopper']==True) & (test_X_Naive['MostFrequentBasketSize']=='S') & (test_X_Naive['MostFrequentBasketType']=='Small Shop'), 'LS_Pred'] = 'YA'\n",
    "test_X_Naive.loc[(test_X_Naive['weekendShopper']==True) & (test_X_Naive['MostFrequentBasketSize']=='S') & (test_X_Naive['MostFrequentBasketType']<>'Small Shop'), 'LS_Pred'] = 'OA'\n",
    "#randomly set 49.6% values to 'OT'\n",
    "test_X_Naive.loc[np.random.random_sample((len(test_X)))<=0.496, 'LS_Pred'] = 'OT'\n",
    "\n",
    "\n",
    "BL_Pred_PS = test_X_Naive.pop(\"PS_Pred\")\n",
    "print(confusion_matrix(test_y_PS, BL_Pred_PS, labels=[\"LA\", \"MM\", \"UM\",\"XX\"]))\n",
    "print(\"Business Logic PS Testing Accuracy:\",accuracy_score(test_y_PS,BL_Pred_PS))\n",
    "print('Business Logic PS Testing Precision: ', precision_score(test_y_PS, BL_Pred_PS, average='weighted'))\n",
    "print('Business Logic PS Testing Recall: ', recall_score(test_y_PS, BL_Pred_PS, average='weighted'))\n",
    "\n",
    "BL_Pred_LS = test_X_Naive.pop(\"LS_Pred\")\n",
    "print(confusion_matrix(test_y_LS, BL_Pred_LS, labels=[\"OA\", \"OF\", \"OT\",\"PE\",\"YA\",\"YF\"]))\n",
    "print(\"Business Logic LS Testing Accuracy:\",accuracy_score(test_y_LS, BL_Pred_LS))\n",
    "print('Business Logic LS Testing Precision: ', precision_score(test_y_LS, BL_Pred_LS, average='weighted'))\n",
    "print('Business Logic LS Testing Recall: ', recall_score(test_y_LS, BL_Pred_LS, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sample Output:\n",
    "[[ 286 2746  190    0]\n",
    " [ 346 4158  471    0]\n",
    " [ 134 2830  390    0]\n",
    " [  10 1834    0    0]]\n",
    "('Business Logic PS Testing Accuracy:', 0.36088092571855168)\n",
    "('Business Logic PS Testing Precision: ', 0.31506449969866618)\n",
    "('Business Logic PS Testing Recall: ', 0.36088092571855168)\n",
    "[[   0  491  831   34   39  241]\n",
    " [   0  155  272   13    4   57]\n",
    " [   6 1654 3328  507  238  897]\n",
    " [   1  288  538   35   33  202]\n",
    " [   0  551  959   50   37  309]\n",
    " [   1  646  793   37   15  133]]\n",
    "('Business Logic LS Testing Accuracy:', 0.27532661440836131)\n",
    "C:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
    "  'precision', 'predicted', average, warn_for)\n",
    "\n",
    "('Business Logic LS Testing Precision: ', 0.27401717499124545)\n",
    "('Business Logic LS Testing Recall: ', 0.27532661440836131)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall that running training data back through the random forest is not as good an indicator of performance as the OOB score\n",
      "Unbalanced:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-34ab7f19a977>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unbalanced:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mrfc_ps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrfc_ps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y_PS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Price Sensitivity OOB: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrfc_ps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moob_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\ensemble\\forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 326\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\ensemble\\forest.pyc\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    740\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    348\u001b[0m                                            self.min_impurity_split)\n\u001b[1;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier #using scikitlearn 0.17.1\n",
    "\n",
    "\n",
    "rfc_ps = RandomForestClassifier(n_estimators = 10000,random_state=42, criterion=\"entropy\"\n",
    "                                , max_features = 10\n",
    "                                #, max_leaf_nodes=1000\n",
    "                                #, min_samples_leaf=20\n",
    "                                , oob_score=True\n",
    "                               )\n",
    "rfc_ls = RandomForestClassifier(n_estimators = 10000,random_state=42, criterion=\"entropy\"\n",
    "                                , max_features = 10\n",
    "                                #, max_leaf_nodes=1000\n",
    "                                #, min_samples_leaf=20\n",
    "                                , oob_score=True\n",
    "                               )\n",
    "#need to handle categorical variables either through pandas.getDummies or http://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder\n",
    "#train_X_num\n",
    "\n",
    "#print(train_X_dummied.head(10))\n",
    "#print(list(train_X_dummied.columns.values))\n",
    "\n",
    "print ('Recall that running training data back through the random forest is not as good an indicator of performance as the OOB score')\n",
    "\n",
    "print('Unbalanced:')\n",
    "rfc_ps = rfc_ps.fit(train_X, train_y_PS)\n",
    "\n",
    "print('Price Sensitivity OOB: ', rfc_ps.oob_score_)\n",
    "tryClassifier_PS (\"Random Forest\",rfc_ps, train_X, test_X, train_y_PS, test_y_PS)\n",
    "\n",
    "rfc_ls = rfc_ls.fit(train_X, train_y_LS)\n",
    "\n",
    "print('Life Stage OOB: ', rfc_ls.oob_score_)\n",
    "tryClassifier_LS (\"Random Forest\", rfc_ls, train_X, test_X, train_y_LS, test_y_LS)\n",
    "\n",
    "\n",
    "\n",
    "rfc_balanced_ps = RandomForestClassifier(n_estimators = 10000,random_state=42, criterion=\"entropy\"\n",
    "                                , max_features = 10\n",
    "                                #, max_leaf_nodes=1000\n",
    "                                #, min_samples_leaf=20\n",
    "                                , oob_score=True\n",
    "                               )\n",
    "rfc_balanced_ls = RandomForestClassifier(n_estimators = 10000,random_state=42, criterion=\"entropy\"\n",
    "                                , max_features = 10\n",
    "                                #, max_leaf_nodes=1000\n",
    "                                #, min_samples_leaf=20\n",
    "                                , oob_score=True\n",
    "                               )\n",
    "\n",
    "print('Downsampled:')\n",
    "rfc_balanced_ps = rfc_balanced_ps.fit(balanced_PS_train_X, balanced_PS_train_y_PS)\n",
    "\n",
    "print('Price Sensitivity OOB: ', rfc_ps.oob_score_)\n",
    "tryClassifier_PS (\"Random Forest\",rfc_balanced_ps, balanced_PS_train_X, test_X, balanced_PS_train_y_PS, test_y_PS)\n",
    "\n",
    "rfc_balanced_ls = rfc_balanced_ls.fit(balanced_LS_train_X, balanced_LS_train_y_LS)\n",
    "\n",
    "print('Life Stage OOB: ', rfc_ls.oob_score_)\n",
    "tryClassifier_LS (\"Random Forest\", rfc_balanced_ls, balanced_LS_train_X, test_X, balanced_LS_train_y_LS, test_y_LS)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Sample Output\n",
    "Recall that running training data back through the random forest is not as good an indicator of performance as the OOB score\n",
    "Unbalanced:\n",
    "('Price Sensitivity OOB: ', 0.61726499008126956)\n",
    "Random Forest\n",
    "('Price Sensitivity Training Accuracy: ', 1.0)\n",
    "('Price Sensitivity Training Precision: ', 1.0)\n",
    "('Price Sensitivity Training Recall: ', 1.0)\n",
    "Price Sensitivity Training Confusion Matrix:\n",
    "[[ 7467     0     0     0]\n",
    " [    0 11628     0     0]\n",
    " [    0     0  7936     0]\n",
    " [    0     0     0  4223]]\n",
    "('Price Sensitivity Testing Accuracy: ', 0.62291899962672637)\n",
    "('Price Sensitivity Testing Precision: ', 0.65534831835390817)\n",
    "('Price Sensitivity Testing Recall: ', 0.62291899962672637)\n",
    "Price Sensitivity Testing Confusion Matrix:\n",
    "[[1141 1915  106   60]\n",
    " [ 435 3845  596   99]\n",
    " [  37 1650 1613   54]\n",
    " [  24   70    5 1745]]\n",
    "('Life Stage OOB: ', 0.52252511678505154)\n",
    "Random Forest\n",
    "('Life Stage Training Accuracy: ', 0.99993600819095152)\n",
    "('Life Stage Training Precision: ', 0.99993601644902474)\n",
    "('Life Stage Training Recall: ', 0.99993600819095152)\n",
    "Life Stage Training Confusion Matrix:\n",
    "[[ 3723     0     0     0     0     0]\n",
    " [    0  1255     0     0     0     0]\n",
    " [    0     0 15496     0     0     0]\n",
    " [    0     0     0  2503     0     0]\n",
    " [    0     0     2     0  4467     0]\n",
    " [    0     0     0     0     0  3808]]\n",
    "('Life Stage Testing Accuracy: ', 0.51765584173198953)\n",
    "('Life Stage Testing Precision: ', 0.4614088028633514)\n",
    "('Life Stage Testing Recall: ', 0.51765584173198953)\n",
    "Life Stage Testing Confusion Matrix:\n",
    "[[  67    0 1421   81    2   65]\n",
    " [   2    0  366    0    0  133]\n",
    " [  52    0 6159   99   21  299]\n",
    " [  65    0  802  223    0    7]\n",
    " [  27    0 1689   23   26  141]\n",
    " [   7    0 1146    8    5  459]]\n",
    "Downsampled:\n",
    "('Price Sensitivity OOB: ', 0.61726499008126956)\n",
    "Random Forest\n",
    "('Price Sensitivity Training Accuracy: ', 1.0)\n",
    "('Price Sensitivity Training Precision: ', 1.0)\n",
    "('Price Sensitivity Training Recall: ', 1.0)\n",
    "Price Sensitivity Training Confusion Matrix:\n",
    "[[4223    0    0    0]\n",
    " [   0 4223    0    0]\n",
    " [   0    0 4223    0]\n",
    " [   0    0    0 4223]]\n",
    "('Price Sensitivity Testing Accuracy: ', 0.59245987308697279)\n",
    "('Price Sensitivity Testing Precision: ', 0.59608694204520729)\n",
    "('Price Sensitivity Testing Recall: ', 0.59245987308697279)\n",
    "Price Sensitivity Testing Confusion Matrix:\n",
    "[[2170  576  377   99]\n",
    " [1713 1640 1464  158]\n",
    " [ 363  551 2347   93]\n",
    " [  34    7   24 1779]]\n",
    "('Life Stage OOB: ', 0.52252511678505154)\n",
    "Random Forest\n",
    "('Life Stage Training Accuracy: ', 1.0)\n",
    "('Life Stage Training Precision: ', 1.0)\n",
    "('Life Stage Training Recall: ', 1.0)\n",
    "Life Stage Training Confusion Matrix:\n",
    "[[1255    0    0    0    0    0]\n",
    " [   0 1255    0    0    0    0]\n",
    " [   0    0 1255    0    0    0]\n",
    " [   0    0    0 1255    0    0]\n",
    " [   0    0    0    0 1255    0]\n",
    " [   0    0    0    0    0 1255]]\n",
    "('Life Stage Testing Accuracy: ', 0.43135498320268756)\n",
    "('Life Stage Testing Precision: ', 0.54792729871524792)\n",
    "('Life Stage Testing Recall: ', 0.43135498320268756)\n",
    "Life Stage Testing Confusion Matrix:\n",
    "[[ 337  163  158  559  298  121]\n",
    " [  29  108   62   37  112  153]\n",
    " [ 382  481 3142  901 1250  474]\n",
    " [ 134   20  158  724   46   15]\n",
    " [ 210  217  210  200  832  237]\n",
    " [ 105  281  175  134  295  635]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsampled:\n",
      "('Price Sensitivity OOB: ', 0.81114551083591335)\n",
      "Random Forest\n",
      "('Price Sensitivity Training Accuracy: ', 1.0)\n",
      "('Price Sensitivity Training Precision: ', 1.0)\n",
      "('Price Sensitivity Training Recall: ', 1.0)\n",
      "Price Sensitivity Training Confusion Matrix:\n",
      "[[11628     0     0     0]\n",
      " [    0 11628     0     0]\n",
      " [    0     0 11628     0]\n",
      " [    0     0     0 11628]]\n",
      "('Price Sensitivity Testing Accuracy: ', 0.62814483016050771)\n",
      "('Price Sensitivity Testing Precision: ', 0.63210697618396605)\n",
      "('Price Sensitivity Testing Recall: ', 0.62814483016050771)\n",
      "Price Sensitivity Testing Confusion Matrix:\n",
      "[[1509 1460  179   74]\n",
      " [ 757 3244  856  118]\n",
      " [ 121 1265 1900   68]\n",
      " [  26   43   14 1761]]\n",
      "('Life Stage OOB: ', 0.957967647564963)\n",
      "Random Forest\n",
      "('Life Stage Training Accuracy: ', 0.9999784890724488)\n",
      "('Life Stage Training Precision: ', 0.99997849184841059)\n",
      "('Life Stage Training Recall: ', 0.9999784890724488)\n",
      "Life Stage Training Confusion Matrix:\n",
      "[[15496     0     0     0     0     0]\n",
      " [    0 15496     0     0     0     0]\n",
      " [    0     0 15494     0     2     0]\n",
      " [    0     0     0 15496     0     0]\n",
      " [    0     0     0     0 15496     0]\n",
      " [    0     0     0     0     0 15496]]\n",
      "('Life Stage Testing Accuracy: ', 0.51675998506905563)\n",
      "('Life Stage Testing Precision: ', 0.46732155107045908)\n",
      "('Life Stage Testing Recall: ', 0.51675998506905563)\n",
      "Life Stage Testing Confusion Matrix:\n",
      "[[ 262    0  909  160  132  173]\n",
      " [  12    0  247    2   48  192]\n",
      " [ 225    0 5152  209  497  547]\n",
      " [ 173    0  510  384    9   21]\n",
      " [ 116    0 1031   39  446  274]\n",
      " [  52    1  718   17  159  678]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier #using scikitlearn 0.17.1\n",
    "\n",
    "rfc_upsampled_ps = RandomForestClassifier(n_estimators = 1000,random_state=42, criterion=\"entropy\"\n",
    "                                , max_features = 10\n",
    "                                #, max_leaf_nodes=1000\n",
    "                                #, min_samples_leaf=20\n",
    "                                , oob_score=True\n",
    "                               )\n",
    "print('Upsampled:')\n",
    "\n",
    "rfc_upsampled_ps = rfc_upsampled_ps.fit(upsampled_PS_train_X, upsampled_PS_train_y_PS)\n",
    "\n",
    "print('Price Sensitivity OOB: ', rfc_upsampled_ps.oob_score_)\n",
    "tryClassifier_PS (\"Random Forest\", rfc_upsampled_ps, upsampled_PS_train_X, test_X, upsampled_PS_train_y_PS, test_y_PS)\n",
    "\n",
    "\n",
    "rfc_upsampled_ls = RandomForestClassifier(n_estimators = 1000,random_state=42, criterion=\"entropy\"\n",
    "                                , max_features = 10\n",
    "                                #, max_leaf_nodes=1000\n",
    "                                #, min_samples_leaf=20\n",
    "                                , oob_score=True\n",
    "                               )\n",
    "\n",
    "rfc_upsampled_ls = rfc_upsampled_ls.fit(upsampled_LS_train_X, upsampled_LS_train_y_LS)\n",
    "\n",
    "print('Life Stage OOB: ', rfc_upsampled_ls.oob_score_)\n",
    "tryClassifier_LS (\"Random Forest\", rfc_upsampled_ls, upsampled_LS_train_X, test_X, upsampled_LS_train_y_LS, test_y_LS)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Upsampled:\n",
    "('Price Sensitivity OOB: ', 0.81114551083591335)\n",
    "Random Forest\n",
    "('Price Sensitivity Training Accuracy: ', 1.0)\n",
    "('Price Sensitivity Training Precision: ', 1.0)\n",
    "('Price Sensitivity Training Recall: ', 1.0)\n",
    "Price Sensitivity Training Confusion Matrix:\n",
    "[[11628     0     0     0]\n",
    " [    0 11628     0     0]\n",
    " [    0     0 11628     0]\n",
    " [    0     0     0 11628]]\n",
    "('Price Sensitivity Testing Accuracy: ', 0.62814483016050771)\n",
    "('Price Sensitivity Testing Precision: ', 0.63210697618396605)\n",
    "('Price Sensitivity Testing Recall: ', 0.62814483016050771)\n",
    "Price Sensitivity Testing Confusion Matrix:\n",
    "[[1509 1460  179   74]\n",
    " [ 757 3244  856  118]\n",
    " [ 121 1265 1900   68]\n",
    " [  26   43   14 1761]]\n",
    "('Life Stage OOB: ', 0.957967647564963)\n",
    "Random Forest\n",
    "('Life Stage Training Accuracy: ', 0.9999784890724488)\n",
    "('Life Stage Training Precision: ', 0.99997849184841059)\n",
    "('Life Stage Training Recall: ', 0.9999784890724488)\n",
    "Life Stage Training Confusion Matrix:\n",
    "[[15496     0     0     0     0     0]\n",
    " [    0 15496     0     0     0     0]\n",
    " [    0     0 15494     0     2     0]\n",
    " [    0     0     0 15496     0     0]\n",
    " [    0     0     0     0 15496     0]\n",
    " [    0     0     0     0     0 15496]]\n",
    "('Life Stage Testing Accuracy: ', 0.51675998506905563)\n",
    "('Life Stage Testing Precision: ', 0.46732155107045908)\n",
    "('Life Stage Testing Recall: ', 0.51675998506905563)\n",
    "Life Stage Testing Confusion Matrix:\n",
    "[[ 262    0  909  160  132  173]\n",
    " [  12    0  247    2   48  192]\n",
    " [ 225    0 5152  209  497  547]\n",
    " [ 173    0  510  384    9   21]\n",
    " [ 116    0 1031   39  446  274]\n",
    " [  52    1  718   17  159  678]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twostage step 1:\n",
      "('Price Sensitivity OOB: ', 0.70023037051257442)\n",
      "Random Forest\n",
      "('Life Stage Training Accuracy: ', 0.99993600819095152)\n",
      "('Life Stage Training Precision: ', 0.99993601644902474)\n",
      "('Life Stage Training Recall: ', 0.99993600819095152)\n",
      "Life Stage Training Confusion Matrix:\n",
      "[[15756     2]\n",
      " [    0 15496]]\n",
      "('Life Stage Testing Accuracy: ', 0.6935423665546846)\n",
      "('Life Stage Testing Precision: ', 0.70778284445277306)\n",
      "('Life Stage Testing Recall: ', 0.6935423665546846)\n",
      "Life Stage Testing Confusion Matrix:\n",
      "[[5612 1153]\n",
      " [2952 3678]]\n",
      "twostage step 2:\n",
      "[[5612 1153]\n",
      " [2952 3678]]\n",
      "('Price Sensitivity OOB: ', 0.46033760629521514)\n",
      "[[ 457    0  254  473  199    0]\n",
      " [  39    0    8  158  211    0]\n",
      " [ 290    0  476   92   27    0]\n",
      " [ 186    0   74  950  325    0]\n",
      " [ 118    0   37  460  778    0]\n",
      " [ 531    0  365 1401  655    0]]\n",
      "0.310719290051\n",
      "[[ 457    0  253  254  473  199]\n",
      " [  39    0   85    8  158  211]\n",
      " [ 531    0 3678  365 1401  655]\n",
      " [ 290    0  212  476   92   27]\n",
      " [ 186    0  371   74  950  325]\n",
      " [ 118    0  232   37  460  778]]\n",
      "0.473236282195\n"
     ]
    }
   ],
   "source": [
    "#try a two-stage LS\n",
    "#step 1, predict OT or not\n",
    "#step 2, for those we predict !OT then predict the rest.\n",
    "\n",
    "#get the training data, excluding OTs\n",
    "\n",
    "\n",
    "train_y_LS_excOT = train_y_LS[train_y_LS<> 'OT']\n",
    "train_X_excOT = train_X[train_y_LS<> 'OT']\n",
    "\n",
    "#create a second training set where anything other than 'OT' is labelled 'LS'\n",
    "\n",
    "train_y_LS_BinaryOT = train_y_LS.copy()\n",
    "train_y_LS_BinaryOT [train_y_LS_BinaryOT<> 'OT'] = 'LS'\n",
    "\n",
    "test_y_LS_BinaryOT = test_y_LS.copy()\n",
    "test_y_LS_BinaryOT [test_y_LS_BinaryOT<> 'OT'] = 'LS'\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier #using scikitlearn 0.17.1\n",
    "\n",
    "#step 1, create a model that clasiffies as LS or not.\n",
    "rfc_twostage_ls = RandomForestClassifier(n_estimators = 10000, random_state=42, criterion=\"entropy\"\n",
    "                                , max_features = 10\n",
    "                                #, max_leaf_nodes=1000\n",
    "                                #, min_samples_leaf=20\n",
    "                                , oob_score=True\n",
    "                               )\n",
    "print('twostage step 1:')\n",
    "\n",
    "rfc_twostage_ls = rfc_twostage_ls.fit(train_X, train_y_LS_BinaryOT)\n",
    "\n",
    "print('Price Sensitivity OOB: ', rfc_twostage_ls.oob_score_)\n",
    "tryClassifier_LS_OT (\"Random Forest\", rfc_twostage_ls, train_X, test_X, train_y_LS_BinaryOT, test_y_LS_BinaryOT)\n",
    "\n",
    "#get the stage 1 predictions\n",
    "rfc_twostage_ls_preds = rfc_twostage_ls.predict(test_X)\n",
    "\n",
    "#print(rfc_twostage_ls.feature_importances_ )\n",
    "\n",
    "#step 2, using the training data that excludes OT, predict the other classes\n",
    "from sklearn.metrics import accuracy_score\n",
    "#fit a model on training data that isn't OT\n",
    "rfc_twostage_ls_2 = RandomForestClassifier(n_estimators = 1000, random_state=42, criterion=\"entropy\"\n",
    "                                , max_features = 20\n",
    "                                , max_leaf_nodes=1000\n",
    "                                , min_samples_leaf=20\n",
    "                                , oob_score=True\n",
    "                               )\n",
    "\n",
    "print('twostage step 2:')\n",
    "rfc_twostage_ls_2 = rfc_twostage_ls_2.fit(train_X_excOT,train_y_LS_excOT)\n",
    "\n",
    "#get the test values where we predict LS instead of 'OT'\n",
    "stage1_LS_test_X = test_X[rfc_twostage_ls_preds=='LS']\n",
    "stage1_LS_test_y_LS = test_y_LS[rfc_twostage_ls_preds=='LS']\n",
    "stage1_LS_test_y_OT = test_y_LS[rfc_twostage_ls_preds=='OT']\n",
    "\n",
    "#construct a new set of Ys and Predictions to evaluate\n",
    "rfc_twostage_ls_2_preds = rfc_twostage_ls_2.predict(stage1_LS_test_X)\n",
    "rfc_twostage_ls_OT_preds = rfc_twostage_ls_preds[rfc_twostage_ls_preds=='OT']\n",
    "\n",
    "constructedY = pd.concat([stage1_LS_test_y_OT,stage1_LS_test_y_LS])\n",
    "constructedPreds = pd.concat([pd.DataFrame(rfc_twostage_ls_OT_preds), pd.DataFrame(rfc_twostage_ls_2_preds)])\n",
    "\n",
    "print(confusion_matrix(test_y_LS_BinaryOT, rfc_twostage_ls_preds, labels=[\"LS\", \"OT\"]))\n",
    "print('Price Sensitivity OOB: ', rfc_twostage_ls_2.oob_score_)\n",
    "\n",
    "print(confusion_matrix(stage1_LS_test_y_LS, rfc_twostage_ls_2_preds, labels=[\"OA\", \"OF\",\"PE\",\"YA\",\"YF\",\"OT\"]))\n",
    "print(accuracy_score(stage1_LS_test_y_LS,rfc_twostage_ls_2_preds))\n",
    "print(confusion_matrix(constructedY, constructedPreds, labels=[\"OA\", \"OF\", \"OT\",\"PE\",\"YA\",\"YF\"]))\n",
    "print(accuracy_score(constructedY,constructedPreds))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Sample Output\n",
    "twostage step 1:\n",
    "('Price Sensitivity OOB: ', 0.70023037051257442)\n",
    "Random Forest\n",
    "('Life Stage Training Accuracy: ', 0.99993600819095152)\n",
    "('Life Stage Training Precision: ', 0.99993601644902474)\n",
    "('Life Stage Training Recall: ', 0.99993600819095152)\n",
    "Life Stage Training Confusion Matrix:\n",
    "[[15756     2]\n",
    " [    0 15496]]\n",
    "('Life Stage Testing Accuracy: ', 0.6935423665546846)\n",
    "('Life Stage Testing Precision: ', 0.70778284445277306)\n",
    "('Life Stage Testing Recall: ', 0.6935423665546846)\n",
    "Life Stage Testing Confusion Matrix:\n",
    "[[5612 1153]\n",
    " [2952 3678]]\n",
    "twostage step 2:\n",
    "[[5612 1153]\n",
    " [2952 3678]]\n",
    "('Price Sensitivity OOB: ', 0.46033760629521514)\n",
    "[[ 457    0  254  473  199    0]\n",
    " [  39    0    8  158  211    0]\n",
    " [ 290    0  476   92   27    0]\n",
    " [ 186    0   74  950  325    0]\n",
    " [ 118    0   37  460  778    0]\n",
    " [ 531    0  365 1401  655    0]]\n",
    "0.310719290051\n",
    "[[ 457    0  253  254  473  199]\n",
    " [  39    0   85    8  158  211]\n",
    " [ 531    0 3678  365 1401  655]\n",
    " [ 290    0  212  476   92   27]\n",
    " [ 186    0  371   74  950  325]\n",
    " [ 118    0  232   37  460  778]]\n",
    "0.473236282195"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier, reg\n",
      "('Price Sensitivity Training Accuracy: ', 1.0)\n",
      "('Price Sensitivity Training Precision: ', 1.0)\n",
      "('Price Sensitivity Training Recall: ', 1.0)\n",
      "Price Sensitivity Training Confusion Matrix:\n",
      "[[ 7467     0     0     0]\n",
      " [    0 11628     0     0]\n",
      " [    0     0  7936     0]\n",
      " [    0     0     0  4223]]\n",
      "('Price Sensitivity Testing Accuracy: ', 0.62777155655095185)\n",
      "('Price Sensitivity Testing Precision: ', 0.64021625712260144)\n",
      "('Price Sensitivity Testing Recall: ', 0.62777155655095185)\n",
      "Price Sensitivity Testing Confusion Matrix:\n",
      "[[1482 1565  144   31]\n",
      " [ 718 3394  810   53]\n",
      " [ 114 1384 1828   28]\n",
      " [  29   75   35 1705]]\n",
      "Gradient Boosting Classifier, downsampled\n",
      "('Price Sensitivity Training Accuracy: ', 1.0)\n",
      "('Price Sensitivity Training Precision: ', 1.0)\n",
      "('Price Sensitivity Training Recall: ', 1.0)\n",
      "Price Sensitivity Training Confusion Matrix:\n",
      "[[4223    0    0    0]\n",
      " [   0 4223    0    0]\n",
      " [   0    0 4223    0]\n",
      " [   0    0    0 4223]]\n",
      "('Price Sensitivity Testing Accuracy: ', 0.60171705860395674)\n",
      "('Price Sensitivity Testing Precision: ', 0.59945445116682206)\n",
      "('Price Sensitivity Testing Recall: ', 0.60171705860395674)\n",
      "Price Sensitivity Testing Confusion Matrix:\n",
      "[[2022  820  320   60]\n",
      " [1490 2041 1343  101]\n",
      " [ 293  763 2238   60]\n",
      " [  36   24   25 1759]]\n",
      "Gradient Boosting Classifier, upsampled\n",
      "('Price Sensitivity Training Accuracy: ', 1.0)\n",
      "('Price Sensitivity Training Precision: ', 1.0)\n",
      "('Price Sensitivity Training Recall: ', 1.0)\n",
      "Price Sensitivity Training Confusion Matrix:\n",
      "[[11628     0     0     0]\n",
      " [    0 11628     0     0]\n",
      " [    0     0 11628     0]\n",
      " [    0     0     0 11628]]\n",
      "('Price Sensitivity Testing Accuracy: ', 0.62881672265770805)\n",
      "('Price Sensitivity Testing Precision: ', 0.63590025259855076)\n",
      "('Price Sensitivity Testing Recall: ', 0.62881672265770805)\n",
      "Price Sensitivity Testing Confusion Matrix:\n",
      "[[1573 1445  167   37]\n",
      " [ 799 3221  901   54]\n",
      " [ 130 1280 1914   30]\n",
      " [  31   63   35 1715]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc_ps = GradientBoostingClassifier(learning_rate=0.05, n_estimators=1000, max_depth=10)\n",
    "balanced_gbc_ps = GradientBoostingClassifier(learning_rate=0.05, n_estimators=1000, max_depth=10)\n",
    "upsampled_gbc_ps = GradientBoostingClassifier(learning_rate=0.05, n_estimators=1000, max_depth=10)\n",
    "\n",
    "#gbc_ls = GradientBoostingClassifier(learning_rate=0.05, n_estimators=1000, max_depth=10)\n",
    "\n",
    "gbc_ps = gbc_ps.fit(train_X, train_y_PS)\n",
    "balanced_gbc_ps = balanced_gbc_ps.fit(balanced_PS_train_X, balanced_PS_train_y_PS)\n",
    "upsampled_gbc_ps = upsampled_gbc_ps.fit(upsampled_PS_train_X, upsampled_PS_train_y_PS)\n",
    "#gbc_ls = rfc_ls.fit(train_X, train_y_LS)\n",
    "\n",
    "tryClassifier_PS (\"Gradient Boosting Classifier, reg\",gbc_ps, train_X, test_X, train_y_PS, test_y_PS)\n",
    "tryClassifier_PS (\"Gradient Boosting Classifier, downsampled\",balanced_gbc_ps, balanced_PS_train_X, test_X, balanced_PS_train_y_PS, test_y_PS)\n",
    "tryClassifier_PS (\"Gradient Boosting Classifier, upsampled\",upsampled_gbc_ps, upsampled_PS_train_X, test_X, upsampled_PS_train_y_PS, test_y_PS)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## sample output\n",
    "Gradient Boosting Classifier, reg\n",
    "('Price Sensitivity Training Accuracy: ', 1.0)\n",
    "('Price Sensitivity Training Precision: ', 1.0)\n",
    "('Price Sensitivity Training Recall: ', 1.0)\n",
    "Price Sensitivity Training Confusion Matrix:\n",
    "[[ 7467     0     0     0]\n",
    " [    0 11628     0     0]\n",
    " [    0     0  7936     0]\n",
    " [    0     0     0  4223]]\n",
    "('Price Sensitivity Testing Accuracy: ', 0.62777155655095185)\n",
    "('Price Sensitivity Testing Precision: ', 0.64021625712260144)\n",
    "('Price Sensitivity Testing Recall: ', 0.62777155655095185)\n",
    "Price Sensitivity Testing Confusion Matrix:\n",
    "[[1482 1565  144   31]\n",
    " [ 718 3394  810   53]\n",
    " [ 114 1384 1828   28]\n",
    " [  29   75   35 1705]]\n",
    "Gradient Boosting Classifier, downsampled\n",
    "('Price Sensitivity Training Accuracy: ', 1.0)\n",
    "('Price Sensitivity Training Precision: ', 1.0)\n",
    "('Price Sensitivity Training Recall: ', 1.0)\n",
    "Price Sensitivity Training Confusion Matrix:\n",
    "[[4223    0    0    0]\n",
    " [   0 4223    0    0]\n",
    " [   0    0 4223    0]\n",
    " [   0    0    0 4223]]\n",
    "('Price Sensitivity Testing Accuracy: ', 0.60171705860395674)\n",
    "('Price Sensitivity Testing Precision: ', 0.59945445116682206)\n",
    "('Price Sensitivity Testing Recall: ', 0.60171705860395674)\n",
    "Price Sensitivity Testing Confusion Matrix:\n",
    "[[2022  820  320   60]\n",
    " [1490 2041 1343  101]\n",
    " [ 293  763 2238   60]\n",
    " [  36   24   25 1759]]\n",
    "Gradient Boosting Classifier, upsampled\n",
    "('Price Sensitivity Training Accuracy: ', 1.0)\n",
    "('Price Sensitivity Training Precision: ', 1.0)\n",
    "('Price Sensitivity Training Recall: ', 1.0)\n",
    "Price Sensitivity Training Confusion Matrix:\n",
    "[[11628     0     0     0]\n",
    " [    0 11628     0     0]\n",
    " [    0     0 11628     0]\n",
    " [    0     0     0 11628]]\n",
    "('Price Sensitivity Testing Accuracy: ', 0.62881672265770805)\n",
    "('Price Sensitivity Testing Precision: ', 0.63590025259855076)\n",
    "('Price Sensitivity Testing Recall: ', 0.62881672265770805)\n",
    "Price Sensitivity Testing Confusion Matrix:\n",
    "[[1573 1445  167   37]\n",
    " [ 799 3221  901   54]\n",
    " [ 130 1280 1914   30]\n",
    " [  31   63   35 1715]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier, reg\n",
      "('Life Stage Training Accuracy: ', 0.99993600819095152)\n",
      "('Life Stage Training Precision: ', 0.99993601644902474)\n",
      "('Life Stage Training Recall: ', 0.99993600819095152)\n",
      "Life Stage Training Confusion Matrix:\n",
      "[[ 3723     0     0     0     0     0]\n",
      " [    0  1255     0     0     0     0]\n",
      " [    0     0 15496     0     0     0]\n",
      " [    0     0     0  2503     0     0]\n",
      " [    0     0     2     0  4467     0]\n",
      " [    0     0     0     0     0  3808]]\n",
      "('Life Stage Testing Accuracy: ', 0.51623740201567747)\n",
      "('Life Stage Testing Precision: ', 0.46368300558700754)\n",
      "('Life Stage Testing Recall: ', 0.51623740201567747)\n",
      "Life Stage Testing Confusion Matrix:\n",
      "[[ 151    0 1287   95   55   48]\n",
      " [   7    5  370    2   16  101]\n",
      " [ 111    5 5937  148  155  274]\n",
      " [ 105    0  730  251    5    6]\n",
      " [  55    3 1554   23  165  106]\n",
      " [  28    2 1129   11   49  406]]\n",
      "Gradient Boosting Classifier, downsampled\n",
      "('Life Stage Training Accuracy: ', 1.0)\n",
      "('Life Stage Training Precision: ', 1.0)\n",
      "('Life Stage Training Recall: ', 1.0)\n",
      "Life Stage Training Confusion Matrix:\n",
      "[[1255    0    0    0    0    0]\n",
      " [   0 1255    0    0    0    0]\n",
      " [   0    0 1255    0    0    0]\n",
      " [   0    0    0 1255    0    0]\n",
      " [   0    0    0    0 1255    0]\n",
      " [   0    0    0    0    0 1255]]\n",
      "('Life Stage Testing Accuracy: ', 0.4127659574468085)\n",
      "('Life Stage Testing Precision: ', 0.53441283797437411)\n",
      "('Life Stage Testing Recall: ', 0.4127659574468085)\n",
      "Life Stage Testing Confusion Matrix:\n",
      "[[ 434  179  185  440  258  140]\n",
      " [  49  130   56   24   86  156]\n",
      " [ 670  603 2986  712 1035  624]\n",
      " [ 197   34  127  660   53   26]\n",
      " [ 292  259  231  144  683  297]\n",
      " [ 159  334  173   85  238  636]]\n",
      "Gradient Boosting Classifier, upsampled\n",
      "('Life Stage Training Accuracy: ', 0.9999784890724488)\n",
      "('Life Stage Training Precision: ', 0.99997849184841059)\n",
      "('Life Stage Training Recall: ', 0.9999784890724488)\n",
      "Life Stage Training Confusion Matrix:\n",
      "[[15496     0     0     0     0     0]\n",
      " [    0 15496     0     0     0     0]\n",
      " [    0     0 15494     0     2     0]\n",
      " [    0     0     0 15496     0     0]\n",
      " [    0     0     0     0 15496     0]\n",
      " [    0     0     0     0     0 15496]]\n",
      "('Life Stage Testing Accuracy: ', 0.51407241508025381)\n",
      "('Life Stage Testing Precision: ', 0.45331116072298172)\n",
      "('Life Stage Testing Recall: ', 0.51407241508025381)\n",
      "Life Stage Testing Confusion Matrix:\n",
      "[[ 224    0 1130  109  111   62]\n",
      " [  13    0  331    0   38  119]\n",
      " [ 216    2 5538  167  389  318]\n",
      " [ 167    0  622  286   13    9]\n",
      " [ 101    1 1288   29  350  137]\n",
      " [  54    1  957   14  111  488]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc_LS = GradientBoostingClassifier(learning_rate=0.05, n_estimators=1000, max_depth=10)\n",
    "balanced_gbc_LS = GradientBoostingClassifier(learning_rate=0.05, n_estimators=1000, max_depth=10)\n",
    "upsampled_gbc_LS=GradientBoostingClassifier(learning_rate=0.05, n_estimators=1000, max_depth=10)\n",
    "#gbc_ls = GradientBoostingClassifier(learning_rate=0.05, n_estimators=1000, max_depth=10)\n",
    "\n",
    "gbc_LS = gbc_LS.fit(train_X, train_y_LS)\n",
    "balanced_gbc_LS = balanced_gbc_LS.fit(balanced_LS_train_X, balanced_LS_train_y_LS)\n",
    "upsampled_gbc_LS = upsampled_gbc_LS.fit(upsampled_LS_train_X, upsampled_LS_train_y_LS)\n",
    "\n",
    "\n",
    "tryClassifier_LS (\"Gradient Boosting Classifier, reg\",gbc_LS, train_X, test_X, train_y_LS, test_y_LS)\n",
    "tryClassifier_LS (\"Gradient Boosting Classifier, downsampled\" ,balanced_gbc_LS, balanced_LS_train_X, test_X, balanced_LS_train_y_LS, test_y_LS)\n",
    "tryClassifier_LS (\"Gradient Boosting Classifier, upsampled\" ,upsampled_gbc_LS, upsampled_LS_train_X, test_X, upsampled_LS_train_y_LS, test_y_LS)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## sample output\n",
    "Gradient Boosting Classifier, reg\n",
    "('Life Stage Training Accuracy: ', 0.99993600819095152)\n",
    "('Life Stage Training Precision: ', 0.99993601644902474)\n",
    "('Life Stage Training Recall: ', 0.99993600819095152)\n",
    "Life Stage Training Confusion Matrix:\n",
    "[[ 3723     0     0     0     0     0]\n",
    " [    0  1255     0     0     0     0]\n",
    " [    0     0 15496     0     0     0]\n",
    " [    0     0     0  2503     0     0]\n",
    " [    0     0     2     0  4467     0]\n",
    " [    0     0     0     0     0  3808]]\n",
    "('Life Stage Testing Accuracy: ', 0.51623740201567747)\n",
    "('Life Stage Testing Precision: ', 0.46368300558700754)\n",
    "('Life Stage Testing Recall: ', 0.51623740201567747)\n",
    "Life Stage Testing Confusion Matrix:\n",
    "[[ 151    0 1287   95   55   48]\n",
    " [   7    5  370    2   16  101]\n",
    " [ 111    5 5937  148  155  274]\n",
    " [ 105    0  730  251    5    6]\n",
    " [  55    3 1554   23  165  106]\n",
    " [  28    2 1129   11   49  406]]\n",
    "Gradient Boosting Classifier, downsampled\n",
    "('Life Stage Training Accuracy: ', 1.0)\n",
    "('Life Stage Training Precision: ', 1.0)\n",
    "('Life Stage Training Recall: ', 1.0)\n",
    "Life Stage Training Confusion Matrix:\n",
    "[[1255    0    0    0    0    0]\n",
    " [   0 1255    0    0    0    0]\n",
    " [   0    0 1255    0    0    0]\n",
    " [   0    0    0 1255    0    0]\n",
    " [   0    0    0    0 1255    0]\n",
    " [   0    0    0    0    0 1255]]\n",
    "('Life Stage Testing Accuracy: ', 0.4127659574468085)\n",
    "('Life Stage Testing Precision: ', 0.53441283797437411)\n",
    "('Life Stage Testing Recall: ', 0.4127659574468085)\n",
    "Life Stage Testing Confusion Matrix:\n",
    "[[ 434  179  185  440  258  140]\n",
    " [  49  130   56   24   86  156]\n",
    " [ 670  603 2986  712 1035  624]\n",
    " [ 197   34  127  660   53   26]\n",
    " [ 292  259  231  144  683  297]\n",
    " [ 159  334  173   85  238  636]]\n",
    "Gradient Boosting Classifier, upsampled\n",
    "('Life Stage Training Accuracy: ', 0.9999784890724488)\n",
    "('Life Stage Training Precision: ', 0.99997849184841059)\n",
    "('Life Stage Training Recall: ', 0.9999784890724488)\n",
    "Life Stage Training Confusion Matrix:\n",
    "[[15496     0     0     0     0     0]\n",
    " [    0 15496     0     0     0     0]\n",
    " [    0     0 15494     0     2     0]\n",
    " [    0     0     0 15496     0     0]\n",
    " [    0     0     0     0 15496     0]\n",
    " [    0     0     0     0     0 15496]]\n",
    "('Life Stage Testing Accuracy: ', 0.51407241508025381)\n",
    "('Life Stage Testing Precision: ', 0.45331116072298172)\n",
    "('Life Stage Testing Recall: ', 0.51407241508025381)\n",
    "Life Stage Testing Confusion Matrix:\n",
    "[[ 224    0 1130  109  111   62]\n",
    " [  13    0  331    0   38  119]\n",
    " [ 216    2 5538  167  389  318]\n",
    " [ 167    0  622  286   13    9]\n",
    " [ 101    1 1288   29  350  137]\n",
    " [  54    1  957   14  111  488]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier, reg\n",
      "('Price Sensitivity Training Accuracy: ', 0.59973123440199649)\n",
      "('Price Sensitivity Training Precision: ', 0.60491262994696227)\n",
      "('Price Sensitivity Training Recall: ', 0.59973123440199649)\n",
      "Price Sensitivity Training Confusion Matrix:\n",
      "[[3675 2971  639  182]\n",
      " [2060 8226 1153  189]\n",
      " [1107 3673 3000  156]\n",
      " [ 123  192   65 3843]]\n",
      "('Price Sensitivity Testing Accuracy: ', 0.48294139604329972)\n",
      "('Price Sensitivity Testing Precision: ', 0.47775244257402044)\n",
      "('Price Sensitivity Testing Recall: ', 0.48294139604329972)\n",
      "Price Sensitivity Testing Confusion Matrix:\n",
      "[[1120 1666  343   93]\n",
      " [1233 2841  793  108]\n",
      " [ 553 1869  861   71]\n",
      " [  64   91   42 1647]]\n",
      "KNN Classifier, downsampled\n",
      "('Price Sensitivity Training Accuracy: ', 0.63485673691688371)\n",
      "('Price Sensitivity Training Precision: ', 0.63232962952582328)\n",
      "('Price Sensitivity Training Recall: ', 0.63485673691688371)\n",
      "Price Sensitivity Training Confusion Matrix:\n",
      "[[2598  900  518  207]\n",
      " [1258 2096  726  143]\n",
      " [ 947 1107 2012  157]\n",
      " [  79   61   65 4018]]\n",
      "('Price Sensitivity Testing Accuracy: ', 0.46368047779022026)\n",
      "('Price Sensitivity Testing Precision: ', 0.46014519763322181)\n",
      "('Price Sensitivity Testing Recall: ', 0.46368047779022026)\n",
      "Price Sensitivity Testing Confusion Matrix:\n",
      "[[1576  945  509  192]\n",
      " [1876 1710 1170  219]\n",
      " [ 908 1114 1190  142]\n",
      " [  40   35   34 1735]]\n",
      "KNN Classifier, upsampled\n",
      "('Price Sensitivity Training Accuracy: ', 0.66817165462676298)\n",
      "('Price Sensitivity Training Precision: ', 0.66613784006329035)\n",
      "('Price Sensitivity Training Recall: ', 0.66817165462676298)\n",
      "Price Sensitivity Training Confusion Matrix:\n",
      "[[ 8011  1910  1342   365]\n",
      " [ 3569  5616  2120   323]\n",
      " [ 2333  2674  6316   305]\n",
      " [  191   130   172 11135]]\n",
      "('Price Sensitivity Testing Accuracy: ', 0.45987308697275103)\n",
      "('Price Sensitivity Testing Precision: ', 0.45977884876241937)\n",
      "('Price Sensitivity Testing Recall: ', 0.45987308697275103)\n",
      "Price Sensitivity Testing Confusion Matrix:\n",
      "[[1561  953  562  146]\n",
      " [1916 1691 1197  171]\n",
      " [ 893 1132 1217  112]\n",
      " [  62   40   51 1691]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_ps = KNeighborsClassifier(n_neighbors=10)\n",
    "balanced_knn_ps = KNeighborsClassifier(n_neighbors=10)\n",
    "upsampled_knn_ps = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "knn_ps = knn_ps.fit(train_X,train_y_PS)\n",
    "balanced_knn_ps = balanced_knn_ps.fit(balanced_PS_train_X,balanced_PS_train_y_PS)\n",
    "upsampled_knn_ps = upsampled_knn_ps.fit(upsampled_PS_train_X, upsampled_PS_train_y_PS)\n",
    "\n",
    "tryClassifier_PS (\"KNN Classifier, reg\",knn_ps, train_X, test_X, train_y_PS, test_y_PS)\n",
    "tryClassifier_PS (\"KNN Classifier, downsampled\",balanced_knn_ps, balanced_PS_train_X, test_X, balanced_PS_train_y_PS, test_y_PS)\n",
    "tryClassifier_PS (\"KNN Classifier, upsampled\",upsampled_knn_ps, upsampled_PS_train_X, test_X, upsampled_PS_train_y_PS, test_y_PS)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## sample output\n",
    "KNN Classifier, reg\n",
    "('Price Sensitivity Training Accuracy: ', 0.59973123440199649)\n",
    "('Price Sensitivity Training Precision: ', 0.60491262994696227)\n",
    "('Price Sensitivity Training Recall: ', 0.59973123440199649)\n",
    "Price Sensitivity Training Confusion Matrix:\n",
    "[[3675 2971  639  182]\n",
    " [2060 8226 1153  189]\n",
    " [1107 3673 3000  156]\n",
    " [ 123  192   65 3843]]\n",
    "('Price Sensitivity Testing Accuracy: ', 0.48294139604329972)\n",
    "('Price Sensitivity Testing Precision: ', 0.47775244257402044)\n",
    "('Price Sensitivity Testing Recall: ', 0.48294139604329972)\n",
    "Price Sensitivity Testing Confusion Matrix:\n",
    "[[1120 1666  343   93]\n",
    " [1233 2841  793  108]\n",
    " [ 553 1869  861   71]\n",
    " [  64   91   42 1647]]\n",
    "KNN Classifier, downsampled\n",
    "('Price Sensitivity Training Accuracy: ', 0.63485673691688371)\n",
    "('Price Sensitivity Training Precision: ', 0.63232962952582328)\n",
    "('Price Sensitivity Training Recall: ', 0.63485673691688371)\n",
    "Price Sensitivity Training Confusion Matrix:\n",
    "[[2598  900  518  207]\n",
    " [1258 2096  726  143]\n",
    " [ 947 1107 2012  157]\n",
    " [  79   61   65 4018]]\n",
    "('Price Sensitivity Testing Accuracy: ', 0.46368047779022026)\n",
    "('Price Sensitivity Testing Precision: ', 0.46014519763322181)\n",
    "('Price Sensitivity Testing Recall: ', 0.46368047779022026)\n",
    "Price Sensitivity Testing Confusion Matrix:\n",
    "[[1576  945  509  192]\n",
    " [1876 1710 1170  219]\n",
    " [ 908 1114 1190  142]\n",
    " [  40   35   34 1735]]\n",
    "KNN Classifier, upsampled\n",
    "('Price Sensitivity Training Accuracy: ', 0.66817165462676298)\n",
    "('Price Sensitivity Training Precision: ', 0.66613784006329035)\n",
    "('Price Sensitivity Training Recall: ', 0.66817165462676298)\n",
    "Price Sensitivity Training Confusion Matrix:\n",
    "[[ 8011  1910  1342   365]\n",
    " [ 3569  5616  2120   323]\n",
    " [ 2333  2674  6316   305]\n",
    " [  191   130   172 11135]]\n",
    "('Price Sensitivity Testing Accuracy: ', 0.45987308697275103)\n",
    "('Price Sensitivity Testing Precision: ', 0.45977884876241937)\n",
    "('Price Sensitivity Testing Recall: ', 0.45987308697275103)\n",
    "Price Sensitivity Testing Confusion Matrix:\n",
    "[[1561  953  562  146]\n",
    " [1916 1691 1197  171]\n",
    " [ 893 1132 1217  112]\n",
    " [  62   40   51 1691]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier, reg\n",
      "('Life Stage Training Accuracy: ', 0.5651116657067895)\n",
      "('Life Stage Training Precision: ', 0.5279202770853334)\n",
      "('Life Stage Training Recall: ', 0.5651116657067895)\n",
      "Life Stage Training Confusion Matrix:\n",
      "[[ 1037    31  1879   173   309   294]\n",
      " [  107    95   654    10   138   251]\n",
      " [  574    70 13453   191   619   589]\n",
      " [  350    11  1315   620   111    96]\n",
      " [  328    45  2499    72  1159   366]\n",
      " [  260    73  1752    55   370  1298]]\n",
      "('Life Stage Testing Accuracy: ', 0.46868234415826798)\n",
      "('Life Stage Testing Precision: ', 0.40507190338460847)\n",
      "('Life Stage Testing Recall: ', 0.46868234415826798)\n",
      "Life Stage Testing Confusion Matrix:\n",
      "[[ 228   16  953   98  169  172]\n",
      " [  32   16  305    6   51   91]\n",
      " [ 362   51 5235  162  429  391]\n",
      " [ 197    7  642  149   50   52]\n",
      " [ 155   25 1189   46  280  211]\n",
      " [ 137   37  877   22  182  370]]\n",
      "KNN Classifier, downsampled\n",
      "('Life Stage Training Accuracy: ', 0.68472775564409027)\n",
      "('Life Stage Training Precision: ', 0.68038839037965038)\n",
      "('Life Stage Training Recall: ', 0.68472775564409027)\n",
      "Life Stage Training Confusion Matrix:\n",
      "[[ 830   71   50  119   94   91]\n",
      " [   2 1252    0    0    0    1]\n",
      " [ 167  116  515  131  181  145]\n",
      " [  68   29   33 1081   14   30]\n",
      " [ 142   87   88   80  716  142]\n",
      " [ 128  123   50   66  126  762]]\n",
      "('Life Stage Testing Accuracy: ', 0.30220231429637923)\n",
      "('Life Stage Testing Precision: ', 0.47666570553556259)\n",
      "('Life Stage Testing Recall: ', 0.30220231429637923)\n",
      "Life Stage Testing Confusion Matrix:\n",
      "[[ 390  202  147  317  270  310]\n",
      " [  90   93   42   50  104  122]\n",
      " [ 978  614 2258  903  971  906]\n",
      " [ 285   98  117  365  130  102]\n",
      " [ 365  265  194  233  452  397]\n",
      " [ 282  271  144  144  294  490]]\n",
      "KNN Classifier, upsampled\n",
      "('Life Stage Training Accuracy: ', 0.73646962657029769)\n",
      "('Life Stage Training Precision: ', 0.73497477215608908)\n",
      "('Life Stage Training Recall: ', 0.73646962657029769)\n",
      "Life Stage Training Confusion Matrix:\n",
      "[[12052   547   382   882   792   841]\n",
      " [    6 15486     0     0     0     4]\n",
      " [ 2287  1372  6121  1809  2090  1817]\n",
      " [  606   189   259 14114   146   182]\n",
      " [ 1463  1032   892   880  9938  1291]\n",
      " [ 1075  1156   491   724  1287 10763]]\n",
      "('Life Stage Testing Accuracy: ', 0.30220231429637923)\n",
      "('Life Stage Testing Precision: ', 0.47666570553556259)\n",
      "('Life Stage Testing Recall: ', 0.30220231429637923)\n",
      "Life Stage Testing Confusion Matrix:\n",
      "[[ 390  202  147  317  270  310]\n",
      " [  90   93   42   50  104  122]\n",
      " [ 978  614 2258  903  971  906]\n",
      " [ 285   98  117  365  130  102]\n",
      " [ 365  265  194  233  452  397]\n",
      " [ 282  271  144  144  294  490]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_LS = KNeighborsClassifier(n_neighbors=10)\n",
    "balanced_knn_LS = KNeighborsClassifier(n_neighbors=10)\n",
    "upsampled_knn_LS = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "\n",
    "knn_LS = knn_LS.fit(train_X,train_y_LS)\n",
    "balanced_knn_LS = balanced_knn_LS.fit(balanced_LS_train_X,balanced_LS_train_y_LS)\n",
    "balanced_knn_LS = balanced_knn_LS.fit(upsampled_LS_train_X, upsampled_LS_train_y_LS)\n",
    "\n",
    "tryClassifier_LS (\"KNN Classifier, reg\",knn_LS, train_X, test_X, train_y_LS, test_y_LS)\n",
    "tryClassifier_LS (\"KNN Classifier, downsampled\",balanced_knn_LS, balanced_LS_train_X, test_X, balanced_LS_train_y_LS, test_y_LS)\n",
    "tryClassifier_LS (\"KNN Classifier, upsampled\" ,balanced_knn_LS, upsampled_LS_train_X, test_X, upsampled_LS_train_y_LS, test_y_LS)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## sample output\n",
    "KNN Classifier, reg\n",
    "('Life Stage Training Accuracy: ', 0.5651116657067895)\n",
    "('Life Stage Training Precision: ', 0.5279202770853334)\n",
    "('Life Stage Training Recall: ', 0.5651116657067895)\n",
    "Life Stage Training Confusion Matrix:\n",
    "[[ 1037    31  1879   173   309   294]\n",
    " [  107    95   654    10   138   251]\n",
    " [  574    70 13453   191   619   589]\n",
    " [  350    11  1315   620   111    96]\n",
    " [  328    45  2499    72  1159   366]\n",
    " [  260    73  1752    55   370  1298]]\n",
    "('Life Stage Testing Accuracy: ', 0.46868234415826798)\n",
    "('Life Stage Testing Precision: ', 0.40507190338460847)\n",
    "('Life Stage Testing Recall: ', 0.46868234415826798)\n",
    "Life Stage Testing Confusion Matrix:\n",
    "[[ 228   16  953   98  169  172]\n",
    " [  32   16  305    6   51   91]\n",
    " [ 362   51 5235  162  429  391]\n",
    " [ 197    7  642  149   50   52]\n",
    " [ 155   25 1189   46  280  211]\n",
    " [ 137   37  877   22  182  370]]\n",
    "KNN Classifier, downsampled\n",
    "('Life Stage Training Accuracy: ', 0.68472775564409027)\n",
    "('Life Stage Training Precision: ', 0.68038839037965038)\n",
    "('Life Stage Training Recall: ', 0.68472775564409027)\n",
    "Life Stage Training Confusion Matrix:\n",
    "[[ 830   71   50  119   94   91]\n",
    " [   2 1252    0    0    0    1]\n",
    " [ 167  116  515  131  181  145]\n",
    " [  68   29   33 1081   14   30]\n",
    " [ 142   87   88   80  716  142]\n",
    " [ 128  123   50   66  126  762]]\n",
    "('Life Stage Testing Accuracy: ', 0.30220231429637923)\n",
    "('Life Stage Testing Precision: ', 0.47666570553556259)\n",
    "('Life Stage Testing Recall: ', 0.30220231429637923)\n",
    "Life Stage Testing Confusion Matrix:\n",
    "[[ 390  202  147  317  270  310]\n",
    " [  90   93   42   50  104  122]\n",
    " [ 978  614 2258  903  971  906]\n",
    " [ 285   98  117  365  130  102]\n",
    " [ 365  265  194  233  452  397]\n",
    " [ 282  271  144  144  294  490]]\n",
    "KNN Classifier, upsampled\n",
    "('Life Stage Training Accuracy: ', 0.73646962657029769)\n",
    "('Life Stage Training Precision: ', 0.73497477215608908)\n",
    "('Life Stage Training Recall: ', 0.73646962657029769)\n",
    "Life Stage Training Confusion Matrix:\n",
    "[[12052   547   382   882   792   841]\n",
    " [    6 15486     0     0     0     4]\n",
    " [ 2287  1372  6121  1809  2090  1817]\n",
    " [  606   189   259 14114   146   182]\n",
    " [ 1463  1032   892   880  9938  1291]\n",
    " [ 1075  1156   491   724  1287 10763]]\n",
    "('Life Stage Testing Accuracy: ', 0.30220231429637923)\n",
    "('Life Stage Testing Precision: ', 0.47666570553556259)\n",
    "('Life Stage Testing Recall: ', 0.30220231429637923)\n",
    "Life Stage Testing Confusion Matrix:\n",
    "[[ 390  202  147  317  270  310]\n",
    " [  90   93   42   50  104  122]\n",
    " [ 978  614 2258  903  971  906]\n",
    " [ 285   98  117  365  130  102]\n",
    " [ 365  265  194  233  452  397]\n",
    " [ 282  271  144  144  294  490]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier, reg\n",
      "('Price Sensitivity Training Accuracy: ', 0.4294170346195687)\n",
      "('Price Sensitivity Training Precision: ', 0.46250924747087663)\n",
      "('Price Sensitivity Training Recall: ', 0.4294170346195687)\n",
      "Price Sensitivity Training Confusion Matrix:\n",
      "[[3355 2488 1465  159]\n",
      " [3595 4777 3060  196]\n",
      " [1571 2811 3446  108]\n",
      " [1355   45  980 1843]]\n",
      "('Price Sensitivity Testing Accuracy: ', 0.42792086599477419)\n",
      "('Price Sensitivity Testing Precision: ', 0.46286154136435592)\n",
      "('Price Sensitivity Testing Recall: ', 0.42792086599477419)\n",
      "Price Sensitivity Testing Confusion Matrix:\n",
      "[[1462 1092  609   59]\n",
      " [1579 2047 1278   71]\n",
      " [ 686 1196 1416   56]\n",
      " [ 585   25  427  807]]\n",
      "MLP Classifier, downsampled\n",
      "('Price Sensitivity Training Accuracy: ', 0.3149419843713)\n",
      "('Price Sensitivity Training Precision: ', 0.26623107099909754)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Price Sensitivity Training Recall: ', 0.3149419843713)\n",
      "Price Sensitivity Training Confusion Matrix:\n",
      "[[   0 2216 1621  386]\n",
      " [   0 2143 1713  367]\n",
      " [   0 1761 2027  435]\n",
      " [   0 1365 1708 1150]]\n",
      "('Price Sensitivity Testing Accuracy: ', 0.34199328107502802)\n",
      "('Price Sensitivity Testing Precision: ', 0.26229036095301422)\n",
      "('Price Sensitivity Testing Recall: ', 0.34199328107502802)\n",
      "Price Sensitivity Testing Confusion Matrix:\n",
      "[[   0 1655 1243  324]\n",
      " [   0 2512 1998  465]\n",
      " [   0 1417 1609  328]\n",
      " [   0  621  763  460]]\n",
      "MLP Classifier, upsampled\n",
      "('Price Sensitivity Training Accuracy: ', 0.31357499140006878)\n",
      "('Price Sensitivity Training Precision: ', 0.27270864467931732)\n",
      "('Price Sensitivity Training Recall: ', 0.31357499140006878)\n",
      "Price Sensitivity Training Confusion Matrix:\n",
      "[[   0 6274 4477  877]\n",
      " [   0 6154 4643  831]\n",
      " [   0 5114 5576  938]\n",
      " [   0 3794 4979 2855]]\n",
      "('Price Sensitivity Testing Accuracy: ', 0.34572601717058604)\n",
      "('Price Sensitivity Testing Precision: ', 0.26554102519351314)\n",
      "('Price Sensitivity Testing Recall: ', 0.34572601717058604)\n",
      "Price Sensitivity Testing Confusion Matrix:\n",
      "[[   0 1747 1227  248]\n",
      " [   0 2610 1987  378]\n",
      " [   0 1501 1598  255]\n",
      " [   0  624  797  423]]\n",
      "MLP Classifier Scaled, reg\n",
      "('Price Sensitivity Training Accuracy: ', 0.60488257503039611)\n",
      "('Price Sensitivity Training Precision: ', 0.6138286578003076)\n",
      "('Price Sensitivity Training Recall: ', 0.60488257503039611)\n",
      "Price Sensitivity Training Confusion Matrix:\n",
      "[[3026 3765  288  388]\n",
      " [1622 7813 1807  386]\n",
      " [ 220 3347 4101  268]\n",
      " [  38  183   37 3965]]\n",
      "('Price Sensitivity Testing Accuracy: ', 0.59962672639044423)\n",
      "('Price Sensitivity Testing Precision: ', 0.60815799387493874)\n",
      "('Price Sensitivity Testing Recall: ', 0.59962672639044423)\n",
      "Price Sensitivity Testing Confusion Matrix:\n",
      "[[1269 1634  145  174]\n",
      " [ 716 3323  754  182]\n",
      " [  93 1418 1740  103]\n",
      " [  17  101   26 1700]]\n",
      "MLP Classifier Scaled, downsampled\n",
      "('Price Sensitivity Training Accuracy: ', 0.64971584181861242)\n",
      "('Price Sensitivity Training Precision: ', 0.63249076034333707)\n",
      "('Price Sensitivity Training Recall: ', 0.64971584181861242)\n",
      "Price Sensitivity Training Confusion Matrix:\n",
      "[[2772  709  373  369]\n",
      " [1486 1439 1025  273]\n",
      " [ 483  791 2679  270]\n",
      " [  81    6   51 4085]]\n",
      "('Price Sensitivity Testing Accuracy: ', 0.56005972377752888)\n",
      "('Price Sensitivity Testing Precision: ', 0.56141551207754814)\n",
      "('Price Sensitivity Testing Recall: ', 0.56005972377752888)\n",
      "Price Sensitivity Testing Confusion Matrix:\n",
      "[[2063  592  285  282]\n",
      " [1804 1598 1241  332]\n",
      " [ 445  631 2079  199]\n",
      " [  53    3   26 1762]]\n",
      "MLP Classifier Scaled, upsampled\n",
      "('Price Sensitivity Training Accuracy: ', 0.64572583419332641)\n",
      "('Price Sensitivity Training Precision: ', 0.62604645171748519)\n",
      "('Price Sensitivity Training Recall: ', 0.64572583419332641)\n",
      "Price Sensitivity Training Confusion Matrix:\n",
      "[[ 7500  2044  1069  1015]\n",
      " [ 4076  3622  3220   710]\n",
      " [ 1384  1886  7655   703]\n",
      " [  230     4   137 11257]]\n",
      "('Price Sensitivity Testing Accuracy: ', 0.56648002986188872)\n",
      "('Price Sensitivity Testing Precision: ', 0.56982058230111743)\n",
      "('Price Sensitivity Testing Recall: ', 0.56648002986188872)\n",
      "Price Sensitivity Testing Confusion Matrix:\n",
      "[[2058  572  325  267]\n",
      " [1717 1569 1366  323]\n",
      " [ 431  535 2193  195]\n",
      " [  52    1   23 1768]]\n"
     ]
    }
   ],
   "source": [
    "#requires sklearn 0.18\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler #from http://www.kdnuggets.com/2016/10/beginners-guide-neural-networks-python-scikit-learn.html/2\n",
    "\n",
    "scaler=StandardScaler()\n",
    "balanced_scaler=StandardScaler()\n",
    "upsampled_scaler=StandardScaler()\n",
    "\n",
    "scaler.fit(train_X)\n",
    "balanced_scaler.fit(balanced_PS_train_X)\n",
    "upsampled_scaler.fit(upsampled_PS_train_X)\n",
    "\n",
    "\n",
    "scaled_X_train=scaler.transform(train_X)\n",
    "scaled_X_test=scaler.transform(test_X)\n",
    "scaled_balanced_PS_X_train=balanced_scaler.transform(balanced_PS_train_X)\n",
    "scaled_balanced_PS_X_test=balanced_scaler.transform(test_X)\n",
    "scaled_upsampled_PS_X_train=balanced_scaler.transform(upsampled_PS_train_X)\n",
    "scaled_upsampled_PS_X_test=balanced_scaler.transform(test_X)\n",
    "\n",
    "\n",
    "ann_PS = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 100,100), random_state=42)\n",
    "balanced_ann_PS = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 100,100), random_state=42)\n",
    "upsampled_ann_PS = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 100,100), random_state=42)\n",
    "scaled_ann_PS = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 100,100), random_state=42)\n",
    "scaled_balanced_ann_PS = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 100,100), random_state=42)\n",
    "scaled_upsampled_ann_PS = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 100,100), random_state=42)\n",
    "\n",
    "ann_PS = ann_PS.fit(train_X, train_y_PS)\n",
    "balanced_ann_PS = balanced_ann_PS.fit(balanced_PS_train_X, balanced_PS_train_y_PS)\n",
    "upsampled_ann_PS = upsampled_ann_PS.fit(upsampled_PS_train_X, upsampled_PS_train_y_PS)\n",
    "\n",
    "scaled_ann_PS = scaled_ann_PS.fit(scaled_X_train, train_y_PS)\n",
    "scaled_balanced_ann_PS = scaled_balanced_ann_PS.fit(scaled_balanced_PS_X_train, balanced_PS_train_y_PS)\n",
    "scaled_upsampled_ann_PS = scaled_upsampled_ann_PS.fit(scaled_upsampled_PS_X_train, upsampled_PS_train_y_PS)\n",
    "\n",
    "\n",
    "\n",
    "tryClassifier_PS (\"MLP Classifier, reg\",ann_PS, train_X, test_X, train_y_PS, test_y_PS)\n",
    "tryClassifier_PS (\"MLP Classifier, downsampled\",balanced_ann_PS, balanced_PS_train_X, test_X, balanced_PS_train_y_PS, test_y_PS)\n",
    "tryClassifier_PS (\"MLP Classifier, upsampled\",upsampled_ann_PS, upsampled_PS_train_X, test_X, upsampled_PS_train_y_PS, test_y_PS)\n",
    "\n",
    "tryClassifier_PS (\"MLP Classifier Scaled, reg\",scaled_ann_PS, scaled_X_train, scaled_X_test, train_y_PS, test_y_PS)\n",
    "tryClassifier_PS (\"MLP Classifier Scaled, downsampled\",scaled_balanced_ann_PS, scaled_balanced_PS_X_train, scaled_balanced_PS_X_test, balanced_PS_train_y_PS, test_y_PS)\n",
    "tryClassifier_PS (\"MLP Classifier Scaled, upsampled\",scaled_upsampled_ann_PS, scaled_upsampled_PS_X_train, scaled_upsampled_PS_X_test, upsampled_PS_train_y_PS, test_y_PS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample output:\n",
    "MLP Classifier, reg\n",
    "('Price Sensitivity Training Accuracy: ', 0.4294170346195687)\n",
    "('Price Sensitivity Training Precision: ', 0.46250924747087663)\n",
    "('Price Sensitivity Training Recall: ', 0.4294170346195687)\n",
    "Price Sensitivity Training Confusion Matrix:\n",
    "[[3355 2488 1465  159]\n",
    " [3595 4777 3060  196]\n",
    " [1571 2811 3446  108]\n",
    " [1355   45  980 1843]]\n",
    "('Price Sensitivity Testing Accuracy: ', 0.42792086599477419)\n",
    "('Price Sensitivity Testing Precision: ', 0.46286154136435592)\n",
    "('Price Sensitivity Testing Recall: ', 0.42792086599477419)\n",
    "Price Sensitivity Testing Confusion Matrix:\n",
    "[[1462 1092  609   59]\n",
    " [1579 2047 1278   71]\n",
    " [ 686 1196 1416   56]\n",
    " [ 585   25  427  807]]\n",
    "MLP Classifier, downsampled\n",
    "('Price Sensitivity Training Accuracy: ', 0.3149419843713)\n",
    "('Price Sensitivity Training Precision: ', 0.26623107099909754)\n",
    "C:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
    "  'precision', 'predicted', average, warn_for)\n",
    "('Price Sensitivity Training Recall: ', 0.3149419843713)\n",
    "Price Sensitivity Training Confusion Matrix:\n",
    "[[   0 2216 1621  386]\n",
    " [   0 2143 1713  367]\n",
    " [   0 1761 2027  435]\n",
    " [   0 1365 1708 1150]]\n",
    "('Price Sensitivity Testing Accuracy: ', 0.34199328107502802)\n",
    "('Price Sensitivity Testing Precision: ', 0.26229036095301422)\n",
    "('Price Sensitivity Testing Recall: ', 0.34199328107502802)\n",
    "Price Sensitivity Testing Confusion Matrix:\n",
    "[[   0 1655 1243  324]\n",
    " [   0 2512 1998  465]\n",
    " [   0 1417 1609  328]\n",
    " [   0  621  763  460]]\n",
    "MLP Classifier, upsampled\n",
    "('Price Sensitivity Training Accuracy: ', 0.31357499140006878)\n",
    "('Price Sensitivity Training Precision: ', 0.27270864467931732)\n",
    "('Price Sensitivity Training Recall: ', 0.31357499140006878)\n",
    "Price Sensitivity Training Confusion Matrix:\n",
    "[[   0 6274 4477  877]\n",
    " [   0 6154 4643  831]\n",
    " [   0 5114 5576  938]\n",
    " [   0 3794 4979 2855]]\n",
    "('Price Sensitivity Testing Accuracy: ', 0.34572601717058604)\n",
    "('Price Sensitivity Testing Precision: ', 0.26554102519351314)\n",
    "('Price Sensitivity Testing Recall: ', 0.34572601717058604)\n",
    "Price Sensitivity Testing Confusion Matrix:\n",
    "[[   0 1747 1227  248]\n",
    " [   0 2610 1987  378]\n",
    " [   0 1501 1598  255]\n",
    " [   0  624  797  423]]\n",
    "MLP Classifier Scaled, reg\n",
    "('Price Sensitivity Training Accuracy: ', 0.60488257503039611)\n",
    "('Price Sensitivity Training Precision: ', 0.6138286578003076)\n",
    "('Price Sensitivity Training Recall: ', 0.60488257503039611)\n",
    "Price Sensitivity Training Confusion Matrix:\n",
    "[[3026 3765  288  388]\n",
    " [1622 7813 1807  386]\n",
    " [ 220 3347 4101  268]\n",
    " [  38  183   37 3965]]\n",
    "('Price Sensitivity Testing Accuracy: ', 0.59962672639044423)\n",
    "('Price Sensitivity Testing Precision: ', 0.60815799387493874)\n",
    "('Price Sensitivity Testing Recall: ', 0.59962672639044423)\n",
    "Price Sensitivity Testing Confusion Matrix:\n",
    "[[1269 1634  145  174]\n",
    " [ 716 3323  754  182]\n",
    " [  93 1418 1740  103]\n",
    " [  17  101   26 1700]]\n",
    "MLP Classifier Scaled, downsampled\n",
    "('Price Sensitivity Training Accuracy: ', 0.64971584181861242)\n",
    "('Price Sensitivity Training Precision: ', 0.63249076034333707)\n",
    "('Price Sensitivity Training Recall: ', 0.64971584181861242)\n",
    "Price Sensitivity Training Confusion Matrix:\n",
    "[[2772  709  373  369]\n",
    " [1486 1439 1025  273]\n",
    " [ 483  791 2679  270]\n",
    " [  81    6   51 4085]]\n",
    "('Price Sensitivity Testing Accuracy: ', 0.56005972377752888)\n",
    "('Price Sensitivity Testing Precision: ', 0.56141551207754814)\n",
    "('Price Sensitivity Testing Recall: ', 0.56005972377752888)\n",
    "Price Sensitivity Testing Confusion Matrix:\n",
    "[[2063  592  285  282]\n",
    " [1804 1598 1241  332]\n",
    " [ 445  631 2079  199]\n",
    " [  53    3   26 1762]]\n",
    "MLP Classifier Scaled, upsampled\n",
    "('Price Sensitivity Training Accuracy: ', 0.64572583419332641)\n",
    "('Price Sensitivity Training Precision: ', 0.62604645171748519)\n",
    "('Price Sensitivity Training Recall: ', 0.64572583419332641)\n",
    "Price Sensitivity Training Confusion Matrix:\n",
    "[[ 7500  2044  1069  1015]\n",
    " [ 4076  3622  3220   710]\n",
    " [ 1384  1886  7655   703]\n",
    " [  230     4   137 11257]]\n",
    "('Price Sensitivity Testing Accuracy: ', 0.56648002986188872)\n",
    "('Price Sensitivity Testing Precision: ', 0.56982058230111743)\n",
    "('Price Sensitivity Testing Recall: ', 0.56648002986188872)\n",
    "Price Sensitivity Testing Confusion Matrix:\n",
    "[[2058  572  325  267]\n",
    " [1717 1569 1366  323]\n",
    " [ 431  535 2193  195]\n",
    " [  52    1   23 1768]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier, reg\n",
      "('Life Stage Training Accuracy: ', 0.17968899980802458)\n",
      "('Life Stage Training Precision: ', 0.2298118760958785)\n",
      "('Life Stage Training Recall: ', 0.17968899980802458)\n",
      "Life Stage Training Confusion Matrix:\n",
      "[[ 669  229 1337  105  137 1246]\n",
      " [ 220   85  581   29   40  300]\n",
      " [2875 1648 3690  782 1900 4601]\n",
      " [ 345  166  837   74  126  955]\n",
      " [ 796  307 1530  106  188 1542]\n",
      " [ 638  239 1818   73  130  910]]\n",
      "('Life Stage Testing Accuracy: ', 0.17991787980589771)\n",
      "('Life Stage Testing Precision: ', 0.23110982790006593)\n",
      "('Life Stage Testing Recall: ', 0.17991787980589771)\n",
      "Life Stage Testing Confusion Matrix:\n",
      "[[ 284   91  576   45   60  580]\n",
      " [ 105   33  198   11   20  134]\n",
      " [1161  746 1598  362  846 1917]\n",
      " [ 155   78  352   40   59  413]\n",
      " [ 311  138  702   38   66  651]\n",
      " [ 258  106  763   53   56  389]]\n",
      "MLP Classifier, downsampled\n",
      "('Life Stage Training Accuracy: ', 0.29229747675962814)\n",
      "('Life Stage Training Precision: ', 0.30431890396068667)\n",
      "('Life Stage Training Recall: ', 0.29229747675962814)\n",
      "Life Stage Training Confusion Matrix:\n",
      "[[139 158 112 302 409 135]\n",
      " [ 80 295 138  89 379 274]\n",
      " [ 45 123 255 145 605  82]\n",
      " [ 93  71 110 571 357  53]\n",
      " [ 74 181 135 125 571 169]\n",
      " [ 95 265 102  75 348 370]]\n",
      "('Life Stage Testing Accuracy: ', 0.24516610675625233)\n",
      "('Life Stage Testing Precision: ', 0.42953691757810564)\n",
      "('Life Stage Testing Recall: ', 0.24516610675625233)\n",
      "Life Stage Testing Confusion Matrix:\n",
      "[[ 169  175  177  419  524  172]\n",
      " [  36  101   56   31  170  107]\n",
      " [ 288  711 1254  752 3170  455]\n",
      " [  76   58   92  500  322   49]\n",
      " [  94  292  199  196  855  270]\n",
      " [ 121  321  131  127  520  405]]\n",
      "MLP Classifier, upsampled\n",
      "('Life Stage Training Accuracy: ', 0.27628635346756153)\n",
      "('Life Stage Training Precision: ', 0.28965059116452474)\n",
      "('Life Stage Training Recall: ', 0.27628635346756153)\n",
      "Life Stage Training Confusion Matrix:\n",
      "[[1702 1808 1766 3312 5104 1804]\n",
      " [1082 4038 1716  829 4580 3251]\n",
      " [ 739 1327 3057 1558 7675 1140]\n",
      " [1386  653 1455 6538 4482  982]\n",
      " [1273 2501 2031 1267 6252 2172]\n",
      " [1083 3638 1554  972 4148 4101]]\n",
      "('Life Stage Testing Accuracy: ', 0.23979096677864875)\n",
      "('Life Stage Testing Precision: ', 0.41057951560607431)\n",
      "('Life Stage Testing Recall: ', 0.23979096677864875)\n",
      "Life Stage Testing Confusion Matrix:\n",
      "[[ 190  167  190  378  507  204]\n",
      " [  35  113   53   35  156  109]\n",
      " [ 320  576 1295  660 3246  533]\n",
      " [ 115   46  111  451  295   79]\n",
      " [ 122  313  245  180  768  278]\n",
      " [ 139  383  160   93  455  395]]\n",
      "MLP Classifier Scaled, reg\n",
      "('Life Stage Training Accuracy: ', 0.64724515262046456)\n",
      "('Life Stage Training Precision: ', 0.63508407459386296)\n",
      "('Life Stage Training Recall: ', 0.64724515262046456)\n",
      "Life Stage Training Confusion Matrix:\n",
      "[[ 1532    26  1565   281   178   141]\n",
      " [   86   237   544     5    73   310]\n",
      " [  411    38 13581   378   683   405]\n",
      " [  267     2   925  1247    30    32]\n",
      " [  264    14  2267    50  1624   250]\n",
      " [  155    77  1295    39   234  2008]]\n",
      "('Life Stage Testing Accuracy: ', 0.49264650989175063)\n",
      "('Life Stage Testing Precision: ', 0.44363126279488707)\n",
      "('Life Stage Testing Recall: ', 0.49264650989175063)\n",
      "Life Stage Testing Confusion Matrix:\n",
      "[[ 308   15  841  186  171  115]\n",
      " [  38    7  275    4   49  128]\n",
      " [ 342   53 5103  246  494  392]\n",
      " [ 173    3  533  340   21   27]\n",
      " [ 178   27 1084   56  366  195]\n",
      " [ 121   40  768   36  185  475]]\n",
      "MLP Classifier Scaled, downsampled\n",
      "('Life Stage Training Accuracy: ', 0.7626826029216468)\n",
      "('Life Stage Training Precision: ', 0.77453653093601682)\n",
      "('Life Stage Training Recall: ', 0.7626826029216468)\n",
      "Life Stage Training Confusion Matrix:\n",
      "[[ 872   27  136   99   89   32]\n",
      " [  27  995  102   22   67   42]\n",
      " [  37   27 1025   63   84   19]\n",
      " [  62   10  152  996   27    8]\n",
      " [  77   58  158   38  898   26]\n",
      " [  30   80   94   23   71  957]]\n",
      "('Life Stage Testing Accuracy: ', 0.39283314669652858)\n",
      "('Life Stage Testing Precision: ', 0.49172606939455604)\n",
      "('Life Stage Testing Recall: ', 0.39283314669652858)\n",
      "Life Stage Testing Confusion Matrix:\n",
      "[[ 373  191  271  387  270  144]\n",
      " [  61  122   84   25   84  125]\n",
      " [ 641  668 3151  641  990  539]\n",
      " [ 212   50  194  550   65   26]\n",
      " [ 317  293  309  155  609  223]\n",
      " [ 182  363  269   84  270  457]]\n",
      "MLP Classifier Scaled, downsampled\n",
      "('Life Stage Training Accuracy: ', 0.62904405437962485)\n",
      "('Life Stage Training Precision: ', 0.62581264592511332)\n",
      "('Life Stage Training Recall: ', 0.62904405437962485)\n",
      "Life Stage Training Confusion Matrix:\n",
      "[[ 8183   559  1357  2415  1996   986]\n",
      " [  222 13166  1034   231   609   234]\n",
      " [ 1562   757  7355  1647  2703  1472]\n",
      " [ 1313   188  1520 11800   456   219]\n",
      " [ 1756   724  1669   844  8419  2084]\n",
      " [ 1094   805  1222   573  2239  9563]]\n",
      "('Life Stage Testing Accuracy: ', 0.41799178798058978)\n",
      "('Life Stage Testing Precision: ', 0.53504674015698228)\n",
      "('Life Stage Testing Recall: ', 0.41799178798058978)\n",
      "Life Stage Testing Confusion Matrix:\n",
      "[[ 526  107  165  374  298  166]\n",
      " [  71   71   58   25   93  183]\n",
      " [ 710  438 3003  679 1137  663]\n",
      " [ 262   24  136  588   57   30]\n",
      " [ 298  202  207  148  744  307]\n",
      " [ 187  221  193   73  284  667]]\n"
     ]
    }
   ],
   "source": [
    "#requires sklearn 0.18\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler #from http://www.kdnuggets.com/2016/10/beginners-guide-neural-networks-python-scikit-learn.html/2\n",
    "\n",
    "scaler=StandardScaler()\n",
    "balanced_scaler=StandardScaler()\n",
    "upsampled_scaler=StandardScaler()\n",
    "\n",
    "scaler.fit(train_X)\n",
    "balanced_scaler.fit(balanced_LS_train_X)\n",
    "upsampled_scaler.fit(upsampled_LS_train_X)\n",
    "\n",
    "scaled_X_train=scaler.transform(train_X)\n",
    "scaled_X_test=scaler.transform(test_X)\n",
    "scaled_balanced_LS_X_train=balanced_scaler.transform(balanced_LS_train_X)\n",
    "scaled_balanced_LS_X_test=balanced_scaler.transform(test_X)\n",
    "scaled_upsampled_LS_X_train=balanced_scaler.transform(upsampled_LS_train_X)\n",
    "scaled_upsampled_LS_X_test=balanced_scaler.transform(test_X)\n",
    "\n",
    "\n",
    "\n",
    "ann_LS = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 100,100), random_state=42)\n",
    "balanced_ann_LS = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 100,100), random_state=42)\n",
    "upsampled_ann_LS = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 100,100), random_state=42)\n",
    "\n",
    "scaled_ann_LS = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 100,100), random_state=42)\n",
    "scaled_balanced_ann_LS = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 100,100), random_state=42)\n",
    "scaled_upsampled_ann_LS = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 100,100), random_state=42)\n",
    "\n",
    "\n",
    "ann_LS = ann_LS.fit(train_X, train_y_LS)\n",
    "balanced_ann_LS = balanced_ann_LS.fit(balanced_LS_train_X, balanced_LS_train_y_LS)\n",
    "upsampled_ann_LS = upsampled_ann_LS.fit(upsampled_LS_train_X, upsampled_LS_train_y_LS)\n",
    "\n",
    "scaled_ann_LS = scaled_ann_LS.fit(scaled_X_train, train_y_LS)\n",
    "scaled_balanced_ann_LS = scaled_balanced_ann_LS.fit(scaled_balanced_LS_X_train, balanced_LS_train_y_LS)\n",
    "scaled_upsampled_ann_LS = scaled_upsampled_ann_LS.fit(scaled_upsampled_LS_X_train, upsampled_LS_train_y_LS)\n",
    "\n",
    "\n",
    "#ann_LS = ann_LS.fit(train_X, train_y_LS)\n",
    "\n",
    "tryClassifier_LS (\"MLP Classifier, reg\",ann_LS, train_X, test_X, train_y_LS, test_y_LS)\n",
    "tryClassifier_LS (\"MLP Classifier, downsampled\",balanced_ann_LS, balanced_LS_train_X, test_X, balanced_LS_train_y_LS, test_y_LS)\n",
    "tryClassifier_LS (\"MLP Classifier, upsampled\",upsampled_ann_LS, upsampled_LS_train_X, test_X, upsampled_LS_train_y_LS, test_y_LS)\n",
    "\n",
    "tryClassifier_LS (\"MLP Classifier Scaled, reg\",scaled_ann_LS, scaled_X_train, scaled_X_test, train_y_LS, test_y_LS)\n",
    "tryClassifier_LS (\"MLP Classifier Scaled, downsampled\",scaled_balanced_ann_LS, scaled_balanced_LS_X_train, scaled_balanced_LS_X_test, balanced_LS_train_y_LS, test_y_LS)\n",
    "tryClassifier_LS (\"MLP Classifier Scaled, downsampled\",scaled_upsampled_ann_LS, scaled_upsampled_LS_X_train, scaled_upsampled_LS_X_test, upsampled_LS_train_y_LS, test_y_LS)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## sample output\n",
    "MLP Classifier, reg\n",
    "('Life Stage Training Accuracy: ', 0.17968899980802458)\n",
    "('Life Stage Training Precision: ', 0.2298118760958785)\n",
    "('Life Stage Training Recall: ', 0.17968899980802458)\n",
    "Life Stage Training Confusion Matrix:\n",
    "[[ 669  229 1337  105  137 1246]\n",
    " [ 220   85  581   29   40  300]\n",
    " [2875 1648 3690  782 1900 4601]\n",
    " [ 345  166  837   74  126  955]\n",
    " [ 796  307 1530  106  188 1542]\n",
    " [ 638  239 1818   73  130  910]]\n",
    "('Life Stage Testing Accuracy: ', 0.17991787980589771)\n",
    "('Life Stage Testing Precision: ', 0.23110982790006593)\n",
    "('Life Stage Testing Recall: ', 0.17991787980589771)\n",
    "Life Stage Testing Confusion Matrix:\n",
    "[[ 284   91  576   45   60  580]\n",
    " [ 105   33  198   11   20  134]\n",
    " [1161  746 1598  362  846 1917]\n",
    " [ 155   78  352   40   59  413]\n",
    " [ 311  138  702   38   66  651]\n",
    " [ 258  106  763   53   56  389]]\n",
    "MLP Classifier, downsampled\n",
    "('Life Stage Training Accuracy: ', 0.29229747675962814)\n",
    "('Life Stage Training Precision: ', 0.30431890396068667)\n",
    "('Life Stage Training Recall: ', 0.29229747675962814)\n",
    "Life Stage Training Confusion Matrix:\n",
    "[[139 158 112 302 409 135]\n",
    " [ 80 295 138  89 379 274]\n",
    " [ 45 123 255 145 605  82]\n",
    " [ 93  71 110 571 357  53]\n",
    " [ 74 181 135 125 571 169]\n",
    " [ 95 265 102  75 348 370]]\n",
    "('Life Stage Testing Accuracy: ', 0.24516610675625233)\n",
    "('Life Stage Testing Precision: ', 0.42953691757810564)\n",
    "('Life Stage Testing Recall: ', 0.24516610675625233)\n",
    "Life Stage Testing Confusion Matrix:\n",
    "[[ 169  175  177  419  524  172]\n",
    " [  36  101   56   31  170  107]\n",
    " [ 288  711 1254  752 3170  455]\n",
    " [  76   58   92  500  322   49]\n",
    " [  94  292  199  196  855  270]\n",
    " [ 121  321  131  127  520  405]]\n",
    "MLP Classifier, upsampled\n",
    "('Life Stage Training Accuracy: ', 0.27628635346756153)\n",
    "('Life Stage Training Precision: ', 0.28965059116452474)\n",
    "('Life Stage Training Recall: ', 0.27628635346756153)\n",
    "Life Stage Training Confusion Matrix:\n",
    "[[1702 1808 1766 3312 5104 1804]\n",
    " [1082 4038 1716  829 4580 3251]\n",
    " [ 739 1327 3057 1558 7675 1140]\n",
    " [1386  653 1455 6538 4482  982]\n",
    " [1273 2501 2031 1267 6252 2172]\n",
    " [1083 3638 1554  972 4148 4101]]\n",
    "('Life Stage Testing Accuracy: ', 0.23979096677864875)\n",
    "('Life Stage Testing Precision: ', 0.41057951560607431)\n",
    "('Life Stage Testing Recall: ', 0.23979096677864875)\n",
    "Life Stage Testing Confusion Matrix:\n",
    "[[ 190  167  190  378  507  204]\n",
    " [  35  113   53   35  156  109]\n",
    " [ 320  576 1295  660 3246  533]\n",
    " [ 115   46  111  451  295   79]\n",
    " [ 122  313  245  180  768  278]\n",
    " [ 139  383  160   93  455  395]]\n",
    "MLP Classifier Scaled, reg\n",
    "('Life Stage Training Accuracy: ', 0.64724515262046456)\n",
    "('Life Stage Training Precision: ', 0.63508407459386296)\n",
    "('Life Stage Training Recall: ', 0.64724515262046456)\n",
    "Life Stage Training Confusion Matrix:\n",
    "[[ 1532    26  1565   281   178   141]\n",
    " [   86   237   544     5    73   310]\n",
    " [  411    38 13581   378   683   405]\n",
    " [  267     2   925  1247    30    32]\n",
    " [  264    14  2267    50  1624   250]\n",
    " [  155    77  1295    39   234  2008]]\n",
    "('Life Stage Testing Accuracy: ', 0.49264650989175063)\n",
    "('Life Stage Testing Precision: ', 0.44363126279488707)\n",
    "('Life Stage Testing Recall: ', 0.49264650989175063)\n",
    "Life Stage Testing Confusion Matrix:\n",
    "[[ 308   15  841  186  171  115]\n",
    " [  38    7  275    4   49  128]\n",
    " [ 342   53 5103  246  494  392]\n",
    " [ 173    3  533  340   21   27]\n",
    " [ 178   27 1084   56  366  195]\n",
    " [ 121   40  768   36  185  475]]\n",
    "MLP Classifier Scaled, downsampled\n",
    "('Life Stage Training Accuracy: ', 0.7626826029216468)\n",
    "('Life Stage Training Precision: ', 0.77453653093601682)\n",
    "('Life Stage Training Recall: ', 0.7626826029216468)\n",
    "Life Stage Training Confusion Matrix:\n",
    "[[ 872   27  136   99   89   32]\n",
    " [  27  995  102   22   67   42]\n",
    " [  37   27 1025   63   84   19]\n",
    " [  62   10  152  996   27    8]\n",
    " [  77   58  158   38  898   26]\n",
    " [  30   80   94   23   71  957]]\n",
    "('Life Stage Testing Accuracy: ', 0.39283314669652858)\n",
    "('Life Stage Testing Precision: ', 0.49172606939455604)\n",
    "('Life Stage Testing Recall: ', 0.39283314669652858)\n",
    "Life Stage Testing Confusion Matrix:\n",
    "[[ 373  191  271  387  270  144]\n",
    " [  61  122   84   25   84  125]\n",
    " [ 641  668 3151  641  990  539]\n",
    " [ 212   50  194  550   65   26]\n",
    " [ 317  293  309  155  609  223]\n",
    " [ 182  363  269   84  270  457]]\n",
    "MLP Classifier Scaled, downsampled\n",
    "('Life Stage Training Accuracy: ', 0.62904405437962485)\n",
    "('Life Stage Training Precision: ', 0.62581264592511332)\n",
    "('Life Stage Training Recall: ', 0.62904405437962485)\n",
    "Life Stage Training Confusion Matrix:\n",
    "[[ 8183   559  1357  2415  1996   986]\n",
    " [  222 13166  1034   231   609   234]\n",
    " [ 1562   757  7355  1647  2703  1472]\n",
    " [ 1313   188  1520 11800   456   219]\n",
    " [ 1756   724  1669   844  8419  2084]\n",
    " [ 1094   805  1222   573  2239  9563]]\n",
    "('Life Stage Testing Accuracy: ', 0.41799178798058978)\n",
    "('Life Stage Testing Precision: ', 0.53504674015698228)\n",
    "('Life Stage Testing Recall: ', 0.41799178798058978)\n",
    "Life Stage Testing Confusion Matrix:\n",
    "[[ 526  107  165  374  298  166]\n",
    " [  71   71   58   25   93  183]\n",
    " [ 710  438 3003  679 1137  663]\n",
    " [ 262   24  136  588   57   30]\n",
    " [ 298  202  207  148  744  307]\n",
    " [ 187  221  193   73  284  667]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier - PS, reg\n",
      "('Price Sensitivity Training Accuracy: ', 0.52828437959941132)\n",
      "('Price Sensitivity Training Precision: ', 0.53359031843164517)\n",
      "('Price Sensitivity Training Recall: ', 0.52828437959941132)\n",
      "Price Sensitivity Training Confusion Matrix:\n",
      "[[2376 3230 1776   85]\n",
      " [1834 4953 4742   99]\n",
      " [ 496 2194 5157   89]\n",
      " [  56   72   70 4025]]\n",
      "('Price Sensitivity Testing Accuracy: ', 0.50496453900709215)\n",
      "('Price Sensitivity Testing Precision: ', 0.51029787358052681)\n",
      "('Price Sensitivity Testing Recall: ', 0.50496453900709215)\n",
      "Price Sensitivity Testing Confusion Matrix:\n",
      "[[ 905 1466  801   50]\n",
      " [ 819 2060 2034   62]\n",
      " [ 216  971 2135   32]\n",
      " [  41   64   75 1664]]\n",
      "AdaBoost Classifier - PS, downsampled\n",
      "('Price Sensitivity Training Accuracy: ', 0.59951456310679607)\n",
      "('Price Sensitivity Training Precision: ', 0.59156465572500982)\n",
      "('Price Sensitivity Training Recall: ', 0.59951456310679607)\n",
      "Price Sensitivity Training Confusion Matrix:\n",
      "[[2298  909  950   66]\n",
      " [1384 1213 1575   51]\n",
      " [ 835  815 2516   57]\n",
      " [  44   30   49 4100]]\n",
      "('Price Sensitivity Testing Accuracy: ', 0.49242254572601718)\n",
      "('Price Sensitivity Testing Precision: ', 0.49571112131737466)\n",
      "('Price Sensitivity Testing Recall: ', 0.49242254572601718)\n",
      "Price Sensitivity Testing Confusion Matrix:\n",
      "[[1702  754  694   72]\n",
      " [1751 1307 1813  104]\n",
      " [ 672  748 1876   58]\n",
      " [  47   39   47 1711]]\n",
      "AdaBoost Classifier - PS, upsampled\n",
      "('Price Sensitivity Training Accuracy: ', 0.58094685242518063)\n",
      "('Price Sensitivity Training Precision: ', 0.60493785116984966)\n",
      "('Price Sensitivity Training Recall: ', 0.58094685242518063)\n",
      "Price Sensitivity Training Confusion Matrix:\n",
      "[[ 4372  5767  1339   150]\n",
      " [ 2293  6411  2782   142]\n",
      " [ 1062  5469  4950   147]\n",
      " [  100    99   141 11288]]\n",
      "('Price Sensitivity Testing Accuracy: ', 0.51705860395670022)\n",
      "('Price Sensitivity Testing Precision: ', 0.51560144938674224)\n",
      "('Price Sensitivity Testing Recall: ', 0.51705860395670022)\n",
      "Price Sensitivity Testing Confusion Matrix:\n",
      "[[1087 1654  421   60]\n",
      " [ 976 2762 1162   75]\n",
      " [ 318 1614 1379   43]\n",
      " [  43   39   64 1698]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_PS = AdaBoostClassifier(n_estimators=1000)\n",
    "balanced_ada_PS = AdaBoostClassifier(n_estimators=1000)\n",
    "upsampled_ada_PS = AdaBoostClassifier(n_estimators=1000)\n",
    "\n",
    "ada_PS = ada_PS.fit(train_X, train_y_PS)\n",
    "balanced_ada_PS = balanced_ada_PS.fit(balanced_PS_train_X, balanced_PS_train_y_PS)\n",
    "upsampled_ada_PS = upsampled_ada_PS.fit(upsampled_PS_train_X, upsampled_PS_train_y_PS)\n",
    "\n",
    "\n",
    "tryClassifier_PS (\"AdaBoost Classifier - PS, reg\",ada_PS, train_X, test_X, train_y_PS, test_y_PS)\n",
    "tryClassifier_PS (\"AdaBoost Classifier - PS, downsampled\",balanced_ada_PS, balanced_PS_train_X, test_X, balanced_PS_train_y_PS, test_y_PS)\n",
    "tryClassifier_PS (\"AdaBoost Classifier - PS, upsampled\",upsampled_ada_PS, upsampled_PS_train_X, test_X, upsampled_PS_train_y_PS, test_y_PS)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Sample Output:\n",
    "AdaBoost Classifier - PS, reg\n",
    "('Price Sensitivity Training Accuracy: ', 0.52828437959941132)\n",
    "('Price Sensitivity Training Precision: ', 0.53359031843164517)\n",
    "('Price Sensitivity Training Recall: ', 0.52828437959941132)\n",
    "Price Sensitivity Training Confusion Matrix:\n",
    "[[2376 3230 1776   85]\n",
    " [1834 4953 4742   99]\n",
    " [ 496 2194 5157   89]\n",
    " [  56   72   70 4025]]\n",
    "('Price Sensitivity Testing Accuracy: ', 0.50496453900709215)\n",
    "('Price Sensitivity Testing Precision: ', 0.51029787358052681)\n",
    "('Price Sensitivity Testing Recall: ', 0.50496453900709215)\n",
    "Price Sensitivity Testing Confusion Matrix:\n",
    "[[ 905 1466  801   50]\n",
    " [ 819 2060 2034   62]\n",
    " [ 216  971 2135   32]\n",
    " [  41   64   75 1664]]\n",
    "AdaBoost Classifier - PS, downsampled\n",
    "('Price Sensitivity Training Accuracy: ', 0.59951456310679607)\n",
    "('Price Sensitivity Training Precision: ', 0.59156465572500982)\n",
    "('Price Sensitivity Training Recall: ', 0.59951456310679607)\n",
    "Price Sensitivity Training Confusion Matrix:\n",
    "[[2298  909  950   66]\n",
    " [1384 1213 1575   51]\n",
    " [ 835  815 2516   57]\n",
    " [  44   30   49 4100]]\n",
    "('Price Sensitivity Testing Accuracy: ', 0.49242254572601718)\n",
    "('Price Sensitivity Testing Precision: ', 0.49571112131737466)\n",
    "('Price Sensitivity Testing Recall: ', 0.49242254572601718)\n",
    "Price Sensitivity Testing Confusion Matrix:\n",
    "[[1702  754  694   72]\n",
    " [1751 1307 1813  104]\n",
    " [ 672  748 1876   58]\n",
    " [  47   39   47 1711]]\n",
    "AdaBoost Classifier - PS, upsampled\n",
    "('Price Sensitivity Training Accuracy: ', 0.58094685242518063)\n",
    "('Price Sensitivity Training Precision: ', 0.60493785116984966)\n",
    "('Price Sensitivity Training Recall: ', 0.58094685242518063)\n",
    "Price Sensitivity Training Confusion Matrix:\n",
    "[[ 4372  5767  1339   150]\n",
    " [ 2293  6411  2782   142]\n",
    " [ 1062  5469  4950   147]\n",
    " [  100    99   141 11288]]\n",
    "('Price Sensitivity Testing Accuracy: ', 0.51705860395670022)\n",
    "('Price Sensitivity Testing Precision: ', 0.51560144938674224)\n",
    "('Price Sensitivity Testing Recall: ', 0.51705860395670022)\n",
    "Price Sensitivity Testing Confusion Matrix:\n",
    "[[1087 1654  421   60]\n",
    " [ 976 2762 1162   75]\n",
    " [ 318 1614 1379   43]\n",
    " [  43   39   64 1698]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier - LS, reg\n",
      "('Life Stage Training Accuracy: ', 0.49702438087924744)\n",
      "('Life Stage Training Precision: ', 0.48383361476872677)\n",
      "('Life Stage Training Recall: ', 0.49702438087924744)\n",
      "Life Stage Training Confusion Matrix:\n",
      "[[  540   179  1836   828   202   138]\n",
      " [   43   335   550    11    84   232]\n",
      " [  406   957 11579  1086   716   752]\n",
      " [  197     1   926  1342    25    12]\n",
      " [  231   495  2378   203   747   415]\n",
      " [  115   905  1471    87   239   991]]\n",
      "('Life Stage Testing Accuracy: ', 0.48114968271743186)\n",
      "('Life Stage Testing Precision: ', 0.4635005629478931)\n",
      "('Life Stage Testing Recall: ', 0.48114968271743186)\n",
      "Life Stage Testing Confusion Matrix:\n",
      "[[ 197   87  835  349   98   70]\n",
      " [  16  112  225    9   40   99]\n",
      " [ 178  438 4889  463  325  337]\n",
      " [  72    5  428  570   12   10]\n",
      " [  86  208 1032  105  292  183]\n",
      " [  62  364  670   39  105  385]]\n",
      "AdaBoost Classifier - LS, downsampled\n",
      "('Life Stage Training Accuracy: ', 0.45657370517928286)\n",
      "('Life Stage Training Precision: ', 0.45262541849006438)\n",
      "('Life Stage Training Recall: ', 0.45657370517928286)\n",
      "Life Stage Training Confusion Matrix:\n",
      "[[452 126 132 309 136 100]\n",
      " [116 515 115  29 174 306]\n",
      " [ 97 138 611 134 150 125]\n",
      " [188  15 112 872  44  24]\n",
      " [143 239 122  80 455 216]\n",
      " [105 321 102  41 153 533]]\n",
      "('Life Stage Testing Accuracy: ', 0.38977230309817096)\n",
      "('Life Stage Testing Precision: ', 0.52306736353196781)\n",
      "('Life Stage Testing Recall: ', 0.38977230309817096)\n",
      "Life Stage Testing Confusion Matrix:\n",
      "[[ 409  202  190  447  220  168]\n",
      " [  53  164   49   23   78  134]\n",
      " [ 527  845 2884  738  880  756]\n",
      " [ 177   28  142  678   38   34]\n",
      " [ 261  411  237  132  536  329]\n",
      " [ 149  452  161   82  231  550]]\n",
      "AdaBoost Classifier - LS, upsampled\n",
      "('Life Stage Training Accuracy: ', 0.43734942350714162)\n",
      "('Life Stage Training Precision: ', 0.43222366548507501)\n",
      "('Life Stage Training Recall: ', 0.43734942350714162)\n",
      "Life Stage Training Confusion Matrix:\n",
      "[[ 4844  1422  1428  4601  2112  1089]\n",
      " [ 1346  7872  1270   386  1795  2827]\n",
      " [ 1319  2068  6994  1837  2120  1158]\n",
      " [ 2304   157  1488 10694   537   316]\n",
      " [ 2054  3392  1653  1220  5289  1888]\n",
      " [ 1315  5370  1204   721  1916  4970]]\n",
      "('Life Stage Testing Accuracy: ', 0.39268383725270622)\n",
      "('Life Stage Testing Precision: ', 0.53755327631600847)\n",
      "('Life Stage Testing Recall: ', 0.39268383725270622)\n",
      "Life Stage Testing Confusion Matrix:\n",
      "[[ 408  172  158  495  273  130]\n",
      " [  59  180   44   19   82  117]\n",
      " [ 572  923 2940  772  901  522]\n",
      " [ 183   22  132  696   35   29]\n",
      " [ 274  450  191  157  588  246]\n",
      " [ 165  558  148   81  225  448]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_LS = AdaBoostClassifier(n_estimators=1000)\n",
    "balanced_ada_LS = AdaBoostClassifier(n_estimators=1000)\n",
    "upsampled_ada_LS = AdaBoostClassifier(n_estimators=1000)\n",
    "\n",
    "ada_LS = ada_LS.fit(train_X, train_y_LS)\n",
    "balanced_ada_LS = balanced_ada_LS.fit(balanced_LS_train_X, balanced_LS_train_y_LS)\n",
    "upsampled_ada_LS = upsampled_ada_LS.fit(upsampled_LS_train_X, upsampled_LS_train_y_LS)\n",
    "\n",
    "\n",
    "tryClassifier_LS (\"AdaBoost Classifier - LS, reg\",ada_LS, train_X, test_X, train_y_LS, test_y_LS)\n",
    "tryClassifier_LS (\"AdaBoost Classifier - LS, downsampled\",balanced_ada_LS, balanced_LS_train_X, test_X, balanced_LS_train_y_LS, test_y_LS)\n",
    "tryClassifier_LS (\"AdaBoost Classifier - LS, upsampled\",upsampled_ada_LS, upsampled_LS_train_X, test_X, upsampled_LS_train_y_LS, test_y_LS)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## sample output\n",
    "AdaBoost Classifier - LS, reg\n",
    "('Life Stage Training Accuracy: ', 0.49702438087924744)\n",
    "('Life Stage Training Precision: ', 0.48383361476872677)\n",
    "('Life Stage Training Recall: ', 0.49702438087924744)\n",
    "Life Stage Training Confusion Matrix:\n",
    "[[  540   179  1836   828   202   138]\n",
    " [   43   335   550    11    84   232]\n",
    " [  406   957 11579  1086   716   752]\n",
    " [  197     1   926  1342    25    12]\n",
    " [  231   495  2378   203   747   415]\n",
    " [  115   905  1471    87   239   991]]\n",
    "('Life Stage Testing Accuracy: ', 0.48114968271743186)\n",
    "('Life Stage Testing Precision: ', 0.4635005629478931)\n",
    "('Life Stage Testing Recall: ', 0.48114968271743186)\n",
    "Life Stage Testing Confusion Matrix:\n",
    "[[ 197   87  835  349   98   70]\n",
    " [  16  112  225    9   40   99]\n",
    " [ 178  438 4889  463  325  337]\n",
    " [  72    5  428  570   12   10]\n",
    " [  86  208 1032  105  292  183]\n",
    " [  62  364  670   39  105  385]]\n",
    "AdaBoost Classifier - LS, downsampled\n",
    "('Life Stage Training Accuracy: ', 0.45657370517928286)\n",
    "('Life Stage Training Precision: ', 0.45262541849006438)\n",
    "('Life Stage Training Recall: ', 0.45657370517928286)\n",
    "Life Stage Training Confusion Matrix:\n",
    "[[452 126 132 309 136 100]\n",
    " [116 515 115  29 174 306]\n",
    " [ 97 138 611 134 150 125]\n",
    " [188  15 112 872  44  24]\n",
    " [143 239 122  80 455 216]\n",
    " [105 321 102  41 153 533]]\n",
    "('Life Stage Testing Accuracy: ', 0.38977230309817096)\n",
    "('Life Stage Testing Precision: ', 0.52306736353196781)\n",
    "('Life Stage Testing Recall: ', 0.38977230309817096)\n",
    "Life Stage Testing Confusion Matrix:\n",
    "[[ 409  202  190  447  220  168]\n",
    " [  53  164   49   23   78  134]\n",
    " [ 527  845 2884  738  880  756]\n",
    " [ 177   28  142  678   38   34]\n",
    " [ 261  411  237  132  536  329]\n",
    " [ 149  452  161   82  231  550]]\n",
    "AdaBoost Classifier - LS, upsampled\n",
    "('Life Stage Training Accuracy: ', 0.43734942350714162)\n",
    "('Life Stage Training Precision: ', 0.43222366548507501)\n",
    "('Life Stage Training Recall: ', 0.43734942350714162)\n",
    "Life Stage Training Confusion Matrix:\n",
    "[[ 4844  1422  1428  4601  2112  1089]\n",
    " [ 1346  7872  1270   386  1795  2827]\n",
    " [ 1319  2068  6994  1837  2120  1158]\n",
    " [ 2304   157  1488 10694   537   316]\n",
    " [ 2054  3392  1653  1220  5289  1888]\n",
    " [ 1315  5370  1204   721  1916  4970]]\n",
    "('Life Stage Testing Accuracy: ', 0.39268383725270622)\n",
    "('Life Stage Testing Precision: ', 0.53755327631600847)\n",
    "('Life Stage Testing Recall: ', 0.39268383725270622)\n",
    "Life Stage Testing Confusion Matrix:\n",
    "[[ 408  172  158  495  273  130]\n",
    " [  59  180   44   19   82  117]\n",
    " [ 572  923 2940  772  901  522]\n",
    " [ 183   22  132  696   35   29]\n",
    " [ 274  450  191  157  588  246]\n",
    " [ 165  558  148   81  225  448]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rfc_ps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-8f3cd4456a7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;31m#sklearn.ensemble.VotingClassifier kept crashing, so do it manually\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrfc_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrfc_ps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mgbc_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgbc_ps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mann_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaled_ann_PS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaled_X_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rfc_ps' is not defined"
     ]
    }
   ],
   "source": [
    "#do ensemble of the best three sets of predictions\n",
    "#sklearn.ensemble.VotingClassifier kept crashing, so do it manually\n",
    "\n",
    "rfc_preds = rfc_ps.predict(test_X)\n",
    "gbc_preds = gbc_ps.predict(test_X)\n",
    "ann_preds = scaled_ann_PS.predict(scaled_X_test)\n",
    "\n",
    "from scipy import stats\n",
    "ensemble_preds = np.transpose(np.array([rfc_preds,gbc_preds,ann_preds]))\n",
    "voted_preds_PS = stats.mode(ensemble_preds, axis=1)\n",
    "\n",
    "print(confusion_matrix(test_y_PS, voted_preds_PS.mode, labels=[\"LA\", \"MM\", \"UM\",\"XX\"]))\n",
    "print(\"Price Sensitivity Accuracy:\",performance_metric(test_y_PS,voted_preds_PS.mode))\n",
    "print('Price Sensitivity Precision: ', precision_score(test_y_PS, voted_preds_PS.mode, average='weighted'))\n",
    "print('Price Sensitivity Recall: ', recall_score(test_y_PS, voted_preds_PS.mode, average='weighted'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "sample output:\n",
    "    [[1301 1760  109   52]\n",
    " [ 545 3690  651   89]\n",
    " [  57 1534 1712   51]\n",
    " [  18   76   11 1739]]\n",
    "('Accuracy:', 0.63023516237402011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rfc_ls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-1f1727cd44f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrfc_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrfc_ls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mupsampled_rfc_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupsampled_rfc_ls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgbc_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupsampled_gbc_LS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mann_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaled_ann_LS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaled_X_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mupsampled_rfc_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrfc_upsampled_ls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rfc_ls' is not defined"
     ]
    }
   ],
   "source": [
    "rfc_preds = rfc_ls.predict(test_X)\n",
    "upsampled_rfc_preds = upsampled_rfc_ls.predict(test_X)\n",
    "gbc_preds = upsampled_gbc_LS.predict(test_X)\n",
    "ann_preds = scaled_ann_LS.predict(scaled_X_test)\n",
    "upsampled_rfc_preds = rfc_upsampled_ls.predict(test_X)\n",
    "ada_preds = ada_LS.predict(test_X)\n",
    "\n",
    "from scipy import stats\n",
    "ensemble_preds = np.transpose(np.array([rfc_preds,gbc_preds,ann_preds,upsampled_rfc_preds,ada_preds]))\n",
    "voted_preds_LS = stats.mode(ensemble_preds, axis=1)\n",
    "\n",
    "print(confusion_matrix(test_y_LS, voted_preds_LS.mode, labels=[\"OA\", \"OF\", \"OT\",\"PE\",\"YA\",\"YF\"]))\n",
    "print(\"Life Stage Accuracy:\",performance_metric(test_y_LS,voted_preds_LS.mode))\n",
    "print('Life Stage Precision: ', precision_score(test_y_LS, voted_preds_LS.mode, average='weighted'))\n",
    "print('Life Stage Recall: ', recall_score(test_y_LS, voted_preds_LS.mode, average='weighted'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sample output:\n",
    "[[ 217    3 1180  120   42   74]\n",
    " [  15    0  324    0   11  151]\n",
    " [ 165   21 5712  167  237  328]\n",
    " [ 139    1  606  343    3    5]\n",
    " [  85    8 1392   25  236  160]\n",
    " [  41   10  993   12   54  515]]\n",
    "('Accuracy:', 0.52430011198208282)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 310    9 1027  144   65   81]\n",
      " [  22   14  291    1   24  149]\n",
      " [ 261   57 5461  178  316  357]\n",
      " [ 177    2  541  363    6    8]\n",
      " [ 122   27 1246   29  309  173]\n",
      " [  83   37  866   14   97  528]]\n",
      "('Accuracy:', 0.5214632325494587)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# initial result summary\n",
    "For PS, it seems that random forest has the highest accuracy, so we can do a grid-search around it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "('Price Sensitivity Training Accuracy: ', 1.0)\n",
      "('Price Sensitivity Training Precision: ', 1.0)\n",
      "('Price Sensitivity Training Recall: ', 1.0)\n",
      "Price Sensitivity Training Confusion Matrix:\n",
      "[[11628     0     0     0]\n",
      " [    0 11628     0     0]\n",
      " [    0     0 11628     0]\n",
      " [    0     0     0 11628]]\n",
      "('Price Sensitivity Testing Accuracy: ', 0.62575587905935048)\n",
      "('Price Sensitivity Testing Precision: ', 0.63031556781300335)\n",
      "('Price Sensitivity Testing Recall: ', 0.62575587905935048)\n",
      "Price Sensitivity Testing Confusion Matrix:\n",
      "[[1497 1481  175   69]\n",
      " [ 766 3223  869  117]\n",
      " [ 104 1282 1901   67]\n",
      " [  24   45   14 1761]]\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features=10, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=5000, n_jobs=1, oob_score='True', random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "{'max_features': 10, 'n_estimators': 5000, 'oob_score': 'True', 'random_state': 42, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "params = {'n_estimators': [5000,10000], 'max_features': [5,10,15],'random_state':[42], 'criterion':[\"entropy\"],'oob_score':[\"True\"]} #, \n",
    "rfc_upsampled_ps=RandomForestClassifier()\n",
    "\n",
    "grid_upsampled_rfc_ps = GridSearchCV(estimator=rfc_upsampled_ps, param_grid=params, n_jobs=5)\n",
    "\n",
    "# Fit the grid search object to the data to compute the optimal model\n",
    "grid_upsampled_rfc_ps = grid_upsampled_rfc_ps.fit(upsampled_PS_train_X, upsampled_PS_train_y_PS)\n",
    "\n",
    "#print('Price Sensitivity OOB: ', grid_upsampled_rfc_ps.oob_score_)\n",
    "tryClassifier_PS (\"Random Forest\", grid_upsampled_rfc_ps, upsampled_PS_train_X, test_X, upsampled_PS_train_y_PS, test_y_PS)\n",
    "\n",
    "print(grid_upsampled_rfc_ps.best_estimator_)\n",
    "print(grid_upsampled_rfc_ps.best_params_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#sample code, up to 3k\n",
    "Random Forest\n",
    "('Price Sensitivity Training Accuracy: ', 1.0)\n",
    "('Price Sensitivity Training Precision: ', 1.0)\n",
    "('Price Sensitivity Training Recall: ', 1.0)\n",
    "Price Sensitivity Training Confusion Matrix:\n",
    "[[11628     0     0     0]\n",
    " [    0 11628     0     0]\n",
    " [    0     0 11628     0]\n",
    " [    0     0     0 11628]]\n",
    "('Price Sensitivity Testing Accuracy: ', 0.62605449794699519)\n",
    "('Price Sensitivity Testing Precision: ', 0.63049293849401533)\n",
    "('Price Sensitivity Testing Recall: ', 0.62605449794699519)\n",
    "Price Sensitivity Testing Confusion Matrix:\n",
    "[[1498 1482  174   68]\n",
    " [ 762 3223  875  115]\n",
    " [ 107 1275 1904   68]\n",
    " [  26   43   14 1761]]\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "            max_depth=None, max_features=10, max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=3000, n_jobs=1, oob_score='True', random_state=42,\n",
    "            verbose=0, warm_start=False)\n",
    "{'max_features': 10, 'n_estimators': 3000, 'oob_score': 'True', 'random_state': 42, 'criterion': 'entropy'}\n",
    "\n",
    "#output up to 5k\n",
    "('Price Sensitivity Training Accuracy: ', 1.0)\n",
    "('Price Sensitivity Training Precision: ', 1.0)\n",
    "('Price Sensitivity Training Recall: ', 1.0)\n",
    "Price Sensitivity Training Confusion Matrix:\n",
    "[[11628     0     0     0]\n",
    " [    0 11628     0     0]\n",
    " [    0     0 11628     0]\n",
    " [    0     0     0 11628]]\n",
    "('Price Sensitivity Testing Accuracy: ', 0.62575587905935048)\n",
    "('Price Sensitivity Testing Precision: ', 0.63031556781300335)\n",
    "('Price Sensitivity Testing Recall: ', 0.62575587905935048)\n",
    "Price Sensitivity Testing Confusion Matrix:\n",
    "[[1497 1481  175   69]\n",
    " [ 766 3223  869  117]\n",
    " [ 104 1282 1901   67]\n",
    " [  24   45   14 1761]]\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "            max_depth=None, max_features=10, max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=5000, n_jobs=1, oob_score='True', random_state=42,\n",
    "            verbose=0, warm_start=False)\n",
    "{'max_features': 10, 'n_estimators': 5000, 'oob_score': 'True', 'random_state': 42, 'criterion': 'entropy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "('Life Stage Training Accuracy: ', 0.9999784890724488)\n",
      "('Life Stage Training Precision: ', 0.99997849184841059)\n",
      "('Life Stage Training Recall: ', 0.9999784890724488)\n",
      "Life Stage Training Confusion Matrix:\n",
      "[[15496     0     0     0     0     0]\n",
      " [    0 15496     0     0     0     0]\n",
      " [    0     0 15494     0     2     0]\n",
      " [    0     0     0 15496     0     0]\n",
      " [    0     0     0     0 15496     0]\n",
      " [    0     0     0     0     0 15496]]\n",
      "('Life Stage Testing Accuracy: ', 0.51519223590892127)\n",
      "('Life Stage Testing Precision: ', 0.46286981551303791)\n",
      "('Life Stage Testing Recall: ', 0.51519223590892127)\n",
      "Life Stage Testing Confusion Matrix:\n",
      "[[ 228    0  953  153  122  180]\n",
      " [  12    0  254    1   42  192]\n",
      " [ 196    0 5236  189  461  548]\n",
      " [ 169    0  563  337    5   23]\n",
      " [  78    0 1094   38  418  278]\n",
      " [  36    0  769   14  124  682]]\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features=5, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=5000, n_jobs=1, oob_score='True', random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "{'max_features': 5, 'n_estimators': 5000, 'oob_score': 'True', 'random_state': 42, 'criterion': 'entropy'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "params = {'n_estimators': [500,1000,3000,5000,10000], 'max_features': [5,10,15],'random_state':[42], 'criterion':[\"entropy\"],'oob_score':[\"True\"]} #, \n",
    "rfc_upsampled_ls=RandomForestClassifier()\n",
    "\n",
    "grid_upsampled_rfc_ls = GridSearchCV(estimator=rfc_upsampled_ls, param_grid=params, n_jobs=5)\n",
    "\n",
    "# Fit the grid search object to the data to compute the optimal model\n",
    "grid_upsampled_rfc_ls = grid_upsampled_rfc_ls.fit(upsampled_LS_train_X, upsampled_LS_train_y_LS)\n",
    "\n",
    "#print('Price Sensitivity OOB: ', grid_upsampled_rfc_ls.oob_score_)\n",
    "tryClassifier_LS (\"Random Forest\", grid_upsampled_rfc_ls, upsampled_LS_train_X, test_X, upsampled_LS_train_y_LS, test_y_LS)\n",
    "\n",
    "print(grid_upsampled_rfc_ls.best_estimator_)\n",
    "print(grid_upsampled_rfc_ls.best_params_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sample output:\n",
    "Random Forest\n",
    "('Life Stage Training Accuracy: ', 0.9999784890724488)\n",
    "('Life Stage Training Precision: ', 0.99997849184841059)\n",
    "('Life Stage Training Recall: ', 0.9999784890724488)\n",
    "Life Stage Training Confusion Matrix:\n",
    "[[15496     0     0     0     0     0]\n",
    " [    0 15496     0     0     0     0]\n",
    " [    0     0 15494     0     2     0]\n",
    " [    0     0     0 15496     0     0]\n",
    " [    0     0     0     0 15496     0]\n",
    " [    0     0     0     0     0 15496]]\n",
    "('Life Stage Testing Accuracy: ', 0.51519223590892127)\n",
    "('Life Stage Testing Precision: ', 0.46286981551303791)\n",
    "('Life Stage Testing Recall: ', 0.51519223590892127)\n",
    "Life Stage Testing Confusion Matrix:\n",
    "[[ 228    0  953  153  122  180]\n",
    " [  12    0  254    1   42  192]\n",
    " [ 196    0 5236  189  461  548]\n",
    " [ 169    0  563  337    5   23]\n",
    " [  78    0 1094   38  418  278]\n",
    " [  36    0  769   14  124  682]]\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "            max_depth=None, max_features=5, max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=5000, n_jobs=1, oob_score='True', random_state=42,\n",
    "            verbose=0, warm_start=False)\n",
    "{'max_features': 5, 'n_estimators': 5000, 'oob_score': 'True', 'random_state': 42, 'criterion': 'entropy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "params = {'learning_rate': [0.01,0.05,0.1], 'n_estimators': [500,1000,3000], 'max_depth':[5,10,15]} \n",
    "upsampled_gbc_ps=GradientBoostingClassifier()\n",
    "grid_upsampled_gbc_ps = GridSearchCV(estimator=upsampled_gbc_ps, param_grid=params, n_jobs=5)\n",
    "grid_upsampled_gbc_ps = grid_upsampled_gbc_ps.fit(upsampled_PS_train_X, upsampled_PS_train_y_PS)\n",
    "tryClassifier_PS (\"Gradient Boosting Classifier, GridSearch\", grid_upsampled_gbc_ps, upsampled_PS_train_X, test_X, upsampled_PS_train_y_PS, test_y_PS)\n",
    "\n",
    "print(grid_upsampled_gbc_ps.best_estimator_)\n",
    "print(grid_upsampled_gbc_ps.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample output:\n",
    "Gradient Boosting Classifier, GridSearch\n",
    "('Price Sensitivity Training: ', 0.838650812338121)\n",
    "[[3551  343  231  111]\n",
    " [ 601 2971  540  116]\n",
    " [ 240  391 3550  107]\n",
    " [  31   10   20 4175]]\n",
    "('Price Sensitivity Testing: ', 0.66629339305711088)\n",
    "[[2278  557  245  142]\n",
    " [1244 2399 1151  181]\n",
    " [ 282  529 2450   93]\n",
    " [  21    8   17 1798]]\n",
    "\n",
    "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
    "              learning_rate=0.01, loss='deviance', max_depth=5,\n",
    "              max_features=None, max_leaf_nodes=None,\n",
    "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "              n_estimators=1000, presort='auto', random_state=None,\n",
    "              subsample=1.0, verbose=0, warm_start=False)\n",
    "{'n_estimators': 1000, 'learning_rate': 0.01, 'max_depth': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#requires sklearn 0.18\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler #from http://www.kdnuggets.com/2016/10/beginners-guide-neural-networks-python-scikit-learn.html/2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(train_X)\n",
    "\n",
    "scaled_X_train=scaler.transform(train_X)\n",
    "scaled_X_test=scaler.transform(test_X)\n",
    "\n",
    "#params = {'learning_rate': [0.01,0.05,0.1], 'n_estimators': [500,1000,3000], 'max_depth':[5,10,15]} \n",
    "\n",
    "params = {'solver':[\"lbfgs\"], 'alpha':[0.00001, 0.0005], 'hidden_layer_sizes':[(100, 100,100),(10), (10,10)], 'random_state':[42]}\n",
    "scaled_ann_LS=MLPClassifier()\n",
    "\n",
    "grid_scaled_ann_LS = GridSearchCV(estimator=scaled_ann_LS, param_grid=params, n_jobs=5)\n",
    "grid_scaled_ann_LS = grid_scaled_ann_LS.fit(scaled_X_train, train_y_LS)\n",
    "\n",
    "#scaled_ann_LS = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 100,100), random_state=42)\n",
    "\n",
    "\n",
    "tryClassifier_LS (\"MLP Classifier Scaled, GridSearch\", grid_scaled_ann_LS, scaled_X_train, test_X, train_y_LS, test_y_LS)\n",
    "\n",
    "print(grid_scaled_ann_LS.best_estimator_)\n",
    "print(grid_scaled_ann_LS.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#requires sklearn 0.18\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler #from http://www.kdnuggets.com/2016/10/beginners-guide-neural-networks-python-scikit-learn.html/2\n",
    "\n",
    "scaler=StandardScaler()\n",
    "\n",
    "scaler.fit(train_X)\n",
    "\n",
    "scaled_X_train=scaler.transform(train_X)\n",
    "scaled_X_test=scaler.transform(test_X)\n",
    "\n",
    "scaled_ann_LS = MLPClassifier(solver='sgd', alpha=0.0001, learning_rate_init=0.001, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(100,10), random_state=43, activation='logistic', max_iter=5000,\n",
    "                             )\n",
    "scaled_ann_LS = scaled_ann_LS.fit(scaled_X_train, train_y_LS)\n",
    "\n",
    "\n",
    "tryClassifier_LS (\"MLP Classifier Scaled\",scaled_ann_LS, scaled_X_train, scaled_X_test, train_y_LS, test_y_LS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaled_ann_LS = MLPClassifier(solver='lbfgs', alpha=0.0001, learning_rate_init=0.001, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(200,200), random_state=42) = .469\n",
    "scaled_ann_LS = MLPClassifier(solver='lbfgs', alpha=0.0001, learning_rate_init=0.01, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(200,200), random_state=42) = .469\n",
    "scaled_ann_LS = MLPClassifier(solver='sgd', alpha=0.0001, learning_rate_init=0.001, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(200,200), random_state=42) = .497, needs more iterations\n",
    "scaled_ann_LS = MLPClassifier(solver='sgd', alpha=0.0001, learning_rate_init=0.01, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(200,200), random_state=42) = 0.447\n",
    "scaled_ann_LS = MLPClassifier(solver='sgd', alpha=0.0001, learning_rate_init=0.001, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(200,200), random_state=42, activation='logistic') = 0.508\n",
    "scaled_ann_LS = MLPClassifier(solver='sgd', alpha=0.0001, learning_rate_init=0.001, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(200,200), random_state=42, activation='logistic', max_iter=500) = 0.511\n",
    "scaled_ann_LS = MLPClassifier(solver='sgd', alpha=0.0001, learning_rate_init=0.001, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(200,200), random_state=42, activation='logistic', max_iter=1000) = 0.511\n",
    "scaled_ann_LS = MLPClassifier(solver='sgd', alpha=0.0001, learning_rate_init=0.001, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(20,20), random_state=42, activation='logistic', max_iter=500) = 0.508\n",
    "scaled_ann_LS = scaled_ann_LS.fit(scaled_X_train, balanced_LS_train_y_LS) = 0.471\n",
    "scaled_ann_LS = MLPClassifier(solver='adam', alpha=0.0001, learning_rate_init=0.001, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(200,200), random_state=42, activation='logistic', max_iter=500)=0.480\n",
    "scaled_ann_LS = MLPClassifier(solver='adam', alpha=0.0001, learning_rate_init=0.001, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(200,200), random_state=42, activation='tanh', max_iter=500)=0.485\n",
    "scaled_ann_LS = scaled_ann_LS.fit(scaled_X_train, upsampled_LS_train_y_LS) = 0.473\n",
    "scaled_ann_LS = MLPClassifier(solver='sgd', alpha=0.0001, learning_rate_init=0.001, learning_rate='adaptive',\n",
    "                              hidden_layer_sizes=(200,200), random_state=42, activation='logistic', max_iter=500) = 0.510\n",
    "scaled_ann_LS = MLPClassifier(solver='sgd', alpha=0.0001, learning_rate_init=0.0001, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(200,200), random_state=42, activation='logistic', max_iter=1000) = 0.498\n",
    "scaled_ann_LS = MLPClassifier(solver='sgd', alpha=0.0001, learning_rate_init=0.001, learning_rate='constant',\n",
    "                              hidden_layer_sizes=(100,10), random_state=42, activation='logistic', max_iter=5000) = 0.512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1df076f5302e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[1;31m# Fit the grid search object to the data to compute the optimal model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgrid_rfc_LS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_rfc_LS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y_LS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtryClassifier_LS\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Random Forest, Grid\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_rfc_LS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y_LS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y_LS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\model_selection\\_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\model_selection\\_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    716\u001b[0m                     \u001b[1;31m# scheduling.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.pyc\u001b[0m in \u001b[0;36mabort_everything\u001b[0;34m(self, ensure_ready)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mabort_everything\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_ready\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[1;34m\"\"\"Shutdown the pool and restart a new one with the same parameters\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_ready\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             self.configure(n_jobs=self.parallel.n_jobs, parallel=self.parallel,\n",
      "\u001b[0;32mC:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.pyc\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[1;34m\"\"\"Shutdown the process or thread pool\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMultiprocessingBackend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJOBLIB_SPAWNED_PROCESS\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJOBLIB_SPAWNED_PROCESS\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.pyc\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# terminate does a join()\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\externals\\joblib\\pool.pyc\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_retries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m                 \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMemmapingPool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mWindowsError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\multiprocessing\\pool.pyc\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_terminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\multiprocessing\\util.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wr)\u001b[0m\n\u001b[1;32m    205\u001b[0m                 sub_debug('finalizer calling %s with args %s and kwargs %s',\n\u001b[1;32m    206\u001b[0m                           self._callback, self._args, self._kwargs)\n\u001b[0;32m--> 207\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_weakref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\multiprocessing\\pool.pyc\u001b[0m in \u001b[0;36m_terminate_pool\u001b[0;34m(cls, taskqueue, inqueue, outqueue, pool, worker_handler, task_handler, result_handler, cache)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'joining task handler'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mthreading\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtask_handler\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mtask_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1e100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'joining result handler'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\threading.pyc\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    949\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s.join(): timed out\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__block\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\leander.quiring\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python2\\lib\\threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                     \u001b[0mdelay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelay\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                     \u001b[0m_sleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgotit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "params = {'n_estimators': [1000,3000,5000], 'max_features': [5,10,15], 'random_state':[42], 'criterion':[\"entropy\"]}\n",
    "\n",
    "rfc_LS=RandomForestClassifier()\n",
    "\n",
    "grid_rfc_LS = GridSearchCV(estimator=rfc_LS, param_grid=params, n_jobs=5)\n",
    "\n",
    "# Fit the grid search object to the data to compute the optimal model\n",
    "grid_rfc_LS = grid_rfc_LS.fit(train_X, train_y_LS)\n",
    "\n",
    "tryClassifier_LS (\"Random Forest, Grid\", grid_rfc_LS, train_X, test_X, train_y_LS, test_y_LS)\n",
    "\n",
    "print(grid_rfc_LS.best_estimator_)\n",
    "print(grid_rfc_LS.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample output:\n",
    "    ('LifeStage Training: ', 0.99910411467332183)\n",
    "[[ 3717     0     6     0     0     0]\n",
    " [    0  1253     2     0     0     0]\n",
    " [    0     0 15496     0     0     0]\n",
    " [    0     0     3  2500     0     0]\n",
    " [    0     0    12     0  4457     0]\n",
    " [    0     0     5     0     0  3803]]\n",
    "('LifeStage Testing: ', 0.51131019036954084)\n",
    "[[  60    0 1455   53    3   65]\n",
    " [   1    0  366    2    0  132]\n",
    " [  58    1 6182   67    9  313]\n",
    " [  71    0  887  130    0    9]\n",
    " [  28    0 1709   10    7  152]\n",
    " [   8    0 1136    9    2  470]]\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "            max_depth=None, max_features=15, max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=5000, n_jobs=1, oob_score=False, random_state=42,\n",
    "            verbose=0, warm_start=False)\n",
    "{'max_features': 15, 'n_estimators': 5000, 'random_state': 42, 'criterion': 'entropy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#random useful code snippets\n",
    "list(data.columns.values)\n",
    "data['SPEND'].dtype\n",
    "data_cross.head(10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
